[
  {
    "objectID": "lectures/lectures-class-5.html",
    "href": "lectures/lectures-class-5.html",
    "title": "Class 5: Data Preparation",
    "section": "",
    "text": "In Class 4, we saw that the first stage in the data processing workflow is data preparation. This is a critical, though often overlooked stepped. This class will focus on some general principals and common data preparation steps.\nThis guide is meant to help you figure out the steps you need to take in order to prepare your data for scoring and analysis. The end product of this data preparation stage is one or more tidy raw data files.\nThis guide assumes you have completed Classes 1 - 4. You should reference materials in those classes to help you at this stage."
  },
  {
    "objectID": "lectures/lectures-class-5.html#understanding-the-messy-raw-data-file",
    "href": "lectures/lectures-class-5.html#understanding-the-messy-raw-data-file",
    "title": "Class 5: Data Preparation",
    "section": "Understanding the Messy Raw Data File",
    "text": "Understanding the Messy Raw Data File\nYou should take some time to better understand your messy raw data file:\nUse functions, such as colnames() and unique(), that we learned in Class 1: An Introduction to Working with Data in R to explore your imported data file.\n\nIdentify the essential columns you want to keep. Some examples:\n\nUnique IDs for each participant\nIf there are multiple trials or items adminstered, what column identifies the trial or item number?\n\nSame thing if there were multiple blocks or sessions adminstered\n\nDifferent experimental conditions or counterbalancing condition\nStimulus information (e.g., red square) for individual trials / items\nResponse information\n\nResponse made\nCorrect response (if there is one)\nAccuracy (if there is one)\nResponse time\n\nAdminstration date and time?\nAnd more…\n\nWhat kind of values do each of those columns contain?\n\nNumeric? Character strings?\n\n\nThe amount of time it took for you to do those steps is the reason we are doing this data preparation step. The end product will hopefully be a tidy raw data file that is way easier to understand and work with, even for someone that was not involved in the project.\nFor example you might have a data frame that is structured like this\n\n\n\n  \n\n\n\nAre you able to understand what this data frame contains?\nThere is a bit of structure in the column names but that is about it. By the end of this guide we will create a tidy version of this messy data file."
  },
  {
    "objectID": "lectures/lectures-class-5.html#tidying-up",
    "href": "lectures/lectures-class-5.html#tidying-up",
    "title": "Class 5: Data Preparation",
    "section": "Tidying Up",
    "text": "Tidying Up\nHow you need to tidy up your data file will depend on the nature of your program used to generate your data. However, there are some common messy problems we can address.\n\nColumn names that are not clear: rename()\nRows that are not needed: filter()\nAdd or modify values in columns: mutate() and case_when()\nColumns that are not needed: select()\n\nNotice in the script template I laid out the general format for this.\n\ndata_raw &lt;- data_import |&gt;\n  rename() |&gt;\n  filter() |&gt;\n  mutate() |&gt;\n  select()"
  },
  {
    "objectID": "lectures/lectures-class-5.html#rename-columns",
    "href": "lectures/lectures-class-5.html#rename-columns",
    "title": "Class 5: Data Preparation",
    "section": "Rename Columns",
    "text": "Rename Columns\nThis step can actually be completed in the rest of the steps below but occasionally can be useful to do upfront.\nOne thing you might want to do at this point though is consider a standard naming scheme for your columns. Do you want to use capital letters? All lower case? Snake_case? CamelCase? etc.\nLet’s go ahead and rename some columns so they are more clear what information they contain:\n\nCodeData Frame\n\n\n\ndata_raw &lt;- data_import |&gt;\n  rename(Trial = trial, Procedure = List,\n         Condition = COND, Correct_Response = Ans)\n\n\n\n\n\n\n\nImportant\n\n\n\n\nYou need to use the special type of quotation marks ` ` if your column names contain special charaters like: a space, $, %, -, and more…\n\n\n\nView the Data Frame tab to see the resulting data frames\n\n\nUse the small arrow ▸ at the end of the column names to see more columns"
  },
  {
    "objectID": "lectures/lectures-class-5.html#filter-rows",
    "href": "lectures/lectures-class-5.html#filter-rows",
    "title": "Class 5: Data Preparation",
    "section": "Filter Rows",
    "text": "Filter Rows\nOccasionally there might be additional rows that are not needed. In this example the first row for each participant is not needed and corresponds to an “Instructions” screen. Let’s remove this\n\nCodeData Frame\n\n\n\ndata_raw &lt;- data_import |&gt;\n  rename(Trial = trial, Procedure = List,\n         Condition = COND, Correct_Response = Ans) |&gt;\n  filter(Procedure != \"inst\")\n\nView the Data Frame tab to see the resulting data frames\n\n\nUse the small arrow ▸ at the end of the column names to see more columns"
  },
  {
    "objectID": "lectures/lectures-class-5.html#add-and-modify-columns",
    "href": "lectures/lectures-class-5.html#add-and-modify-columns",
    "title": "Class 5: Data Preparation",
    "section": "Add and Modify Columns",
    "text": "Add and Modify Columns\nThis is where most of the work will be done for data preparation. Some common problems with messy raw data files:\n\nValues in columns don’t make sense and/or require understanding how the program was setup\nThe same information is contained across different columns BUT in different rows\nMissing columns that should be there\n\n\nValues in columns don’t make sense\nIn this sample data:\n\nThe Trial number continues across practice prac and real task trials\nCondition has values of 0 and 1. What do 0 and 1 mean???\nProcedure has values that can be more clear (don’t abbreviate!)\nColumns with .resp and Correct Response contain values that do not make sense (we will deal with this later though). What do 5 and 6 mean???\n\nFor the Trial number we will use a combination of mutate(.by = ) and dplyr::row_number()\n\nCodeData Frame\n\n\n\ndata_raw &lt;- data_import |&gt;\n  rename(Trial = trial, Procedure = List,\n         Condition = COND, Correct_Response = Ans) |&gt;\n  filter(Procedure != \"inst\") |&gt;\n  mutate(.by = c(ID, Procedure),\n         Trial = row_number())\n\nView the Data Frame tab to see the resulting data frames\n\n\nUse the small arrow ▸ at the end of the column names to see more columns\n\n\n\n  \n\n\n\n\n\n\nFor the other ones we can use a combination of mutate() and case_when():\n\nCodeData Frame\n\n\n\ndata_raw &lt;- data_import |&gt;\n  rename(Trial = trial, Procedure = List,\n         Condition = COND, Correct_Response = Ans) |&gt;\n  filter(Procedure != \"inst\") |&gt;\n  mutate(.by = c(ID, Procedure),\n         Trial = row_number()) |&gt;\n  mutate(Condition = case_when(Condition == 0 ~ \"word_match\",\n                               Condition == 1 ~ \"word_mismatch\"),\n         Procedure = case_when(Procedure == \"prac\" ~ \"practice\",\n                               Procedure == \"task\" ~ \"real\"),\n         Correct_Response = case_when(Correct_Response == 5 ~ \"yes\",\n                                      Correct_Response == 6 ~ \"no\"))\n\nView the Data Frame tab to see the resulting data frames\n\n\nUse the small arrow ▸ at the end of the column names to see more columns\n\n\n\n  \n\n\n\n\n\n\nI haven’t even told you anything about the task that generated this data (I am making this up as I go so I don’t know either), yet it is already easier to understand what kind of data it contains.\n\n\nCombine information across columns\nYou can probably guess that the data contained in slide1.resp and slide2.resp contains the same information about what response was made. But one is for practice trials and the other for real trials. This should just be combined in one column. Same thing with slide1.rt and slide2.rt.\nThere is a convenient function to do this, dplyr::coalesce()\n\nCodeData Frame\n\n\n\ndata_raw &lt;- data_import |&gt;\n  rename(Trial = trial, Procedure = List,\n         Condition = COND, Correct_Response = Ans) |&gt;\n  filter(Procedure != \"inst\") |&gt;\n  mutate(.by = c(ID, Procedure),\n         Trial = row_number()) |&gt;\n  mutate(Condition = case_when(Condition == 0 ~ \"word_match\",\n                               Condition == 1 ~ \"word_mismatch\"),\n         Procedure = case_when(Procedure == \"prac\" ~ \"practice\",\n                               Procedure == \"task\" ~ \"real\"),\n         Correct_Response = case_when(Correct_Response == 5 ~ \"yes\",\n                                      Correct_Response == 6 ~ \"no\"),\n         Response = coalesce(slide1.resp, slide2.resp),\n         Response = case_when(Response == 5 ~ \"yes\",\n                              Response == 6 ~ \"no\"),\n         RT = coalesce(slide1.rt, slide2.rt))\n\nView the Data Frames tab to see the resulting data frames\n\n\nUse the small arrow ▸ at the end of the column names to see more columns\n\n\n\n  \n\n\n\n\n\n\n\n\nAdd additional columns\nYou may have noticed that there is no column corresponding to accuracy. We have Response and Correct_Response information so we can create a new column for Accuracy\n\nCodeData Frame\n\n\n\ndata_raw &lt;- data_import |&gt;\n  rename(Trial = trial, Procedure = List,\n         Condition = COND, Correct_Response = Ans) |&gt;\n  filter(Procedure != \"inst\") |&gt;\n  mutate(.by = c(ID, Procedure),\n         Trial = row_number()) |&gt;\n  mutate(Condition = case_when(Condition == 0 ~ \"word_match\",\n                               Condition == 1 ~ \"word_mismatch\"),\n         Procedure = case_when(Procedure == \"prac\" ~ \"practice\",\n                               Procedure == \"task\" ~ \"real\"),\n         Correct_Response = case_when(Correct_Response == 5 ~ \"yes\",\n                                      Correct_Response == 6 ~ \"no\"),\n         Response = coalesce(slide1.resp, slide2.resp),\n         Response = case_when(Response == 5 ~ \"yes\",\n                              Response == 6 ~ \"no\"),\n         RT = coalesce(slide1.rt, slide2.rt),\n         Accuracy = case_when(Response == Correct_Response ~ 1,\n                              Response != Correct_Response ~ 0))\n\nView the Data Frame tab to see the resulting data frames\n\n\nUse the small arrow ▸ at the end of the column names to see more columns"
  },
  {
    "objectID": "lectures/lectures-class-5.html#remove-columns",
    "href": "lectures/lectures-class-5.html#remove-columns",
    "title": "Class 5: Data Preparation",
    "section": "Remove Columns",
    "text": "Remove Columns\nFinally, we can remove and reorder columns using select():\n\ndata_raw &lt;- data_import |&gt;\n  rename(Trial = trial, Procedure = List,\n         Condition = COND, Correct_Response = Ans) |&gt;\n  filter(Procedure != \"inst\") |&gt;\n  mutate(.by = c(ID, Procedure),\n         Trial = row_number()) |&gt;\n  mutate(Condition = case_when(Condition == 0 ~ \"word_match\",\n                               Condition == 1 ~ \"word_mismatch\"),\n         Procedure = case_when(Procedure == \"prac\" ~ \"practice\",\n                               Procedure == \"task\" ~ \"real\"),\n         Correct_Response = case_when(Correct_Response == 5 ~ \"yes\",\n                                      Correct_Response == 6 ~ \"no\"),\n         Response = coalesce(slide1.resp, slide2.resp),\n         Response = case_when(Response == 5 ~ \"yes\",\n                              Response == 6 ~ \"no\"),\n         RT = coalesce(slide1.rt, slide2.rt),\n         Accuracy = case_when(Response == Correct_Response ~ 1,\n                              Response != Correct_Response ~ 0)) |&gt;\n  select(ID, Procedure, Trial, Condition, Response, \n         Correct_Response, Accuracy, RT)\n\nWe now end up with a tidy raw data frame!\n\nTidyMessy\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nYou can see that this data frame is much easier to understand and to work with. Someone outside of your project would have a decent understanding of what information is contained and what is being measured.\nYou need to have your data in this type of format as it will be easier for you to start thinking about scoring and analyzing your data"
  },
  {
    "objectID": "lectures/lectures-class-7.html",
    "href": "lectures/lectures-class-7.html",
    "title": "Class 7: Quarto Documents",
    "section": "",
    "text": "Quarto documents are a versatile way to create production quality articles, presentations, dashboards, websites, blogs, and books in HTML, PDF, MS Word, ePub, and more. In fact, this R Workshop was created using Quarto documents.\nIn this class, you will learn how to use Quarto documents to create an HTML report that contains data visualizations and statistical analyses. View a sample report to see an example of this kind of document.\nR Scripts vs. Quarto Documents\nTo open a Quarto document:\nThere are three types of content that form the structure of a Quarto document."
  },
  {
    "objectID": "lectures/lectures-class-7.html#yaml-header",
    "href": "lectures/lectures-class-7.html#yaml-header",
    "title": "Class 7: Quarto Documents",
    "section": "YAML Header",
    "text": "YAML Header\nThe YAML header contains metadata about how the document should be rendered and the output format. It is located at the very top of the document and is surrounded by lines of three dashes.\n---\ntitle: \"Title of document\"\noutput: html_document\n---\nThere are various metadata options you can specify, such as if you want to include a table of contents. To learn about a few of them see the documentation here.\nGo ahead and include the output: html_document line in the YAML of the empty document you opened."
  },
  {
    "objectID": "lectures/lectures-class-7.html#markdown-text",
    "href": "lectures/lectures-class-7.html#markdown-text",
    "title": "Class 7: Quarto Documents",
    "section": "Markdown Text",
    "text": "Markdown Text\nThe markdown text section is just as if you were writing content in Microsoft Word or Google Docs. You can write up paragraphs of text, create bullet or numbered lists, embed images or web links, create tables, and more.\nThe text is formatted using a language known as Markdown. Markdown is a convenient and flexible way to format text. When a Markdown document is rendered into some output (such as HTML or PDF), the text will be formatted as specified by Markdown syntax.\nThere are a lot of guides on how to use Markdown syntax. I will not cover this so you should check them out on your own. Here is one I reference often: Markdown Cheatsheet\nAdd some markdown text below the YAML header in your open Quarto document\nHere is some sample text with a numbered list\n\n1. This is first\n2. Second\n3. Third"
  },
  {
    "objectID": "lectures/lectures-class-7.html#r-code-chunks",
    "href": "lectures/lectures-class-7.html#r-code-chunks",
    "title": "Class 7: Quarto Documents",
    "section": "R Code Chunks",
    "text": "R Code Chunks\nA Quarto document (.qmd) is a mixture of markdown text and R code chunks.\n\nCreate an R code chunk\nR code chunks are enclosed with\n```{r}\n\n```\nOr might look like:\n\n{r}\n\na &lt;- 1 + 6\n\nYou can create R code chunks with the shortcut:\n\nMac: ⌘ ⌥ i (command + alt/opt + i)\nWindows: ⌃ ⌥ i (ctrl + alt + i)\n\nOr in the toolbar of the Quarto document (same section area as Source and Visual)\n\nInsert -&gt; Excecutable Cell -&gt; R\n\n\nNotice that there are a lot of other options to Insert all sorts of other content like Figure/Image…\nInsert the following code in the R code chunk\n\nlibrary(palmerpenguins)\n\nhead(penguins)\n\nCreate another R code chunk with the following code\n\nlibrary(ggplot2)\n\nggplot(penguins, aes(species, body_mass_g, color = species)) +\n  geom_jitter(alpha = .7, width = .05, color = \"gray\") +\n  geom_point(stat = \"summary\", fun = mean, na.rm = TRUE, size = 3) +\n  geom_errorbar(stat = \"summary\", fun.data = mean_cl_normal, na.rm = TRUE,\n                width = .2) +\n  scale_color_brewer(palette = \"Set1\", label = \"none\") +\n  guides(color = \"none\") +\n  labs(title = \"Body Mass of Penguin Species\", \n       x = \"Species\", y = \"Body Mass (g)\") +\n  theme_classic()\n\n\n\nExecute R code chunk\nTo run chunks of R code you can click on the green “play” button on the top right of the R code chunk.\n\nGo ahead and do so. You can see that the results of the R code chunks are now displayed in the document."
  },
  {
    "objectID": "lectures/lectures-class-7.html#visual-editor",
    "href": "lectures/lectures-class-7.html#visual-editor",
    "title": "Class 7: Quarto Documents",
    "section": "Visual Editor",
    "text": "Visual Editor\nBy default, Quarto will open a new document in the visual editor mode.){taget=“_blank”}. The Quarto visual editor provides a WYSIWYM editing interface.\nIn Source mode, you will see the raw markdown and code elements. On occassion you may find that it is easier to edit a document in Source mode rather than with the Visual editor. You can switch back and forth between the two easily at the top-left of the toolbar"
  },
  {
    "objectID": "lectures/lectures-class-7.html#render-document",
    "href": "lectures/lectures-class-7.html#render-document",
    "title": "Class 7: Quarto Documents",
    "section": "Render Document",
    "text": "Render Document\nWhen you have finalized the content of a Quarto document you will then want to generate the document into the specified output format (e.g., HTML).\nTo render a Quarto document click on Render at the top. This will\n\nGenerate a preview of the document in the Viewer pane\nCreate an HTML file\n\nGo ahead and render the document you just created. Find the generated HTML file and open it. You will notice that it will open in your default web browser.\nThere are some advantages to using an HTML format:\n\nEasily shareable, anyone can open it in a web browser (does not require some other application that might cost money like Microsoft Word)\nCan include elements like\n\nTable of contents\nTabs - can include a lot more content without taking up a lot of space and saves on scrolling through large documents\nCode folding - code chunks can be toggled to hide/show them\nCode download - link to download the Quarto document\nCSS styling\nand more\n\n\nLet’s take a look at some of these elements and more"
  },
  {
    "objectID": "lectures/lectures-class-7.html#additional-elements",
    "href": "lectures/lectures-class-7.html#additional-elements",
    "title": "Class 7: Quarto Documents",
    "section": "Additional Elements",
    "text": "Additional Elements\n\nHeaders\nHeaders are a great way to organize the content in a Quarto document. Use # to create different header levels:\n# This is a level 1 header\n\n## A level 2 header\n\n### And level 3 header\nHeaders become even more useful with a table of contents and using tabs\n\n\nTable of Contents\nA table of contents is useful to navigate longer documents. It also provides an outline for the viewer to understand the document. You can specify the table of contents layout in the YAML header:\nformat:\n  html:\n    toc: true\n    toc-depth: 1\n    toc-location: left\ntoc-depth will change how many header levels are displayed in the table of contents (toc).\n\n\nTabs\nTabs are a great way to add a lot of content while avoiding having to scroll endlessly through a large document. The syntax for a tabset is\n::: panel-tabset\n## First tab\n\nHere is some content\n\n## A second tab\n\nMore content!\n\n## And third tab\n\nHello!\n:::\nThe second level headers will be used to label the tabs in the document (see below)\nYou can also add multiple tabs easily by going to\n\nInsert -&gt; Tabset…\n\nTabs look like this:\n\nFirst tabA second tabAnd third tab\n\n\nHere is some content\n\n\nMore content!\n\n\nHello!\n\n\n\n\n\nCode Tools\nYou can include a Code menu in the header of your document that provides various tools for readers to interact with the source code. Specify in the YAML\ncode-tools: true\n\n\nCode Folding\nYou may not always want to show the R code chunks in the HTML output. Or you might want to give the viewer a choice to show/hide R code chunks. You can specify code folding in the top-level YAML header or in each code chunk individually\ncode-fold: true\n\n\n\nValue\nBehavior\n\n\n\n\nfalse\nNo folding (default)\n\n\ntrue\nFold code (initially hidden)\n\n\nshow\nFold code (initially shown)\n\n\n\n\n\nR Chunk Options\nSome settings you can change for individual R code chunks. The syntax to do this uses #| in the R code chunk:\n\n\nHide the code!\n```{r}\n#| eval: false\n#| warning: false\n#| message: false\n#| code-fold: show\n#| code-summary: \"Hide the code!\"\n\n1 + 1\n```\n\n\nSome commone ones to change are:\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nEvaluate the code chunk (if false, just echos the code into the output).\n\n\necho\nInclude the source code in output\n\n\noutput\nInclude the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\n\n\nwarning\nInclude warnings in the output.\n\n\nerror\nInclude errors in the output (note that this implies that errors executing code will not halt processing of the document).\n\n\ninclude\nCatch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\n\nSee the Quarto Documentation for more details\n\n\nCSS Styling\nYou can also add CSS styling, either as a separate .css document or at the end of the Quarto document.\nFor instance, I used the following styling options in the sample report:\n\n.tab-content {\n  border-style: none;\n}\n\nh1 {\n  color: #005098;\n}\n\nh2 {\n  color: #96834a !important;\n  font-weight: 600 !important;\n}\n\na {\n  color: #005098;\n}\n\na:hover {\n  color: #96834a !important;\n}\n\n.quarto-title-meta-heading {\n  color: #96834a;\n  font-weight: 600 !important;\n}\n\n.sidebar nav[role=doc-toc] ul&gt;li&gt;a, .sidebar nav[role=doc-toc] ul&gt;li&gt;ul&gt;li&gt;a {\n  color: #005098 !important;\n  border-left: 2px solid #ECE5D7;\n  border-left-color: solid #ECE5D7;\n}\n\n.sidebar nav[role=doc-toc] ul&gt;li&gt;a.active, .sidebar nav[role=doc-toc] ul&gt;li&gt;ul&gt;li&gt;a.active {\n  color: #005098 !important;\n  font-weight: 600;\n  border-left: 2px solid #CBB879;\n  border-left-color: solid #CBB879;\n}\n\n.sidebar nav[role=doc-toc] ul&gt;li&gt;a:hover, .sidebar nav[role=doc-toc] ul&gt;li&gt;ul&gt;li&gt;a:hover {\n  color: #005098 !important;\n  font-weight: 600;\n  border-left: 2px solid #CBB879;\n  border-left-color: solid #CBB879;\n}\n\n.nav-link {\n  color: #495057;\n}\n\n.nav-tabs .nav-link.active, .nav-tabs .nav-item.show .nav-link {\n  color: #96834a !important;\n}\n\n.code-tools-button {\n  color: #96834a !important;\n}\n\n.dropdown-toggle {\n  color: #005098 !important;\n}"
  },
  {
    "objectID": "lectures/lectures-class-2.html",
    "href": "lectures/lectures-class-2.html",
    "title": "Class 2: Importing, Merging, and Restructuring Data",
    "section": "",
    "text": "We will cover importing data, merging data frames, and restructuring data in this class."
  },
  {
    "objectID": "lectures/lectures-class-2.html#pipe-operator",
    "href": "lectures/lectures-class-2.html#pipe-operator",
    "title": "Class 2: Importing, Merging, and Restructuring Data",
    "section": "Pipe Operator",
    "text": "Pipe Operator\nFirst, however, we need to talk about the pipe operator |&gt; .\nThere are actually two pipe operators now. The original dplyr pipe operator, %&gt;% , and the newer base R pipe operator, |&gt; . You can use either one.\nThe pipe operator allows you to chain together a set of functions to conduct a sequence of manipulations on it. Conceptually, here’s what code written using the pipe operator looks like\n\ndata |&gt;\n  step1 |&gt;\n  step2 |&gt;\n  step3\n\nWe start with our data. Then we do step1. Then we do step2. Then we do step3. The pipe ties it all together, enabling us to do multiple things to our data, all in one execution of code.\nThere are different approaches to writing code that performs multiple functions on the same object. Here is the standard, non-pipe operator way:\n\n# three steps: filter, calculate a mean, then select only some columns to keep\ndata_new &lt;- filter(data, y != \"c\")\ndata_new &lt;- mutate(data_new, x_mean = mean(x))\ndata_new &lt;- select(data_new, y, x_mean)\n\nAn alternative is to use the pipe operator |&gt;\n\n# three steps: filter, calculate a mean, then select only some columns to keep\ndata_new &lt;- data |&gt;\n  filter(y != \"c\") |&gt;\n  mutate(x_mean = mean(x)) |&gt;\n  select(y, x_mean)\n\nWith the pipe operator, the result of the previous line gets passed (or piped) onto the next function. The first line in this example is simply specifying the data frame that is being passed from one line to the next. Notice how I did not have to specify data inside the filter(), mutate(), and select(), functions. This makes the code more concise and easier to read. The end result of the last function, then gets assigned to data_new &lt;-."
  },
  {
    "objectID": "lectures/lectures-class-2.html#import",
    "href": "lectures/lectures-class-2.html#import",
    "title": "Class 2: Importing, Merging, and Restructuring Data",
    "section": "Import",
    "text": "Import\nR needs to know the full file path to the file on your computer in order to import it - this is what is referred to as an absolute file path. Absolute file paths start at the root directory of your computer and might look something like:\nOn Macs:\nUsers/username/projects/project_name/a_file.csv\nOn Windows:\nC:\\username\\projects\\project_name\\a_file.csv\n\nWhat if you don’t know the full absolute file path to your data?\nI want to point out three approaches to specifying file paths in R:\n\nUse setwd()\nUse the RStudio Import Dataset GUI\nUse RProjects and here()\n\nNever… ever… ever… use option 1, setwd().\nInstead, you should use RProjects and here(). But we will not cover this until Class 5. For now, we can just use the RStudio Import Dataset GUI to find the absolute file path.\n\nRStudio GUI\nWhen you are having difficulty importing a file correctly or unsure of the file format the RStudio Import Dataset GUI can be really useful.\nIn the Environment window click on “Import Dataset”. You will see several options available, these options all rely on different packages. For now, select the From Text (readr)… option.\nYou will see a data import window open up that looks like this\n\n\n\nRStudio Import Dataset GUI\n\n\n\nSelect Browse on the top right and select the data file you want to import.\nThe Data Preview window will let you see if it is importing it in the right format. You can change the Import Options below.\nClick on the 📋 icon above the Code Preview window to copy the code.\nClick on Cancel to exit out of the Import GUI window\nPaste the code into your Untitled.R script\n\nThe most useful thing here will be the absolute file path.\n\n\n\n\n\n\n\n\nExploring Your Data\n\n\n\nWhen you want to just explore some data and don’t care about creating a reproducible script it can be perfectly acceptable to not copy and paste the code from Code Preview window and just select the Import button.\n\n\n\n\nCSV Files\ncsv files are by far the easiest files to import into R and most software programs. For this reason, I suggest any time you want to save/output a data file to your computer, do it in csv format.\nCSV stands for “Comma-Separated Values.” It’s a simple file format used to store data in a table. Each line in the file is a row of the table, and commas are used to separate columns. Think of it like a spreadsheet where each piece of information is lined up in rows and columns, but instead of seeing the grid like in Excel, each row is just a line of text with commas between the values that would go into different columns.\ncsv files are typically saved with .csv file extension (e.g., data file.csv)\nTo import a csv file you can use read_csv() from the readr package.\n\nlibrary(readr)\n\ndata_import &lt;- read_csv(\"filepath/datafile.csv\")\n\n\n\nTab-Delimited Files\ntab-delimited files are a little more tedious to import just because they require specifying more arguments. Which means you have to memorize more to import tab-delimited files.\nTab-delimited files use tabs between items in a row to separate columns. In general, the delimiter is the type of value that is used between items in a row to separate columns. There are a lot of different types of delimiters with tab and comma (csv) being the most common.\nTab-delimited files are typically saved with the more standard .txt file extension (e.g., data file.txt) but a lot of other file formats might also have the .txt extension. This can create some ambiguity as to how the data is stored and formatted for .txt files.\nTo import a tab-delimited file you can use read_delim() from the readr package.\n\ndata_import &lt;- read_delim(\"filepath/datafile.txt\", delim = \"\\t\", \n                     escape_double = FALSE, trim_ws = TRUE)\n\nThere are three additional arguments we have to specify: delim, escape_double, and trim_ws. The notation for tab-delimted files is \"\\t\". I always forget how to specify each of these arguments so I frequently use the RStudio Import Dataset GUI to copy the code needed to import a tab-delimited file."
  },
  {
    "objectID": "lectures/lectures-class-2.html#merge",
    "href": "lectures/lectures-class-2.html#merge",
    "title": "Class 2: Importing, Merging, and Restructuring Data",
    "section": "Merge",
    "text": "Merge\nYou might find yourself in a situation where you need to import multiple data files and merge them into a single data frame. There are two general classes of merging data\n\nBind\nJoin\n\n\nBind\nIn R, a “bind” is combining data frames together by stacking either the rows or columns.\nA row “bind” takes data frames that have the same columns but different rows and stacks them on top of each other. This will happen if you have separate data files for each subject from the same task. Each subject data file will have their unique rows but all subjects will have the same columns.\n\n\n\nIllustration of a row bind\n\n\nA column “bind” takes data frames that have the same rows but different columns and stacks them side-by-side. This is a much less common situation than a row bind and can usually be accomplished with a join instead.\nRow and column binds can be performed with bind_rows() and bind_cols() from the dplyr package\n\nlibrary(dplyr)\n\ndata_merged &lt;- bind_rows(data_1, data_2)\ndata_merged &lt;- bind_cols(data_1, data_2)\n\n\n\nJoin\nIn R, a “join” is merging data frames together that have at least one column in common with a mix of shared and unique entries in that column (e.g. Subject IDs).\nThere are lots of different kinds of joins, some of which are:\n\n\n\nTypes of joins using dplyr\n\n\nFor a full list and detailed description of the _join() functions see the dplyr documentation\nBut for the most part you can get away with just knowing how to do a full join using full_join() from the dplyr package.\n\ndata_merged &lt;- full_join(data_1, data_2, by = \"Subject\")\n\nWhenever joining, you need to specify what are the key column(s) to join by - columns that are common between the data frames. Often times there is more than one key column that the data frames need to be joined by:\n\ndata_merged &lt;- full_join(data_1, data_2, by = c(\"Subject\", \"Session\"))"
  },
  {
    "objectID": "lectures/lectures-class-2.html#restructure",
    "href": "lectures/lectures-class-2.html#restructure",
    "title": "Class 2: Importing, Merging, and Restructuring Data",
    "section": "Restructure",
    "text": "Restructure\nThe exact same data can be structured in different ways. There are two main formats that any data set can be structured as:\nWide: Variables are spread out across columns, making the data frame wider\n\n\n\n\n\n\n\n\n\nParticipant ID\nStress Level Score\nCreativity Score\nMemory Score\n\n\n\n\n1\n5\n7\n8\n\n\n2\n3\n6\n7\n\n\n3\n4\n8\n6\n\n\n\n \nLong: Variables and values are spread across rows, making the data frame longer\n\n\n\nParticipant ID\nTest Type\nScore\n\n\n\n\n1\nStress Level\n5\n\n\n1\nCreativity\n7\n\n\n1\nMemory\n8\n\n\n2\nStress Level\n3\n\n\n2\nCreativity\n6\n\n\n2\nMemory\n7\n\n\n3\nStress Level\n4\n\n\n3\nCreativity\n8\n\n\n3\nMemory\n6\n\n\n\n \nAnd actually, you can have a mix of wide and long formatted data in a single data frame.\n\n\n\n\n\n\n\n\n\n\nParticipant ID\nSession\nStress Level\nCreativity\nMemory\n\n\n\n\n1\n1\n5\n7\n8\n\n\n1\n2\n4\n8\n9\n\n\n1\n3\n3\n9\n10\n\n\n2\n1\n6\n6\n7\n\n\n2\n2\n5\n7\n8\n\n\n2\n3\n4\n8\n9\n\n\n3\n1\n4\n8\n6\n\n\n3\n2\n3\n9\n7\n\n\n3\n3\n2\n10\n8\n\n\n\nSession is in long format with values stacked in rows. Stress, creativity, and memory are all in wide format.\nA good rule of thumb for formatting data is to have your variables (IVs and DVs) each have their own column.\n\nNotice that this is not the case in the long formatted data above. Test Type and Score are not variables in this study. Rather Stress, Creativity, and Memory are. Therefore, it makes more sense to have that data in a wide format.\nThis often results in:\n\nMeasured variables in wide format\nExperimental conditions or repeated-measures in long format\n\nNotice how Session, a within-subject variable, is in long format because Session is an independent variable in the study, so Session needs it’s own column. Stress, Creativity, and Memory are other variables (probably dependent variables) in this study and so they need their own columns, therefore they are laid out in a wide format.\n\nRestructuring data involves changing the structure from long-to-wide (wider) or wide-to-long (longer). The tidyr package provides useful functions to do this:\n\npivot_wider() “widens” data from long-to-wide\npivot_longer() “lengthens” data from wide-to-long\n\nThe tidyr package, like readr and dplyr, is from the tidyverse set of packages.\n\nPivot Wider\nUsing the example data sets above, let’s restructure the long data frame to a wide format:\nFirst let’s create the data frame - you can just copy and paste this code\n\ndata_long &lt;- data.frame(\n  ParticipantID = rep(1:3, each = 3),\n  TestType = rep(c(\"Stress Level\", \"Creativity\", \"Memory\"), times = 3),\n  Score = c(5, 7, 8, 3, 6, 7, 4, 8, 6)\n  )\n\nThe two main arguments to specify in pivot_wider() are\n\nnames_from: The column name that contains the variables to create new columns by (e.g. “Test Type”). The values in this column will become Column names in the wider data format.\nvalues_from: The column name that contains the values (e.g. “Score”).\n\nNow we can use pivot_wider() to convert it to a wide format:\n\nlibrary(tidyr)\n\ndata_wide &lt;- data_long |&gt;\n  pivot_wider(names_from = TestType,\n              values_from = Score)\n\n\n\n\n\n\n\nColumn Names\n\n\n\nR does not like column names to have spaces in them, but it does allow it.\nNotice how in data_wide the column Stress Level contains a space. This is because the value in data_long had a space, which was not a problem then.\nclean_names() from the janitor package provides a convenient way to get rid of spaces and replace them with an _\n\nlibrary(janitor)\n\ndata_wide_clean &lt;- clean_names(data_wide, case = \"parse\")\n\n\n\n\n\nPivot Longer\nThe three main arguments to specify in pivot_longer() are:\n\ncols: The column names that will be restructured to a longer format\nnames_to: The new column name that will contain values which correspond to the column names in the wide data\nvalues_to: The new column name that will contain the actual values in the wide data\n\nUsing pivot_longer() we can restructure the data back to long format\n\ndata_long_again &lt;- data_wide |&gt;\n  pivot_longer(cols = any_of(c(\"Stress Level\", \"Creativity\", \"Memory\")),\n               names_to = \"TestType\",\n               values_to = \"Score\")\n\nCheck to make sure data_long and data_long_again are identical.\nOkay, now let’s say we have a wide data set with multiple sessions of Stress , Creativity, and Memory.\n\ndata_sessions_wide &lt;- tibble(\n  ParticipantID = 1:3,\n  StressLevel_S1 = c(5, 6, 4),\n  Creativity_S1 = c(7, 6, 8),\n  Memory_S1 = c(8, 7, 6),\n  StressLevel_S2 = c(4, 5, 3),\n  Creativity_S2 = c(8, 7, 9),\n  Memory_S2 = c(9, 8, 7),\n  StressLevel_S3 = c(3, 4, 2),\n  Creativity_S3 = c(9, 8, 10),\n  Memory_S3 = c(10, 9, 8)\n)\n\nThe data is not very useful in this format, so let’s restructure it to be a mix of long and wide format. Using the rule of thumb above, we want to create 4 columns with Session, Stress Level, Creativity, and Memory. There are two strategies for doing this:\n\nUsing pivot_longer(), separate(), and then pivot_wider()\nUse more complicated syntax in pivot_longer()\n\n\n# 1. Using pivot_longer(), separate(), and then pivot_wider()\ndata_sessions_1 &lt;- data_sessions_wide |&gt;\n  pivot_longer(cols = contains(\"_S\"),\n               names_to = \"Session\",\n               values_to = \"Score\") |&gt;\n  separate(Session, into = c(\"Test\", \"Session\")) |&gt;\n  pivot_wider(names_from = Test,\n              values_from = Score)\n\n# 2. Use more complicated syntax in pivot_longer()\ndata_sessions_2 &lt;- data_sessions_wide |&gt;\n  pivot_longer(cols = contains(\"_S\"),\n               names_to = c(\".value\", \"Session\"),\n               names_pattern = \"(.*)_(S\\\\d)\")\n\nYou may find yourself in a situation where you need to select multiple columns in a argument but it can be tedious to type each every column, especially if the number of columns is larger.\nThere are what is known as tidy select functions to easily select column names, particularly if there is a consistent pattern to those column names.\nThis can be very useful in functions like pivot_longer(). In the examples provided on above, we used some tidy select functions: any_of() and contains().\nTo learn more about what tidy select functions are available and what they do read the tidy select documentation.\n\n✏️ Start Learning Activity -&gt;"
  },
  {
    "objectID": "lectures/lectures-class-8.html",
    "href": "lectures/lectures-class-8.html",
    "title": "Class 8: Data Visualization",
    "section": "",
    "text": "Data visualization is an essential skill for anyone working with data and requires a combination of design principles with statistical understanding. In general there are two purposes for needing to graphically visualize data:"
  },
  {
    "objectID": "lectures/lectures-class-8.html#ggplot2",
    "href": "lectures/lectures-class-8.html#ggplot2",
    "title": "Class 8: Data Visualization",
    "section": "ggplot2",
    "text": "ggplot2\nIn this class, we will learn about the fundamentals of data visualization using the ggplot2 package. This is by far the most popular package for data visualization in R.\n\nYou have already seen and used ggplot2 in previous classes, but now we will cover how to actually use this package. The elements for creating a ggplot was largely inspired from the work of Leland Wilkinson (Grammar of Graphics, 1999), who formalized two main principles in plotting data:\n\nLayering: The idea of layering involves building plots by adding different layers of grammatical elements. Each layer can consist of components such as points, lines, bars, etc., and can be combined to create complex plots.\nMapping: This principle involves mapping variables in your data to aesthetic properties of the graphical objects, such as size, shape, color, position, and the scales on the x and y axes.\n\nIn this framework, the essential grammatical elements required to create any data visualization are:\n\nLet’s take a look at how these elements work to create a simple visualization of data. In Class 1 I introduced you to the fun palmerpenguins data set. I will use this data set to illustrate how ggplot2 works.\n\n\n\n\n\nGo ahead and load the palmerpenguins and ggplot2 packages using library() . Additionally, let’s make the penguins data set that is loaded with palmerpenguins visible in the environment by explicitly assigning it to an object.\n\npenguins &lt;- penguins"
  },
  {
    "objectID": "lectures/lectures-class-8.html#data-layer",
    "href": "lectures/lectures-class-8.html#data-layer",
    "title": "Class 8: Data Visualization",
    "section": "Data layer",
    "text": "Data layer\nThe Data Layer specifies the data object that is being plotted.\n\nIt is the first grammatical element that is required to create a plot:\n\nggplot(data = penguins)\n\n\n\n\n\n\n\n\nYou can see that we only have a blank square. This is because we have not added any other layers yet, we have only specified the data layer. ggplot() doesn’t yet know how to map the variables onto the axis scales. That is where the aesthetic mapping layer comes in."
  },
  {
    "objectID": "lectures/lectures-class-8.html#aesthetics-layer",
    "href": "lectures/lectures-class-8.html#aesthetics-layer",
    "title": "Class 8: Data Visualization",
    "section": "Aesthetics Layer",
    "text": "Aesthetics Layer\nThe next grammatical element is the aesthetic layer, or aes for short. This layer specifies how we want to map our data onto the scales of the plot.\n\nThe aesthetic layer maps variables in our data onto scales in our graphical visualization, such as the x and y coordinates. In ggplot2 the aesthetic layer is specified using the aes() function. Let’s create a plot of the relationship between bill_length_mm and flipper_length_mm, putting them on the x and y axis respectively.\n\nggplot(penguins, \n       mapping = aes(x = bill_length_mm, y = flipper_length_mm))\n\n\n\n\n\n\n\n\nYou can see we went from a blank box to a graph with the variable and scales of bill_length_mm mapped onto the x-axis and flipper_length_mm on the y-axis.\nThe aesthetic layer also maps variables in our data to other elements in our graphical visualization, such as color, size, fill, etc. These other elements are useful for adding a third variable onto our graphical visualizations. For instance, we can add the variable of species by mapping species onto the color aesthetic.\n\nggplot(penguins, \n       mapping = aes(bill_length_mm, flipper_length_mm, color = species))\n\n\n\n\n\n\n\n\nYou will notice that the plot has not changed. Species is not plotted by color. This is because ggplot() does not know the geometrical form the data should take - a bar plot, line plot, dot plot, etc.? It cannot add color to a geometrical form that is not specified yet. That is where the geometries layer comes in."
  },
  {
    "objectID": "lectures/lectures-class-8.html#geometries-layer",
    "href": "lectures/lectures-class-8.html#geometries-layer",
    "title": "Class 8: Data Visualization",
    "section": "Geometries Layer",
    "text": "Geometries Layer\nThe next essential grammatical element for graphical visualization is the geometries layer or geom for short. This layer specifies the visual elements that should be used to plot the actual data.\n\nThere are a lot of different types of geoms to use in ggplot2. Some of the most commonly used ones are:\n\nPoints or jittered points: geom_point() or geom_jitter()\nLines: geom_line()\nBars: geom_bar()\nViolin: geom_violin()\nError bars: geom_errobar() or geom_ribbon()\n\nFor a full list see the ggplot2 documentation\n\nFor now, let’s demonstrate this using geom_point(). We will create what is called a scatterplot - plotting the individual data points for two continuous variables.\nTo create a scatterplot we can simply add geom_point() to our ggplot.\n\n\n\n\n\n\nNote\n\n\n\nNote that in ggplot2 there is a special notation that is similar to the pipe operator |&gt; seen before. Except in ggplot2 you have to use a plus sign + .\n\n\n\nggplot(penguins, aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point()\n\n\n\n\n\n\n\n\nNote you can also specify the color = species aesthetic mapping on the geometric layer instead of the data layer:\n\nggplot(penguins, aes(bill_length_mm, flipper_length_mm)) +\n  geom_point(mapping = aes(color = species))\n\nBesides mapping variables in your data to certain aesthetics, you can change the aesthetic properties of geometrical elements. Common aesthetic properties include:\n\nColor related aesthetics\nSee more details here\n\nColor: applies to most geoms geom_(color = )\nFill: applies to most geoms geom_(fill = )\nTransparency: applies to most geoms. values can range from 0 to 1, 0 = transparent; 1 = opaque; geom_(alpha = )\n\nSee a full list of R colors here\n\n\nShape related aesthetics\nSee more details here\n\nShape: geom_point(shape = ), geom_jitter(shape = )\nSize: geom_point(size = ), geom_jitter(size = )\nLine Type: geom_line(linetype = )\nLine Width: geom_line(linewidth = )\nWidth: geom_errobar(width = ), geom_jitter(width = )\n\n\nggplot(penguins, \n       aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point(shape = \"diamond filled\", size = 3, fill = \"white\")\n\n\n\n\n\n\n\n\nBesides the data, aesthetics, and geometries layers, there are often other types of elements you may want to include."
  },
  {
    "objectID": "lectures/lectures-class-8.html#facets-layer",
    "href": "lectures/lectures-class-8.html#facets-layer",
    "title": "Class 8: Data Visualization",
    "section": "Facets Layer",
    "text": "Facets Layer\nThe facets layer allows you to create panels of subplots within the same graphic object\n\nThe previous three layers are the essential layers. The facet layer is not essential, but it can be useful when you want to communicate the relationship among 4 or more variables.\nLet’s create a facet layer of our scatterplot with different panels for sex\n\n# first let's remove any missing values for sex\nlibrary(dplyr)\npenguins &lt;- filter(penguins, !is.na(sex))\n\nggplot(penguins, \n       aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point() +\n  facet_grid(cols = vars(sex))\n\n\n\n\n\n\n\n\nYou can see we are now conveying information about 4 different variables in our data; bill_length_mm, flipper_length_mm, species, and sex .\nSee the ggplot2 documentation on facet_grid and facet_wrap"
  },
  {
    "objectID": "lectures/lectures-class-8.html#statistics-layer",
    "href": "lectures/lectures-class-8.html#statistics-layer",
    "title": "Class 8: Data Visualization",
    "section": "Statistics Layer",
    "text": "Statistics Layer\nThe statistics layer allows you plot aggregated statistical values calculated from your data\n\nThe statistics layer is used in combination with a geom to plot values that are a function (e.g., mean) of the values in your data. The two main stat functions are:\n\ngeom_(stat = \"summary\")\nstat_smooth()\n\n\ngeom_(stat = “summary”)\nIn the previous plots, we plotted the raw values for each individual penguin. However, statistics are often evaluated at the aggregate level (e.g., think mean differences between groups). We can calculate summary statistics inside inside of the geom functions using stat = \"summary\". There are two main arguments you need to specify:\n\nstat: set this to “summary” to calculate a summary statistic\nfun: The function used to calculate an aggregated summary statistic. Functions like mean, sum, min, max, sd can all be specified. You can then specify additional argument that should be passed into these functions as regular arguments in geom_()\n\nIn the penguins data set, we have the raw values of body_mass_g for each individual penguin but perhaps we are just interested in the average (mean) values for each species. This can be done easily using geom_point(stat = \"summary\", fun = mean)\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_point(stat = \"summary\", fun = mean, na.rm = TRUE,\n             shape = \"diamond\", size = 5, color = \"firebrick\")\n\n\n\n\n\n\n\n\nUsing multiple geoms you can plot both the raw values for each individual penguin and the summary statistic\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_jitter(width = .1, size = .75, alpha = .2) +\n  geom_point(stat = \"summary\", fun = mean, na.rm = TRUE,\n             shape = \"diamond\", size = 5, color = \"firebrick\")\n\n\n\n\n\n\n\n\nThe fun = argument returns only a single summary statistic value (e.g., a mean). However, some geoms actually require two values. For instance, when plotting errorbars you will need both ymin and ymax values returned. For these types of cases, you need to use the fun.data argument instead:\nmean_cl_normal is a function to calculate 95% confidence limits from your data.\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_jitter(width = .1, size = .75, alpha = .2) +\n  geom_point(stat = \"summary\", fun = mean, na.rm = TRUE,\n             shape = \"diamond\", size = 5, color = \"firebrick\") +\n  geom_errorbar(stat = \"summary\", fun.data = mean_cl_normal, width = .1)\n\n\n\n\n\n\n\n\n\n\nstat_smooth(method = “lm”)\nstat_smooth(method = \"lm\") is used in scatterplots to plot the regression line on your data.\n\nggplot(penguins, aes(x = bill_length_mm, y = flipper_length_mm)) +\n  geom_point() +\n  stat_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nYou can add separate regression lines if other variables are mapped to aesthetics and/or are wrapped in different facets\n\nggplot(penguins, \n       aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point() +\n  facet_grid(cols = vars(sex)) +\n  stat_smooth(method = \"lm\")"
  },
  {
    "objectID": "lectures/lectures-class-8.html#coordinates-layer",
    "href": "lectures/lectures-class-8.html#coordinates-layer",
    "title": "Class 8: Data Visualization",
    "section": "Coordinates Layer",
    "text": "Coordinates Layer\nThe coordinate layer allows you to adjust the x and y coordinates\n\nThere are two main groups of functions that are useful for adjusting the x and y coordinates.\n\ncoord_cartesian() for adjusting the axis limits (zoom in and out)\nscale_x_ and scale_y_ for setting the axis ticks and labels\n\n\naxis limits\nYou can adjust limits (min and max) of the x and y axes using the coord_cartesian(xlim = c(), ylim = c()) function.\n\n\n\n\n\n\nNote\n\n\n\nIf you want to compare two separate graphs, then they need to be on the same scale. This an important design principle in graphical visualization.\n\n\nCompare these two sets of plots\n\nmale &lt;- filter(penguins, sex == \"male\")\nfemale &lt;- filter(penguins, sex == \"female\")\n\np1 &lt;- ggplot(male, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(2000, 10000))\n\np2 &lt;- ggplot(female, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) + \n  coord_cartesian(ylim = c(3000, 5000))\n\n\n# patchwork can be used to combine multiple plots into one image\nlibrary(patchwork)\n\np1 + labs(title = \"male\") + p2 + labs(title = \"female\")\n\n\n\n\n\n\n\n\nA cursory look at this plot, you might conclude a couple things\n\nFemale Gentoo penguins have the largest body mass\nThere is a larger difference in body mass, relative to the other penguin species, for the Female Gentoo penguins than for Male Gentoo penguins.\n\nThese are both false! Take a closer look at the y-axis on the two plots. Let’s plot the exact same data but make the scales on the y-axis the same.\n\np1 &lt;- ggplot(male, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 6000)) +\n  labs(title = \"male\")\n\np2 &lt;- ggplot(female, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) + \n  coord_cartesian(ylim = c(3000, 6000)) +\n  labs(title = \"female\")\n\n\n# patchwork can be used to combine multiple plots into one image\nlibrary(patchwork)\n\np1 + labs(title = \"male\") + p2 + labs(title = \"female\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\npatchwork is a convenient package to combine multiple plots into one image. The package can be used to create a more complex arrangement of multiple plots but the simplest use of it is to add plots side-by-side by simply using the + notation that is already used to add additional layers to a ggplot()\n\nplot1 + plot2\n\n\n\n\n\naxis ticks and labels\nYou can adjust the scale (major and minor ticks) of the x and y axes using the scale_x_ and scale_y_ set of functions. The two main set of functions to know are for continuous and discrete scales:\n\ncontinuous: scale_x_continuous(breaks = seq()) and scale_y_continuous(breaks = seq())\ndiscrete: scale_x_discrete(breaks = seq()) and scale_y_continuous(breaks = seq())\n\nFor example:\n\np1 &lt;- ggplot(male, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 6000)) +\n  scale_y_continuous(breaks = seq(3000, 6000, by = 500))\n\np2 &lt;- ggplot(female, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) + \n  coord_cartesian(ylim = c(3000, 6000)) +\n  scale_y_continuous(breaks = seq(3000, 6000, by = 500))\n\n\np1 + labs(title = \"male\") + p2 + labs(title = \"female\")"
  },
  {
    "objectID": "lectures/lectures-class-8.html#theme-layer",
    "href": "lectures/lectures-class-8.html#theme-layer",
    "title": "Class 8: Data Visualization",
    "section": "Theme Layer",
    "text": "Theme Layer\nThe theme layer refers to visual elements that are not mapped to the data but controls the overall design, colors, and labels on the plot\n\nThere are three main set of functions that we can use to control the theme layer:\n\nColor: scale_color_ set of functions will change the color scheme of the geometric elements:\n\nscale_color_manual() - see documentation here\nscale_color_brewer() - see documentation here\n\nLabels: labs() is a convenient function for labeling the title, subtitle, axes, and legend\nTheme templates: There are predefined theme templates that come with ggplot2\nOther theme elements: theme() can be used to further customize the look of your plot\n\ntheme(legend.title = element_text(face = \"bold\"))\n\n\n\nColor\nChanging the color theme can get complicated but is an important design element in your plot.\nThe RColorBrewer package offers several color palettes for R:\n\n\n\nYou can access these palettes using scale_color_brewer(palette = \"palette name\")\n\nggplot(penguins, aes(species, body_mass_g, color = sex)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 6000)) +\n  scale_y_continuous(breaks = seq(3000, 6000, by = 500)) +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nCheck out the ggsci color palettes inspired by scientific journals, science fiction movies, and TV shows.\n\n\n\n\nLabels\nChanging labels and adding titles is easy using labs()\n\nggplot(penguins, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 6000)) +\n  scale_y_continuous(breaks = seq(3000, 6000, by = 500)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\")\n\n\n\n\n\n\n\n\nTo change labels for legends you need to refer to the aesthetic mapping that was defined in aes() (e.g., color, shape).\n\nadelie &lt;- filter(penguins, species != \"Gentoo\")\n\nggplot(adelie, aes(species, body_mass_g, \n                     color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\n\n\nTheme templates\nHere are some themes that come loaded with ggplot2\n\ntheme_bw()\ntheme_light()\ntheme_dark()\ntheme_minimal()\ntheme_classic()\ntheme_void()\n\nUsing a theme template is straightforward\n\nadelie &lt;- filter(penguins, species != \"Gentoo\")\n\nggplot(adelie, aes(species, body_mass_g, \n                     color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\nOther theme elements\nIn addition to using a pre-defined theme template, you may also want to tweak other design elements on your plot. You will mostly due this using theme()\nFor instance, to give the legend titles a bold face font:\n\nadelie &lt;- filter(penguins, species != \"Gentoo\")\n\nggplot(adelie, aes(species, body_mass_g, \n                     color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_classic() +\n  theme(legend.title = element_text(face = \"bold\"))\n\n\n\n\n\n\n\n\nHere is a list of different elements you can change. They are organized into text, line, and rectangle elements:\n\nText, line, and rectangle elements each have their corresponding element function e.g., element_text()\n\nObviously, there are a lot of different theme elements you can tweak and it is hard to memorize them all. Make use of Google, ggplot2 documentation, and Generative AI’s for assistance.\nHere is the ggplot2 documentation on theme elements\n\n\nCreate your own theme template\nOften times you may want to apply the same customized theme elements to multiple plots and even across multiple projects.\nOne convenient way of doing so is to use theme_set()\ntheme_set() will automatically apply the same theme settings across all ggplots created in a document.\nFor instance, if you want to make sure all your ggplots have a bolded legend title and use theme_classic() you can create a theme to do that:\n\nbold_legend &lt;- theme(legend.title = element_text(face = \"bold\"))\n\nplot_theme &lt;- theme_classic() + bold_legend\n\nThen you need to set the theme that will be applied across all ggplots\n\ntheme_set(plot_theme)\n\nNow any ggplots you create will be given this theme setting without you having to include it in the actual ggplot.\n\nggplot(adelie, aes(species, body_mass_g, \n                     color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\")\n\n\n\n\n\n\n\n\nYou can also create theme functions to give you more flexibility from one document/project to another (change the font size, whether to use “bold” fonts for titles or not, etc.).\nHere is a custom theme I made. One of the things it does is increases the amount of white space betwen plot elements, such as the axis labels and the axis ticks (it annoys me how close the y-axis label is to the axis tick labels by default).\n\n\nShow theme_spacious()\ntheme_spacious &lt;- function(font_size = 14, bold = TRUE) {\n  key_size &lt;- trunc(font_size * .8)\n  if (bold == TRUE) {\n    face.type &lt;- \"bold\"\n  } else {\n    face.type &lt;- \"plain\"\n  }\n\n  theme(text = element_text(size = font_size),\n        axis.title.x = element_text(margin = margin(t = 15, r = 0,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        axis.title.y = element_text(margin = margin(t = 0, r = 15,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        legend.title = element_text(face = face.type),\n        legend.spacing = unit(20, \"pt\"),\n        legend.text = element_text(size = key_size),\n        plot.title = element_text(face = face.type, hjust = .5,\n                                  margin = margin(b = 10)),\n        plot.subtitle = element_text(hjust = .5),\n        plot.caption = element_text(hjust = 0, size = key_size,\n                                    margin = margin(t = 20)),\n        strip.background = element_rect(fill = \"white\", color = \"white\"),\n        strip.text = element_text(color = \"black\",\n                                  face = face.type))\n}\n\n\n\noutput_theme &lt;- theme_linedraw() + \n  theme_spacious(font_size = 12, bold = TRUE) +\n  theme(panel.border = element_rect(color = \"gray\"),\n        axis.line.x = element_line(color = \"gray\"),\n        axis.line.y = element_line(color = \"gray\"),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\ntheme_set(output_theme)\n\n\nggplot(adelie, aes(species, body_mass_g, \n                     color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\")"
  },
  {
    "objectID": "lectures/lectures-class-8.html#common-types-of-plots",
    "href": "lectures/lectures-class-8.html#common-types-of-plots",
    "title": "Class 8: Data Visualization",
    "section": "Common Types of Plots",
    "text": "Common Types of Plots\n\nHistogram\n\nggplot(penguins, aes(body_mass_g)) +\n  geom_histogram(bins = 20, fill = \"white\", color = \"black\")\n\n\n\n\n\n\n\n\n\n\nBar, point, and line\nWhen you have a categorical (nominal or ordinal) variable on the x-axis and you want to plot that against a continuous variable on the y-axis this is usually done in the form of a bar, point, or line plot.\n\nBar plot\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_bar(stat = \"summary\", fun = mean)\n\n\n\n\n\n\n\n\n\n\nPoint plot\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_point(stat = \"summary\", fun = mean)\n\n\n\n\n\n\n\n\n\n\nPoint plot - with raw values\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_jitter(width = .1, size = .75, alpha = .2) +\n  geom_point(stat = \"summary\", fun = mean, \n             size = 4, color = \"steelblue\")\n\n\n\n\n\n\n\n\n\n\nLine plot\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_line(stat = \"summary\", fun = mean, group = 1)\n\n\n\n\n\n\n\n\n\n\nLine plot - with raw values\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_jitter(width = .1, size = .75, alpha = .2) +\n  geom_line(stat = \"summary\", fun = mean, group = 1) +\n  geom_point(stat = \"summary\", fun = mean, \n             size = 4, color = \"steelblue\")\n\n\n\n\n\n\n\n\n\n\n\nScatterplot\nWhen you have a continuous (interval or ratio) variable on the x-axis and you want to plot it against a continuous variable on the y-axis this is known as a scatterplot.\n\nggplot(penguins, aes(bill_length_mm, body_mass_g)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", color = \"forestgreen\")"
  },
  {
    "objectID": "activities/activities-class-2.html",
    "href": "activities/activities-class-2.html",
    "title": "Class 2 Learning Activity",
    "section": "",
    "text": "Let’s consider a study investigating the impact of sleep quality interventions on cognitive performance and mood across several weeks. In this scenario, participants are exposed to two interventions (Sleep Hygiene Education and Relaxation Techniques) and their cognitive performance scores and mood ratings are recorded weekly.\nYou’re analyzing data from a psychology experiment where participants’ cognitive performance scores and mood ratings are recorded across four weeks for two interventions. The data is split into two files, one with the cognitive performance data (⬇️ class_2_cog_data.csv) and another with the mood ratings data (⬇️ class_2_mood_data.txt), but the same participants across each data set.\nYour task will be to import, restructure, and merge the data so that we can graphically visualize the results of the experiment."
  },
  {
    "objectID": "activities/activities-class-2.html#setup-and-import",
    "href": "activities/activities-class-2.html#setup-and-import",
    "title": "Class 2 Learning Activity",
    "section": "Setup and Import",
    "text": "Setup and Import\n\nCreate a new R script and save it as class_2_activity.R\nLoad the following packages at the top of your script\n\nreadr, dplyr, tidyr, ggplot2\n\nImport the data files\nGet to know the data (use what you learned from Class 1)\n\nWhat are the column names?\nWhat type of values are in the columns?\nHow many participants are in the study?\nHow many are in each of the intervention conditions?\nApproximately, what are the range of values on cognitive performance and mood ratings?\n\nHint: You can click on the columns names when viewing the data frame to toggle between sorting from low-to-high and high-to-low\n\nAre there are any missing values in the data?"
  },
  {
    "objectID": "activities/activities-class-2.html#restructure",
    "href": "activities/activities-class-2.html#restructure",
    "title": "Class 2 Learning Activity",
    "section": "Restructure",
    "text": "Restructure\n\nRestructure each data set to long format with week spread across rows instead of columns and one column for cognitive score or mood rating\nThe data frames should look something like\n\n\n\n\n\n\n\n\n\nparticipant_id\nintervention_type\nweek\ncognitive_score\n\n\n\n\n1\nSleep Hygiene\n1\n76.09\n\n\n1\nSleep Hygiene\n2\n75.34\n\n\n1\nSleep Hygiene\n3\n75.09\n\n\n1\nSleep Hygiene\n4\n78.85\n\n\n2\nSleep Hygiene\n1\n72.30\n\n\n\n\n\n\n\n\n\n\n\n\nparticipant_id\nintervention_type\nweek\nmood_score\n\n\n\n\n1\nSleep Hygiene\n1\n66.32\n\n\n1\nSleep Hygiene\n2\n83.44\n\n\n1\nSleep Hygiene\n3\n76.29\n\n\n1\nSleep Hygiene\n4\n79.14\n\n\n2\nSleep Hygiene\n1\n60.17\n\n\n\n\nAfter you have restructured the data frames, you will notice that the values in the week column also contain the string: cognitive_week_ or mood_week_. This is redundant information with the column names and can be removed to clean up the format of the data. The following line of code can be used to to do so.\n\nmutate(week = parse_number(week))\n\n# e.g., you can pipe the result of pivot_longer() to this mutate() code\n\ndata_long &lt;- data |&gt;\n  pivot_longer() |&gt;\n  mutate(week = parse_number(week))"
  },
  {
    "objectID": "activities/activities-class-2.html#merge",
    "href": "activities/activities-class-2.html#merge",
    "title": "Class 2 Learning Activity",
    "section": "Merge",
    "text": "Merge\n\nMerge the two long data frames into one data frame.\n\nHint: There is more than one key column that the data frames need to be joined by."
  },
  {
    "objectID": "activities/activities-class-2.html#plot",
    "href": "activities/activities-class-2.html#plot",
    "title": "Class 2 Learning Activity",
    "section": "Plot",
    "text": "Plot\n\nPlot the cognitive performance data:\nCreate a plot showing the cognitive scores (y-axis) across weeks (x-axis) by intervention type (color). Something like this:\n\n\nFirst add the data and aesthetic layers - how the data map onto the plot scales and axes\n\n\n\n\n\n\nTip\n\n\n\n\ndata should be changed to the name of your data frame containing the cognitive data\nvar_x should be changed to the name of the column that should be plotted on the x-axis\nvar_y should be changed to the name of the column that should be plotted on the y-axis\nvar_color should be change to the name of the column containing the intervention type\n\n\n\n\n# change the following values to fit your data\n# data, var_x, var_y, var_color\n\nggplot(data, aes(x = var_x, y = var_y,\n                 color = var_color, group = var_color))\n\nNow let’s add in the geometries layer - the visual elements used for the data\n\nggplot(data, aes(x = var_x, y = var_y,\n                 color = var_color, group = var_color))\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .9) +\n  stat_summary(fun = mean, geom = \"line\", size = .5) +\n  stat_summary(fun = mean, geom = \"point\", size = 1.5)\n\nNo need to modify the code here. For now don’t worry about what these are doing, we will cover graphical visualization in more detail in later chapters. But you can see that we are plotting three geom layers, errorbar, line, and point. We need to use stat_summary() because the data are not aggregated, this function will aggregate the data across participants using fun = mean.\nFinally, let’s make this plot a little prettier\n\n# change the following values based on your preference\n# the width, and size values in stat_summary()\n# lower limit and upper limit in coord_cartesian()\n# the title, x, y, and color in labs()\n# choose a ggplot2 theme\n\nggplot(data, aes(x = var_x, y = var_y,\n                 color = var_color, group = var_color)) +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .9) +\n  stat_summary(fun = mean, geom = \"line\", size = .5) +\n  stat_summary(fun = mean, geom = \"point\", size = 1.5) +\n  coord_cartesian(ylim = c(72, 80)) +\n  labs(title = \"Give the plot a title\", \n       x = \"change x-axis label\", \n       y = \"change y-axis label\", \n       color = \"change legend title\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_() # choose a ggplot2 theme\n\nChange the following values based on your preference\n\nthe width of the error bars: stat_summary(width = .9)\nthe size of the lines: stat_summary(size = .5)\nthe size of the data points: stat_summary(size = .1.5)\nthe lower and upper limit of the y-axis (zoom in or out): coord_cartesian(ylim = c(lower_limit, upper_limit)\nadd a plot title\nthe y-axis, x-axis, and legend labels. e.g., no underscores, capitalize words, etc.\nchoose a brewer color palette: scale_color_brewer(palette = \"Set1\")\n\nSee options here: R Color Brewer’s palettes\n\nchoose a ggplot2 theme:\n\ntheme_bw()\ntheme_light()\ntheme_dark()\ntheme_minimal()\ntheme_classic()\ntheme_void()\n\n\n\nPlot the mood data:\n\n\nCopy and paste the code you wrote for plotting the cognitive performance data.\nChange values as needed\n\nThe variable to be plotted on the y-axis aes(y = )\nthe lower and upper limits of the y-axis coord_cartesian(ylim = c(lower_limit, upper_limit)\nplot title, y-axis, x-axis, and legend labels\n\n\nSave the plots as a file on your computer\n\nPlace the following code directly below the code for creating each of the plots. It will save the last generated plot to a file. Change the file name for each plot.\n\nggsave(\"folder/path/class_2_cognitive_plot.png\", \n       width = 6, height = 4, dpi = 300)\n\n\nOrganize and clean up your script\n\nLoad all packages at the top of your script\nGet rid of code that is not necessary, such as:\n\ninstall.package() calls\nView()\n\nAdd comment headers to sections of your code: e.g., # load packages"
  },
  {
    "objectID": "activities/activities-class-2.html#check-your-work",
    "href": "activities/activities-class-2.html#check-your-work",
    "title": "Class 2 Learning Activity",
    "section": "Check Your Work",
    "text": "Check Your Work\nYou should attempt to complete the activity without looking at this code\n\n\nShow Code\n# load packages\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\n\n# import data\ncog_import &lt;- read_csv(\"data/class_2_cog_data.csv\")\nmood_import &lt;- read_delim(\"data/class_2_mood_data.txt\", \n                          delim = \"\\t\", escape_double = FALSE, trim_ws = TRUE)\n\n# restructure data\ncog_data &lt;- cog_import |&gt;\n  pivot_longer(cols = starts_with(\"cognitive_week\"), \n               names_to = \"week\", \n               values_to = \"cognitive_score\") |&gt;\n  mutate(week = parse_number(week))\n\nmood_data &lt;- mood_import |&gt;\n  pivot_longer(cols = starts_with(\"mood_week\"), \n               names_to = \"week\", \n               values_to = \"mood_score\") |&gt;\n  mutate(week = parse_number(week))\n\n# merge data\ndata_merged &lt;- full_join(cog_data, mood_data, \n                         by = c(\"participant_id\", \"intervention_type\", \"week\"))\n\n# plot data\nggplot(data_merged, aes(x = week, y = cognitive_score, \n                        color = intervention_type, group = intervention_type)) +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .25) +\n  stat_summary(fun = mean, geom = \"line\", size = 1) +\n  stat_summary(fun = mean, geom = \"point\", size = 2) +\n  coord_cartesian(ylim = c(65, 85)) +\n  labs(title = \"Cognitive Scores Across Weeks by Intervention Type\", \n       x = \"Week\", \n       y = \"Cognitive Score\", \n       color = \"Intervention Type\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_classic()\n\nggsave(\"images/class_2_cognitive_plot.png\", \n       width = 6, height = 4, dpi = 300)\n\nggplot(data_merged, aes(x = week, y = mood_score, \n                        color = intervention_type, group = intervention_type)) +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .25) +\n  stat_summary(fun = mean, geom = \"line\", size = 1) +\n  stat_summary(fun = mean, geom = \"point\", size = 2) +\n  coord_cartesian(ylim = c(60, 80)) +\n  labs(title = \"Mood Across Weeks by Intervention Type\", \n       x = \"Week\", \n       y = \"Mood\", \n       color = \"Intervention Type\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_classic()\n\nggsave(\"images/class_2_mood_plot.png\", \n       width = 6, height = 4, dpi = 300)"
  },
  {
    "objectID": "supplemental/data-prep-qualtrics.html",
    "href": "supplemental/data-prep-qualtrics.html",
    "title": "Data Preparation - Qualtrics",
    "section": "",
    "text": "In Class 4, we saw that the first stage in the data processing workflow is data preparation. This is a critical, though often overlooked stepped.\nThere are certain considerations that need to be made when working with data generated from a Qualtrics Survey (a popular survey tool used in psychology and other fields). This guide is meant to help you figure out the steps you need to take in order to prepare your data from a Qualtrics Survey for scoring and analysis. The end product of this data preparation stage is one or more tidy raw data files.\nThis guide assumes you have completed Classes 1 - 4. You should reference materials in those classes to help you at this stage.",
    "crumbs": [
      "Supplemental",
      "Data Prep - Qualtrics"
    ]
  },
  {
    "objectID": "supplemental/data-prep-qualtrics.html#understanding-the-messy-raw-data-file",
    "href": "supplemental/data-prep-qualtrics.html#understanding-the-messy-raw-data-file",
    "title": "Data Preparation - Qualtrics",
    "section": "Understanding the Messy Raw Data File",
    "text": "Understanding the Messy Raw Data File\nYou should take some time to better understand your messy raw data file:\nUse functions, such as colnames() and unique(), that we learned in Class 1: An Introduction to Working with Data in R to explore your imported data file.\n\nIn a document, write down the column names that go with each questionnaire/scale. If the scale has subscales within it, note which column names go with those subscales.\nWhich column is associated with unique IDs for each participant?\nAre there any other columns that are important?\nFor each questionnaire/scale how are responses recorded?\n\nNumeric? What is the range of possible values?\nCharacter? What are the response options?\n\ne.g. strongly disagree, disagree, agree, strongly disagree\n\n\n\nThe amount of time it took for you to do those steps is the reason we are doing this data preparation step. The end product will hopefully be a tidy raw data file that is way easier to understand, even for someone that was not involved in the project.\nFor example you might have a data frame that is structured like this\n\n\n\n  \n\n\n\nAre you able to understand what questionnaires/scales this data contain? And which questions go together?\nThere is a bit of structure in the column names but that is about it. By the end of this guide we will create a tidy version of this messy data file.",
    "crumbs": [
      "Supplemental",
      "Data Prep - Qualtrics"
    ]
  },
  {
    "objectID": "supplemental/data-prep-qualtrics.html#tidying-up",
    "href": "supplemental/data-prep-qualtrics.html#tidying-up",
    "title": "Data Preparation - Qualtrics",
    "section": "Tidying Up",
    "text": "Tidying Up\nHow you need to tidy up your data file will depend on the nature of your Qualtrics study used to generate your data. However, there are some common messy problems we can address for Qualtrics Survey data.\nOne problem is that if you have multiple questionnaires with many items, then there are probably way too many columns to sort through. (this is not the case with our example data because I am keeping it simple)\nAnother major problem with the messy raw data from Qualtrics is that everything is spread across columns (wide format). When that is the case, we cannot visually group certain columns together making it challenging to understand which questions/items go together. Let alone, the column names are often times meaningless.\nFinally, there is information missing from the messy raw data file that can be added.\n\nThe name or acronym of the questionnaire\nIf there are subscales: the name of those scales and which items correspond to which subscale\n\nYou can address these problems with your data by:\n\nCreating a separate data frame for each questionnaire: select()\nConverting the data frame to long format: pivot_longer()\nAdd and modify columns to make the data easier to understand: mutate() and case_when()\n\nNotice in the script template I laid out the general format for this.\n\ndata_survey1 &lt;- data_import |&gt;\n  select() |&gt;\n  pivot_longer() |&gt;\n  mutate()\n\ndata_survey2 &lt;- data_import |&gt;\n  select() |&gt;\n  pivot_longer() |&gt;\n  mutate()\n\n\nSeparate Questionnaires\nSeparating the questionnaires into different data frames is easy, but you need to know which column names go with which questionnaire first (which is why I had you do this above).\nUse the select() function from dplyr . This will create a separate data frame that only contains columns corresponding to a single questionnaire.\nFor example\n\nCodeData Frames\n\n\n\ndata_survey1 &lt;- data_import |&gt;\n  select(ID, Q21.., Q22.., Q23..)\n\ndata_survey2 &lt;- data_import |&gt;\n  select(ID, SQ_S1, SQ_S2, SQ_P3)\n\n\n\n\n\n\n\nImportant\n\n\n\n\nYou need to use the special type of quotation marks ` ` if your column names contain special charaters like: a space, $, %, -, and more…\nYou should also keep a column corresponding to the unique participant ID\n\n\n\nView the Data Frames tab to see the resulting data frames",
    "crumbs": [
      "Supplemental",
      "Data Prep - Qualtrics"
    ]
  },
  {
    "objectID": "supplemental/data-prep-qualtrics.html#convert-to-long-format",
    "href": "supplemental/data-prep-qualtrics.html#convert-to-long-format",
    "title": "Data Preparation - Qualtrics",
    "section": "Convert to Long Format",
    "text": "Convert to Long Format\nIt is still not clear from the data frame whether there are subscales and which items go together. This is where converting the data frame to a long format can make this data easy to understand and work with.\nUse the pivot_longer() function from tidyr to do this. Again, notice in the script template I laid out the general format for this. You can pipe the result of select() onto pivot_longer() . This will produce a data frame that has one row for every item in the questionnaire/scale and a single column with all the responses.\n\n\n\n\n\n\nNote\n\n\n\nReference materials from Class 2 for how to use pivot_longer()\n\n\nUsing the sample tables from above we might do something like\n\nCodeData Frames\n\n\n\ndata_survey1 &lt;- data_import |&gt;\n  select(ID, Q21.., Q22.., Q23..) |&gt;\n  pivot_longer(cols = starts_with(\"Q\"),\n               names_to = \"Item\",\n               values_to = \"Response\")\n\ndata_survey2 &lt;- data_import |&gt;\n  select(ID, starts_with(\"SQ_\")) |&gt;\n  pivot_longer(cols = starts_with(\"SQ_\"),\n               names_to = \"Item\",\n               values_to = \"Response\")\n\nView the Data Frames tab to see the resulting data frames",
    "crumbs": [
      "Supplemental",
      "Data Prep - Qualtrics"
    ]
  },
  {
    "objectID": "supplemental/data-prep-qualtrics.html#add-and-modify-columns",
    "href": "supplemental/data-prep-qualtrics.html#add-and-modify-columns",
    "title": "Data Preparation - Qualtrics",
    "section": "Add and Modify Columns",
    "text": "Add and Modify Columns\nWe can then:\n\nCreate a column for the name of the questionnaire\nClean up the values in the Item column\nCreate a column containing information about subscales (if there are any)\nRecode values int he Response column\n\nCreating the name of the questionnaire is easy using mutate()\n\nCodeData Frames\n\n\n\ndata_survey1 &lt;- data_import |&gt;\n  select(ID, Q21.., Q22.., Q23..) |&gt;\n  pivot_longer(cols = starts_with(\"Q\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"ERI\")\n\ndata_survey2 &lt;- data_import |&gt;\n  select(ID, starts_with(\"SQ_\")) |&gt;\n  pivot_longer(cols = starts_with(\"SQ_\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"SCS\")\n\nView the Data Frames tab to see the resulting data frames\n\n\n\n\n\n  \n\n\n\n\n  \n\n\n\n\n\n\nTo clean up values in Item you can use the str_remove() function from stringr . You might want to convert Item to numeric if you remove all string character values.\nSee the stringr documentation for convenient functions for working with non-numeric values.\n\nCodeData Frames\n\n\n\ndata_survey1 &lt;- data_import |&gt;\n  select(ID, Q21.., Q22.., Q23..) |&gt;\n  pivot_longer(cols = starts_with(\"Q\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"ERI\",\n         Item = str_remove(Item, \"Q2\"),\n         Item = str_remove(Item, \"\\\\..\"),\n         Item = as.numeric(Item))\n\ndata_survey2 &lt;- data_import |&gt;\n  select(ID, starts_with(\"SQ_\")) |&gt;\n  pivot_longer(cols = starts_with(\"SQ_\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"SCS\",\n         Item = str_remove(Item, \"SQ_\"))\n\n\n\n\n\n\n\nNote\n\n\n\nI used the notation \"\\\\..\" to remove trailing periods. The \\\\ were required because a . serves as a special notation in R and dplyr syntax. \\\\ in many languages says treat . as a literal period not as a special notation.\n\n\nView the Data Frames tab to see the resulting data frames\n\n\n\n\n\n  \n\n\n\n\n  \n\n\n\n\n\n\nIf there are subscales, we can create a column with information about which items belong to which subscale. You should have identified this information for your data in the steps above. (If there are no subscales then you do not need this step).\nWe can use case_when() from dplyr() to do this.\nFor this sample data:\n\nCodeData Frames\n\n\n\ndata_survey1 &lt;- data_import |&gt;\n  select(ID, Q21.., Q22.., Q23..) |&gt;\n  pivot_longer(cols = starts_with(\"Q\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"ERI\",\n         Item = str_remove(Item, \"Q2\"),\n         Item = str_remove(Item, \"\\\\..\"),\n         Item = as.numeric(Item),\n         Subscale = case_when(between(Item, 1,2) ~ \"Emotion_Regulation\",\n                              Item == 3 ~ \"Emotion_Reappraisal\"))\n\ndata_survey2 &lt;- data_import |&gt;\n  select(ID, starts_with(\"SQ_\")) |&gt;\n  pivot_longer(cols = starts_with(\"SQ_\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"SCS\",\n         Item = str_remove(Item, \"SQ_\"),\n         Subscale = \n           case_when(Item %in% c(\"S1\", \"S2\") ~ \"Friendship_Quality\",\n                     Item == \"P3\" ~ \"Community_Engagement\"))\n\n\n\n\n\n\n\nNote\n\n\n\nNote that in case_when() I am just providing you with different options you can use as a shorthand.\n\nbetween() is for numeric values and results in TRUE when a value is within a certain range. In this example the range is dumb, just 1 to 2.\nItem %in% c(\"S1\", \"S2\") reads as: Is Item in this list of “S1”, “S2”?. If Item is in this list, then set Subscale to “Friendship_Quality”\n\nAlternatively, you can do this in a longer format using a series of == for every single item:\n\ncase_when(Item == 1 ~ \"Emotion_Regulation\",\n          Item == 2 ~ \"Emotoin_Regulation\",\n          Item == 3 ~ \"Emotion_Reappraisal\")\n\nBut you can see that this can get quite tedious when you have a lot of items in one scale.\n\n\nView the Data Frames tab to see the resulting data frames\n\n\n\n\n\n  \n\n\n\n\n  \n\n\n\n\n\n\nYou may want to create an additional column that converts the Response into numeric (or vice versa if it is already in numeric you may want to convert it to a character string).\nAgain we can use case_when()\n\nCodeData Frames\n\n\n\ndata_survey1 &lt;- data_import |&gt;\n  select(ID, Q21.., Q22.., Q23..) |&gt;\n  pivot_longer(cols = starts_with(\"Q\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"ERI\",\n         Item = str_remove(Item, \"Q2\"),\n         Item = str_remove(Item, \"\\\\..\"),\n         Item = as.numeric(Item),\n         Subscale = case_when(between(Item, 1,2) ~ \"Emotion_Regulation\",\n                              Item == 3 ~ \"Emotion_Reappraisal\"),\n         Response_Code = case_when(Response == \"never\" ~ 1,\n                                   Response == \"almost never\" ~ 2,\n                                   Response == \"rarely\" ~ 3,\n                                   Response == \"sometimes\" ~ 4,\n                                   Response == \"often\" ~ 5,\n                                   Response == \"almost always\" ~ 6,\n                                   Response == \"always\" ~ 7))\n\ndata_survey2 &lt;- data_import |&gt;\n  select(ID, starts_with(\"SQ_\")) |&gt;\n  pivot_longer(cols = starts_with(\"SQ_\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"SCS\",\n         Item = str_remove(Item, \"SQ_\"),\n         Subscale = \n           case_when(Item %in% c(\"S1\", \"S2\") ~ \"Friendship_Quality\",\n                     Item == \"P3\" ~ \"Community_Engagement\"),\n         Response_Code = \n           case_when(Response == \"strongly disagree\" ~ 1,\n                     Response == \"disagree\" ~ 2,\n                     Response == \"neither agree nor disagree\" ~ 3,\n                     Response == \"agree\" ~ 4,\n                     Response == \"strongly agree\" ~ 5))\n\nView the Data Frames tab to see the resulting data frames",
    "crumbs": [
      "Supplemental",
      "Data Prep - Qualtrics"
    ]
  },
  {
    "objectID": "supplemental/data-prep-qualtrics.html#reorder-columns",
    "href": "supplemental/data-prep-qualtrics.html#reorder-columns",
    "title": "Data Preparation - Qualtrics",
    "section": "Reorder Columns",
    "text": "Reorder Columns\nFinally, we may want to reorder the columns in a way that makes more sense using select():\n\ndata_survey1 &lt;- data_import |&gt;\n  select(ID, Q21.., Q22.., Q23..) |&gt;\n  pivot_longer(cols = starts_with(\"Q\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"ERI\",\n         Item = str_remove(Item, \"Q2\"),\n         Item = str_remove(Item, \"\\\\..\"),\n         Item = as.numeric(Item),\n         Subscale = case_when(between(Item, 1,2) ~ \"Emotion_Regulation\",\n                              Item == 3 ~ \"Emotion_Reappraisal\"),\n         Response_Code = case_when(Response == \"never\" ~ 1,\n                                   Response == \"almost never\" ~ 2,\n                                   Response == \"rarely\" ~ 3,\n                                   Response == \"sometimes\" ~ 4,\n                                   Response == \"often\" ~ 5,\n                                   Response == \"almost always\" ~ 6,\n                                   Response == \"always\" ~ 7)) |&gt;\n  select(ID, Questionnaire, Subscale, Item, Response, Response_Code)\n\ndata_survey2 &lt;- data_import |&gt;\n  select(ID, starts_with(\"SQ_\")) |&gt;\n  pivot_longer(cols = starts_with(\"SQ_\"),\n               names_to = \"Item\",\n               values_to = \"Response\") |&gt;\n  mutate(Questionnaire = \"SCS\",\n         Item = str_remove(Item, \"SQ_\"),\n         Subscale = \n           case_when(Item %in% c(\"S1\", \"S2\") ~ \"Friendship_Quality\",\n                     Item == \"P3\" ~ \"Community_Engagement\"),\n         Response_Code = \n           case_when(Response == \"strongly disagree\" ~ 1,\n                     Response == \"disagree\" ~ 2,\n                     Response == \"neither agree nor disagree\" ~ 3,\n                     Response == \"agree\" ~ 4,\n                     Response == \"strongly agree\" ~ 5)) |&gt;\n  select(ID, Questionnaire, Subscale, Item, Response, Response_Code)\n\nWe now end up with tidy raw data frames\n\nTidyMessy\n\n\n\n\n\n  \n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\nYou can see these data frames are much easier to understand and to work with. Someone outside of your project would have a decent understanding of what information is contained and what is being measured.\nYou need to have your data in this type of format as it will be easier for you to start thinking about scoring and analyzing your data",
    "crumbs": [
      "Supplemental",
      "Data Prep - Qualtrics"
    ]
  },
  {
    "objectID": "slides/slides-class-8.html#outline",
    "href": "slides/slides-class-8.html#outline",
    "title": "Class 8",
    "section": "Outline",
    "text": "Outline\n \n\nggplot2\nData and Aesthetic Layers\nGeometries Layer\nFacets and Statistics Layer\nCoordinates Layer\nTheme Layer\nCommon Types of Plots"
  },
  {
    "objectID": "slides/slides-class-8.html#data-visualization",
    "href": "slides/slides-class-8.html#data-visualization",
    "title": "Class 8",
    "section": "Data Visualization",
    "text": "Data Visualization\n \nData visualization is an essential skill for anyone working with data and requires a combination of design principles with statistical understanding. In general there are two purposes for needing to graphically visualize data:\n \n\nData exploration: It is difficult to fully understand your data just by looking at numbers on a screen arranged in rows and columns. Being skilled in the graphical visualization of data will help you better understand patterns and relationships that exist in your data.\nExplain and Communicate: Data visualization is the most effective way of explaining and communicating your statistical findings to colleagues, in scientific presentations and publications, and especially to a broader non-academic audience."
  },
  {
    "objectID": "slides/slides-class-8.html#section",
    "href": "slides/slides-class-8.html#section",
    "title": "Class 8",
    "section": "",
    "text": "In this class, we will learn about the fundamentals of data visualization using the ggplot2 package. This is by far the most popular package for data visualization in R.\n \nYou have already seen and used ggplot2 in previous classes, but now we will cover how to actually use this package."
  },
  {
    "objectID": "slides/slides-class-8.html#section-1",
    "href": "slides/slides-class-8.html#section-1",
    "title": "Class 8",
    "section": "",
    "text": "The elements for creating a ggplot was largely inspired from the work of Leland Wilkinson (Grammar of Graphics, 1999), who formalized two main principles in plotting data:\n\n\nLayering\nMapping\n\n\n\nIn this framework, the essential grammatical elements required to create any data visualization are:"
  },
  {
    "objectID": "slides/slides-class-8.html#palmerpenguins",
    "href": "slides/slides-class-8.html#palmerpenguins",
    "title": "Class 8",
    "section": "palmerpenguins",
    "text": "palmerpenguins\n \nWe will use a data set from the palmerpenguins package"
  },
  {
    "objectID": "slides/slides-class-8.html#palmerpenguins-1",
    "href": "slides/slides-class-8.html#palmerpenguins-1",
    "title": "Class 8",
    "section": "palmerpenguins",
    "text": "palmerpenguins\n \n\n\nGo ahead and load the palmerpenguins and ggplot2 packages using library() .\nAdditionally, let’s make the penguins data set that is loaded with palmerpenguins visible in the environment by explicitly assigning it to an object.\n\n\n\n\nlibrary(palmerpenguins)\nlibrary(ggplot2)\n\npenguins &lt;- penguins"
  },
  {
    "objectID": "slides/slides-class-8.html#data-layer",
    "href": "slides/slides-class-8.html#data-layer",
    "title": "Class 8",
    "section": "Data Layer",
    "text": "Data Layer\nThe Data Layer specifies the data object that is being plotted.\n \n\n \nIt is the first grammatical element that is required to create a plot:\n\nggplot(data = penguins)"
  },
  {
    "objectID": "slides/slides-class-8.html#aesthetic-layer",
    "href": "slides/slides-class-8.html#aesthetic-layer",
    "title": "Class 8",
    "section": "Aesthetic Layer",
    "text": "Aesthetic Layer\nThe next grammatical element is the aesthetic layer, or aes for short. This layer specifies how we want to map our data onto the scales of the plot.\n \n\n \nThe aesthetic layer maps variables in our data onto scales in our graphical visualization, such as the x and y coordinates. In ggplot2 the aesthetic layer is specified using the aes() function.\n \n\nggplot(penguins, mapping = aes(x = bill_length_mm, y = flipper_length_mm))"
  },
  {
    "objectID": "slides/slides-class-8.html#aesthetic-layer-1",
    "href": "slides/slides-class-8.html#aesthetic-layer-1",
    "title": "Class 8",
    "section": "Aesthetic Layer",
    "text": "Aesthetic Layer\n \n\nggplot(penguins, mapping = aes(x = bill_length_mm, y = flipper_length_mm))\n\n\n\n\n\n\n\n\nYou can see we went from a blank box to a graph with the variable and scales of bill_length_mm mapped onto the x-axis and flipper_length_mm on the y-axis."
  },
  {
    "objectID": "slides/slides-class-8.html#aesthetic-layer-2",
    "href": "slides/slides-class-8.html#aesthetic-layer-2",
    "title": "Class 8",
    "section": "Aesthetic Layer",
    "text": "Aesthetic Layer\n \n\n\nThe aesthetic layer also maps variables in our data to other elements in our graphical visualization, such as color, size, fill, etc.\nThese other elements are useful for adding a third variable onto our graphical visualizations. For instance, we can add the variable of species by mapping species onto the color aesthetic.\n\n\n\n\nggplot(penguins, \n       mapping = aes(bill_length_mm, flipper_length_mm, color = species))"
  },
  {
    "objectID": "slides/slides-class-8.html#geometries-layer-1",
    "href": "slides/slides-class-8.html#geometries-layer-1",
    "title": "Class 8",
    "section": "Geometries Layer",
    "text": "Geometries Layer\nThe next essential grammatical element for graphical visualization is the geometries layer or geom for short. This layer specifies the visual elements that should be used to plot the actual data.\n \n\n\nThere are a lot of different types of geoms to use in ggplot2. Some of the most commonly used ones are:\n\n\nPoints or jittered points: geom_point() or geom_jitter()\nLines: geom_line()\nBars: geom_bar()\nViolin: geom_violin()\nError bars: geom_errobar() or geom_ribbon()\n\n\n\n\nFor a full list see the ggplot2 documentation"
  },
  {
    "objectID": "slides/slides-class-8.html#geom_point",
    "href": "slides/slides-class-8.html#geom_point",
    "title": "Class 8",
    "section": "geom_point()",
    "text": "geom_point()\n \nFor now, let’s demonstrate this using geom_point(). We will create what is called a scatterplot - plotting the individual data points for two continuous variables.\n\n \n\nggplot(penguins, aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point()\n\n \n\n\nYou can also specify the color = species aesthetic mapping on the geometric layer\n\nggplot(penguins, aes(bill_length_mm, flipper_length_mm)) +\n  geom_point(mapping = aes(color = species))\n\n \n\n\n\n\n\n\n\n\nNote\n\n\nNote that in ggplot2 there is a special notation that is similar to the pipe operator |&gt; seen in previous classes. Except in ggplot2 you have to use a plus sign + ."
  },
  {
    "objectID": "slides/slides-class-8.html#geom_point-1",
    "href": "slides/slides-class-8.html#geom_point-1",
    "title": "Class 8",
    "section": "geom_point()",
    "text": "geom_point()\n \n\nggplot(penguins, aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-class-8.html#aesthetic-properties-of-geoms",
    "href": "slides/slides-class-8.html#aesthetic-properties-of-geoms",
    "title": "Class 8",
    "section": "Aesthetic Properties of geoms",
    "text": "Aesthetic Properties of geoms\nBesides mapping variables in your data to certain aesthetics, you can change the aesthetic properties of geometrical elements. Common aesthetic properties include:\n \nColor related aesthetics: See more details here\n\n\nColor: applies to most geoms geom_(color = )\nFill: applies to most geoms geom_(fill = )\nTransparency: applies to most geoms. values can range from 0 to 1, 0 = transparent; 1 = opaque; geom_(alpha = )\nSee a full list of R colors here\n\n\nShape related aesthetics: See more details here\n\n\nShape: geom_point(shape = ), geom_jitter(shape = )\nSize: geom_point(size = ), geom_jitter(size = )\nLine Type: geom_line(linetype = )\nLine Width: geom_line(linewidth = )\nWidth: geom_errobar(width = ), geom_jitter(width = )"
  },
  {
    "objectID": "slides/slides-class-8.html#aesthetic-properties-of-geoms-1",
    "href": "slides/slides-class-8.html#aesthetic-properties-of-geoms-1",
    "title": "Class 8",
    "section": "Aesthetic Properties of geoms",
    "text": "Aesthetic Properties of geoms\n \n\nggplot(penguins, \n       aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point(shape = \"diamond filled\", size = 3, fill = \"white\")"
  },
  {
    "objectID": "slides/slides-class-8.html#more-ggplot2-layers",
    "href": "slides/slides-class-8.html#more-ggplot2-layers",
    "title": "Class 8",
    "section": "More ggplot2 layers",
    "text": "More ggplot2 layers\n \nBesides the data, aesthetics, and geometries layers, there are often other types of elements you may want to include."
  },
  {
    "objectID": "slides/slides-class-8.html#facets-layer",
    "href": "slides/slides-class-8.html#facets-layer",
    "title": "Class 8",
    "section": "Facets Layer",
    "text": "Facets Layer\nThe facets layer allows you to create panels of subplots within the same graphic object\n \n\nThe previous three layers are the essential layers. The facet layer is not essential, but it can be useful when you want to communicate the relationship among 4 or more variables.\n \n\nLet’s create a facet layer of our scatterplot with different panels for sex\n\n# first let's remove any missing values for sex\nlibrary(dplyr)\npenguins &lt;- filter(penguins, !is.na(sex))\n\nggplot(penguins, \n       aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point() +\n  facet_grid(cols = vars(sex))\n\nSee the ggplot2 documentation on facet_grid and facet_wrap"
  },
  {
    "objectID": "slides/slides-class-8.html#facets-layer-1",
    "href": "slides/slides-class-8.html#facets-layer-1",
    "title": "Class 8",
    "section": "Facets Layer",
    "text": "Facets Layer\n \n\n# first let's remove any missing values for sex\nlibrary(dplyr)\npenguins &lt;- filter(penguins, !is.na(sex))\n\nggplot(penguins, \n       aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point() +\n  facet_grid(cols = vars(sex))"
  },
  {
    "objectID": "slides/slides-class-8.html#statistics-layer",
    "href": "slides/slides-class-8.html#statistics-layer",
    "title": "Class 8",
    "section": "Statistics Layer",
    "text": "Statistics Layer\nThe statistics layer allows you plot aggregated statistical values calculated from your data\n \n\nThe statistics layer is used in combination with a geom to plot values that are a function (e.g., mean) of the values in your data. The two main stat functions are:\n\ngeom_(stat = \"summary\")\nstat_smooth()"
  },
  {
    "objectID": "slides/slides-class-8.html#geom_stat-summary",
    "href": "slides/slides-class-8.html#geom_stat-summary",
    "title": "Class 8",
    "section": "geom_(stat = “summary”)",
    "text": "geom_(stat = “summary”)\n \nStatistics are often evaluated at the aggregate level (e.g., think mean differences between groups). We can calculate summary statistics inside inside of the geom functions using stat = \"summary\". There are two main arguments you need to specify:\n\nstat: set this to “summary” to calculate a summary statistic\nfun: The function used to calculate an aggregated summary statistic. Functions like mean, sum, min, max, sd can all be specified. You can then specify additional argument that should be passed into these functions as regular arguments in geom_()\n\n\nTo plot the average (mean) body_mass_g for each species.\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_point(stat = \"summary\", fun = mean, na.rm = TRUE,\n             shape = \"diamond\", size = 5, color = \"firebrick\")\n\n \n\n\nUsing multiple geoms you can plot both the raw values for each individual penguin and the summary statistic\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_jitter(width = .1, size = 1, alpha = .2) +\n  geom_point(stat = \"summary\", fun = mean, na.rm = TRUE,\n             shape = \"diamond\", size = 5, color = \"firebrick\")"
  },
  {
    "objectID": "slides/slides-class-8.html#geom_stat-summary-1",
    "href": "slides/slides-class-8.html#geom_stat-summary-1",
    "title": "Class 8",
    "section": "geom_(stat = “summary”)",
    "text": "geom_(stat = “summary”)\n \n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_jitter(width = .1, size = 1, alpha = .2) +\n  geom_point(stat = \"summary\", fun = mean, na.rm = TRUE,\n             shape = \"diamond\", size = 5, color = \"firebrick\")"
  },
  {
    "objectID": "slides/slides-class-8.html#geom_stat-summary-2",
    "href": "slides/slides-class-8.html#geom_stat-summary-2",
    "title": "Class 8",
    "section": "geom_(stat = “summary”)",
    "text": "geom_(stat = “summary”)\n \nThe fun = argument returns only a single summary statistic value (e.g., a mean). However, some geoms actually require two values. For instance, when plotting errorbars you will need both ymin and ymax values returned. For these types of cases, you need to use the fun.data argument instead:\n \n\nmean_cl_normal is a function to calculate 95% confidence limits from your data.\n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_jitter(width = .1, size = .75, alpha = .2) +\n  geom_point(stat = \"summary\", fun = mean, na.rm = TRUE,\n             shape = \"diamond\", size = 5, color = \"firebrick\") +\n  geom_errorbar(stat = \"summary\", fun.data = mean_cl_normal, width = .1)"
  },
  {
    "objectID": "slides/slides-class-8.html#stat_smoothmethod-lm",
    "href": "slides/slides-class-8.html#stat_smoothmethod-lm",
    "title": "Class 8",
    "section": "stat_smooth(method = “lm”)",
    "text": "stat_smooth(method = “lm”)\n \nstat_smooth(method = \"lm\") is used in scatterplots to plot the regression line on your data.\n \n\nggplot(penguins, aes(x = bill_length_mm, y = flipper_length_mm)) +\n  geom_point() +\n  stat_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/slides-class-8.html#stat_smoothmethod-lm-1",
    "href": "slides/slides-class-8.html#stat_smoothmethod-lm-1",
    "title": "Class 8",
    "section": "stat_smooth(method = “lm”)",
    "text": "stat_smooth(method = “lm”)\n \nYou can add separate regression lines if other variables are mapped to aesthetics and/or are wrapped in different facets\n\nggplot(penguins, \n       aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point() +\n  facet_grid(cols = vars(sex)) +\n  stat_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/slides-class-8.html#stat_smoothmethod-lm-2",
    "href": "slides/slides-class-8.html#stat_smoothmethod-lm-2",
    "title": "Class 8",
    "section": "stat_smooth(method = “lm”)",
    "text": "stat_smooth(method = “lm”)\n \n\nggplot(penguins, \n       aes(bill_length_mm, flipper_length_mm, color = species)) +\n  geom_point() +\n  facet_grid(cols = vars(sex)) +\n  stat_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/slides-class-8.html#coordinates-layer-1",
    "href": "slides/slides-class-8.html#coordinates-layer-1",
    "title": "Class 8",
    "section": "Coordinates Layer",
    "text": "Coordinates Layer\nThe coordinate layer allows you to adjust the x and y coordinates\n \n\n \nThere are two main groups of functions that are useful for adjusting the x and y coordinates.\n\ncoord_cartesian() for adjusting the axis limits (zoom in and out)\nscale_x_ and scale_y_ for setting the axis ticks and labels"
  },
  {
    "objectID": "slides/slides-class-8.html#axis-limits",
    "href": "slides/slides-class-8.html#axis-limits",
    "title": "Class 8",
    "section": "axis limits",
    "text": "axis limits\nYou can adjust limits (min and max) of the x and y axes using coord_cartesian(xlim = c(), ylim = c())\n \n\n\n\n\n\n\nImportant\n\n\nIf you want to compare two separate graphs, then they need to be on the same scale. This an important design principle in graphical visualization."
  },
  {
    "objectID": "slides/slides-class-8.html#axis-limits-1",
    "href": "slides/slides-class-8.html#axis-limits-1",
    "title": "Class 8",
    "section": "axis limits",
    "text": "axis limits\n \nYou can adjust limits (min and max) of the x and y axes using coord_cartesian(xlim = c(), ylim = c())\n\nmale &lt;- filter(penguins, sex == \"male\")\nfemale &lt;- filter(penguins, sex == \"female\")\n\np1 &lt;- ggplot(male, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 6000)) +\n  labs(title = \"male\")\n\np2 &lt;- ggplot(female, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) + \n  coord_cartesian(ylim = c(3000, 6000)) +\n  labs(title = \"female\")"
  },
  {
    "objectID": "slides/slides-class-8.html#axis-limits-2",
    "href": "slides/slides-class-8.html#axis-limits-2",
    "title": "Class 8",
    "section": "axis limits",
    "text": "axis limits"
  },
  {
    "objectID": "slides/slides-class-8.html#axis-limits-3",
    "href": "slides/slides-class-8.html#axis-limits-3",
    "title": "Class 8",
    "section": "axis limits",
    "text": "axis limits"
  },
  {
    "objectID": "slides/slides-class-8.html#axis-ticks-and-labels",
    "href": "slides/slides-class-8.html#axis-ticks-and-labels",
    "title": "Class 8",
    "section": "axis ticks and labels",
    "text": "axis ticks and labels\n \nYou can adjust the scale (major and minor ticks) of the x and y axes using the scale_x_ and scale_y_ set of functions. The two main set of functions to know are for continuous and discrete scales:\n \n\n\ncontinuous: scale_x_continuous(breaks = seq()) and scale_y_continuous(breaks = seq())\ndiscrete: scale_x_discrete(breaks = seq()) and scale_y_continuous(breaks = seq())\n\n\n\nFor example:\n\nggplot(male, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 6000)) +\n  scale_y_continuous(breaks = seq(3000, 6000, by = 500))"
  },
  {
    "objectID": "slides/slides-class-8.html#axis-ticks-and-labels-1",
    "href": "slides/slides-class-8.html#axis-ticks-and-labels-1",
    "title": "Class 8",
    "section": "axis ticks and labels",
    "text": "axis ticks and labels\n \n\nggplot(male, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 6000)) +\n  scale_y_continuous(breaks = seq(3000, 6000, by = 500))"
  },
  {
    "objectID": "slides/slides-class-8.html#theme-layer-1",
    "href": "slides/slides-class-8.html#theme-layer-1",
    "title": "Class 8",
    "section": "Theme Layer",
    "text": "Theme Layer\nThe theme layer refers to visual elements that are not mapped to the data but controls the overall design, colors, and labels on the plot\n \n\nThere are three main set of functions that we can use to control the theme layer:\n\nColor: scale_color_ set of functions will change the color scheme of the geometric elements:\nLabels: labs() is a convenient function for labeling the title, subtitle, axes, and legend\nTheme templates: There are predefined theme templates that come with ggplot2\nOther theme elements: theme() can be used to further customize the look of your plot"
  },
  {
    "objectID": "slides/slides-class-8.html#color",
    "href": "slides/slides-class-8.html#color",
    "title": "Class 8",
    "section": "Color",
    "text": "Color\n \nThe RColorBrewer package offers several color palettes for R:\n\n\n\n\n \nAlso, check out the ggsci color palettes inspired by scientific journals, science fiction movies, and TV shows."
  },
  {
    "objectID": "slides/slides-class-8.html#color-1",
    "href": "slides/slides-class-8.html#color-1",
    "title": "Class 8",
    "section": "Color",
    "text": "Color\nYou can access these palettes using scale_color_brewer(palette = \"palette name\")\n\n\nggplot(penguins, aes(species, body_mass_g, color = sex)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 6000)) +\n  scale_y_continuous(breaks = seq(3000, 6000, by = 500)) +\n  scale_color_brewer(palette = \"Set1\")"
  },
  {
    "objectID": "slides/slides-class-8.html#labels",
    "href": "slides/slides-class-8.html#labels",
    "title": "Class 8",
    "section": "Labels",
    "text": "Labels\nChanging labels and adding titles is easy using labs()\n\n \n\nggplot(penguins, aes(species, body_mass_g)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 6000)) +\n  scale_y_continuous(breaks = seq(3000, 6000, by = 500)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\")"
  },
  {
    "objectID": "slides/slides-class-8.html#labels-1",
    "href": "slides/slides-class-8.html#labels-1",
    "title": "Class 8",
    "section": "Labels",
    "text": "Labels\nTo change labels for legends you need to refer to the aesthetic mapping that was defined in aes() (e.g., color, shape).\n \n\nadelie &lt;- filter(penguins, species != \"Gentoo\")\n\nggplot(adelie, aes(species, body_mass_g, color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\")"
  },
  {
    "objectID": "slides/slides-class-8.html#theme-templates",
    "href": "slides/slides-class-8.html#theme-templates",
    "title": "Class 8",
    "section": "Theme templates",
    "text": "Theme templates\n \nHere are some themes that come loaded with ggplot2\n\ntheme_bw()\ntheme_light()\ntheme_dark()\ntheme_minimal()\ntheme_classic()\ntheme_void()"
  },
  {
    "objectID": "slides/slides-class-8.html#theme-templates-1",
    "href": "slides/slides-class-8.html#theme-templates-1",
    "title": "Class 8",
    "section": "Theme templates",
    "text": "Theme templates\n \nUsing a theme template is straightforward\n\nadelie &lt;- filter(penguins, species != \"Gentoo\")\n\nggplot(adelie, aes(species, body_mass_g, color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_classic()"
  },
  {
    "objectID": "slides/slides-class-8.html#other-theme-elements",
    "href": "slides/slides-class-8.html#other-theme-elements",
    "title": "Class 8",
    "section": "Other Theme Elements",
    "text": "Other Theme Elements\nIn addition to using a pre-defined theme template, you may also want to tweak other design elements on your plot. You can do this using theme()\n\nadelie &lt;- filter(penguins, species != \"Gentoo\")\n\nggplot(adelie, aes(species, body_mass_g, color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\") +\n  theme_classic() +\n  theme(legend.title = element_text(face = \"bold\"))"
  },
  {
    "objectID": "slides/slides-class-8.html#other-theme-elements-1",
    "href": "slides/slides-class-8.html#other-theme-elements-1",
    "title": "Class 8",
    "section": "Other Theme Elements",
    "text": "Other Theme Elements\nHere is a list of different elements you can change. They are organized into text, line, and rectangle elements:"
  },
  {
    "objectID": "slides/slides-class-8.html#other-theme-elements-2",
    "href": "slides/slides-class-8.html#other-theme-elements-2",
    "title": "Class 8",
    "section": "Other Theme Elements",
    "text": "Other Theme Elements\nText, line, and rectangle elements each have their corresponding element function e.g., element_text()\n \n\nObviously, there are a lot of different theme elements you can tweak and it is hard to memorize them all. Make use of Google, ggplot2 documentation, and Generative AI’s for assistance.\nHere is the ggplot2 documentation on theme elements"
  },
  {
    "objectID": "slides/slides-class-8.html#create-your-own-theme-template",
    "href": "slides/slides-class-8.html#create-your-own-theme-template",
    "title": "Class 8",
    "section": "Create your own theme template",
    "text": "Create your own theme template\nOften times you may want to apply the same customized theme elements to multiple plots and even across multiple projects.\n \n\nOne convenient way of doing so is to use theme_set()\ntheme_set() will automatically apply the same theme settings across all ggplots created in a document."
  },
  {
    "objectID": "slides/slides-class-8.html#create-your-own-theme-template-1",
    "href": "slides/slides-class-8.html#create-your-own-theme-template-1",
    "title": "Class 8",
    "section": "Create your own theme template",
    "text": "Create your own theme template\n \nFor instance, if you want to make sure all your ggplots have a bolded legend title and use theme_classic() you can create a theme to do that:\n \n\nbold_legend &lt;- theme(legend.title = element_text(face = \"bold\"))\n\nplot_theme &lt;- theme_classic() + bold_legend\n\n \nThen you need to set the theme that will be applied across all ggplots\n\ntheme_set(plot_theme)\n\n \nNow any ggplots you create will be given this theme setting without you having to include it in the actual ggplot."
  },
  {
    "objectID": "slides/slides-class-8.html#create-your-own-theme-template-2",
    "href": "slides/slides-class-8.html#create-your-own-theme-template-2",
    "title": "Class 8",
    "section": "Create your own theme template",
    "text": "Create your own theme template\n \n\nggplot(adelie, aes(species, body_mass_g, \n                     color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\")"
  },
  {
    "objectID": "slides/slides-class-8.html#create-your-own-theme-template-3",
    "href": "slides/slides-class-8.html#create-your-own-theme-template-3",
    "title": "Class 8",
    "section": "Create your own theme template",
    "text": "Create your own theme template\n \n\n\nShow theme_spacious()\ntheme_spacious &lt;- function(font_size = 14, bold = TRUE) {\n  key_size &lt;- trunc(font_size * .8)\n  if (bold == TRUE) {\n    face.type &lt;- \"bold\"\n  } else {\n    face.type &lt;- \"plain\"\n  }\n\n  theme(text = element_text(size = font_size),\n        axis.title.x = element_text(margin = margin(t = 15, r = 0,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        axis.title.y = element_text(margin = margin(t = 0, r = 15,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        legend.title = element_text(face = face.type),\n        legend.spacing = unit(20, \"pt\"),\n        legend.text = element_text(size = key_size),\n        plot.title = element_text(face = face.type, hjust = .5,\n                                  margin = margin(b = 10)),\n        plot.subtitle = element_text(hjust = .5),\n        plot.caption = element_text(hjust = 0, size = key_size,\n                                    margin = margin(t = 20)),\n        strip.background = element_rect(fill = \"white\", color = \"white\"),\n        strip.text = element_text(color = \"black\",\n                                  face = face.type))\n}\n\n\n\noutput_theme &lt;- theme_linedraw() + \n  theme_spacious(font_size = 12, bold = TRUE) +\n  theme(panel.border = element_rect(color = \"gray\"),\n        axis.line.x = element_line(color = \"gray\"),\n        axis.line.y = element_line(color = \"gray\"),\n        panel.grid.major.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\ntheme_set(output_theme)"
  },
  {
    "objectID": "slides/slides-class-8.html#create-your-own-theme-template-4",
    "href": "slides/slides-class-8.html#create-your-own-theme-template-4",
    "title": "Class 8",
    "section": "Create your own theme template",
    "text": "Create your own theme template\n \n\nggplot(adelie, aes(species, body_mass_g, \n                     color = sex, shape = island)) +\n  stat_summary(fun = mean, geom = \"point\") +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .1) +\n  coord_cartesian(ylim = c(3000, 4250)) +\n  scale_y_continuous(breaks = seq(3000, 4250, by = 250)) +\n  labs(title = \"A Plot Title\", subtitle = \"A subtitle\", tag = \"A)\",\n       x = \"Species\", y = \"Body Mass (g)\", color = \"Sex\", shape = \"Island\") +\n  scale_color_brewer(palette = \"Set1\")"
  },
  {
    "objectID": "slides/slides-class-8.html#histogram",
    "href": "slides/slides-class-8.html#histogram",
    "title": "Class 8",
    "section": "Histogram",
    "text": "Histogram\n \n\nggplot(penguins, aes(body_mass_g)) +\n  geom_histogram(bins = 20, fill = \"white\", color = \"black\")"
  },
  {
    "objectID": "slides/slides-class-8.html#bar-point-and-line",
    "href": "slides/slides-class-8.html#bar-point-and-line",
    "title": "Class 8",
    "section": "Bar, point, and line",
    "text": "Bar, point, and line\nWhen you have a categorical (nominal or ordinal) variable on the x-axis and you want to plot that against a continuous variable on the y-axis this is usually done in the form of a bar, point, or line plot.\n \n\nBar plots\nPoint plots\nLine plots"
  },
  {
    "objectID": "slides/slides-class-8.html#bar-plot",
    "href": "slides/slides-class-8.html#bar-plot",
    "title": "Class 8",
    "section": "Bar plot",
    "text": "Bar plot\n \n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_bar(stat = \"summary\", fun = mean)"
  },
  {
    "objectID": "slides/slides-class-8.html#point-plot",
    "href": "slides/slides-class-8.html#point-plot",
    "title": "Class 8",
    "section": "Point plot",
    "text": "Point plot\n \n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_point(stat = \"summary\", fun = mean)"
  },
  {
    "objectID": "slides/slides-class-8.html#point-plot---with-raw-values",
    "href": "slides/slides-class-8.html#point-plot---with-raw-values",
    "title": "Class 8",
    "section": "Point plot - with raw values",
    "text": "Point plot - with raw values\n \n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_jitter(width = .1, size = .75, alpha = .2) +\n  geom_point(stat = \"summary\", fun = mean, \n             size = 4, color = \"steelblue\")"
  },
  {
    "objectID": "slides/slides-class-8.html#line-plot",
    "href": "slides/slides-class-8.html#line-plot",
    "title": "Class 8",
    "section": "Line plot",
    "text": "Line plot\n \n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_line(stat = \"summary\", fun = mean, group = 1)"
  },
  {
    "objectID": "slides/slides-class-8.html#line-plot---with-raw-values",
    "href": "slides/slides-class-8.html#line-plot---with-raw-values",
    "title": "Class 8",
    "section": "Line plot - with raw values",
    "text": "Line plot - with raw values\n \n\nggplot(penguins, aes(species, body_mass_g)) +\n  geom_jitter(width = .1, size = .75, alpha = .2) +\n  geom_line(stat = \"summary\", fun = mean, group = 1) +\n  geom_point(stat = \"summary\", fun = mean, \n             size = 4, color = \"steelblue\")"
  },
  {
    "objectID": "slides/slides-class-8.html#scatterplot",
    "href": "slides/slides-class-8.html#scatterplot",
    "title": "Class 8",
    "section": "Scatterplot",
    "text": "Scatterplot\nWhen you have a continuous (interval or ratio) variable on the x-axis and you want to plot it against a continuous variable on the y-axis this is known as a scatterplot\n \n\nggplot(penguins, aes(bill_length_mm, body_mass_g)) +\n  geom_point() +\n  stat_smooth(method = \"lm\", color = \"forestgreen\")"
  },
  {
    "objectID": "slides/slides-class-7.html#outline",
    "href": "slides/slides-class-7.html#outline",
    "title": "Class 7",
    "section": "Outline",
    "text": "Outline\n\nYAML Header\nMarkdown\nR Code Chunks\nRender Document\nAdditional Elements"
  },
  {
    "objectID": "slides/slides-class-2.html#prepare",
    "href": "slides/slides-class-2.html#prepare",
    "title": "Class 2",
    "section": "Prepare",
    "text": "Prepare\n \nBefore starting this class:\n📦 Install readr, dplyr, tidyr, ggplot2 , Hmisc , RColorBrewer\n \nDownload sample data files: (right-click to download linked file)\n⬇️ class_2_cog_data.csv\n⬇️ class_2_mood_data.txt"
  },
  {
    "objectID": "slides/slides-class-2.html#outline",
    "href": "slides/slides-class-2.html#outline",
    "title": "Class 2",
    "section": "Outline",
    "text": "Outline\n \n\n\nImport: readr\n\nFile paths\nread_csv() and read_delim()\n\nMerge: dplyr\n\nbind_() functions\njoin_() functions\n\nRestructure: tidyr\n\npivot_wider()\npivot_longer()"
  },
  {
    "objectID": "slides/slides-class-2.html#pipe-operator-1",
    "href": "slides/slides-class-2.html#pipe-operator-1",
    "title": "Class 2",
    "section": "Pipe Operator",
    "text": "Pipe Operator\n \nThe pipe operator allows you to chain together a set of functions to conduct a sequence of manipulations on it. Conceptually, here’s what code written using the pipe operator looks like:\n \n\ndata |&gt;\n  step1 |&gt;\n  step2 |&gt;\n  step3\n\n\nWe start with our data. Then we do step1. Then we do step2. Then we do step3. The pipe ties it all together, enabling us to do multiple things to our data, all in one execution of code."
  },
  {
    "objectID": "slides/slides-class-2.html#pipe-operator-2",
    "href": "slides/slides-class-2.html#pipe-operator-2",
    "title": "Class 2",
    "section": "Pipe Operator",
    "text": "Pipe Operator\n \nThere are different approaches to writing code that performs multiple functions on the same object.\n \nHere is the standard, non-pipe operator way:\n\n# three steps: filter, calculate a mean, then select only some columns to keep\ndata_new &lt;- filter(data, y != \"c\")\ndata_new &lt;- mutate(data_new, x_mean = mean(x))\ndata_new &lt;- select(data_new, y, x_mean)\n\n\nAn alternative is to use the pipe operator |&gt;\n\n# three steps: filter, calculate a mean, then select only some columns to keep\ndata_new &lt;- data |&gt;\n  filter(y != \"c\") |&gt;\n  mutate(x_mean = mean(x)) |&gt;\n  select(y, x_mean)"
  },
  {
    "objectID": "slides/slides-class-2.html#pipe-operator-3",
    "href": "slides/slides-class-2.html#pipe-operator-3",
    "title": "Class 2",
    "section": "Pipe Operator",
    "text": "Pipe Operator\n \n\n# three steps: filter, calculate a mean, then select only some columns to keep\ndata_new &lt;- data |&gt;\n  filter(y != \"c\") |&gt;\n  mutate(x_mean = mean(x)) |&gt;\n  select(y, x_mean)\n\n\nWith the pipe operator, the result of the previous line gets passed (or piped) onto the next function.\n\nThe first line in this example is simply specifying the data frame that is being passed from one line to the next.\nNotice how I did not have to specify data inside the filter(), mutate(), and select(), functions. This makes the code more concise and easier to read.\nThe end result of the last function, then gets assigned to data_new &lt;-."
  },
  {
    "objectID": "slides/slides-class-2.html#file-paths",
    "href": "slides/slides-class-2.html#file-paths",
    "title": "Class 2",
    "section": "File Paths",
    "text": "File Paths\nR needs to know the full file path to the file on your computer in order to import it\n \n\n\nAbsolute file paths\n\n\nOn Macs:\nUsers/username/projects/project_name/a_file.csv\n \nOn Windows:\nC:\\username\\projects\\project_name\\a_file.csv"
  },
  {
    "objectID": "slides/slides-class-2.html#three-approaches-to-getting-the-right-file-path",
    "href": "slides/slides-class-2.html#three-approaches-to-getting-the-right-file-path",
    "title": "Class 2",
    "section": "Three approaches to getting the right file path",
    "text": "Three approaches to getting the right file path\n \n\n\nUse setwd()\nUse the RStudio Import Dataset GUI\nUse RProjects and here()\n\n\n\nNever… ever… ever… use option 1, setwd().\nInstead, you should use RProjects and here(). But we will not cover this until Class 5.\nFor now, we can just use the RStudio Import Dataset GUI to find the absolute file path."
  },
  {
    "objectID": "slides/slides-class-2.html#rstudio-import-dataset-gui",
    "href": "slides/slides-class-2.html#rstudio-import-dataset-gui",
    "title": "Class 2",
    "section": "RStudio Import Dataset GUI",
    "text": "RStudio Import Dataset GUI"
  },
  {
    "objectID": "slides/slides-class-2.html#rstudio-import-dataset-gui-1",
    "href": "slides/slides-class-2.html#rstudio-import-dataset-gui-1",
    "title": "Class 2",
    "section": "RStudio Import Dataset GUI",
    "text": "RStudio Import Dataset GUI"
  },
  {
    "objectID": "slides/slides-class-2.html#rstudio-import-dataset-gui-2",
    "href": "slides/slides-class-2.html#rstudio-import-dataset-gui-2",
    "title": "Class 2",
    "section": "RStudio Import Dataset GUI",
    "text": "RStudio Import Dataset GUI\n \n\n\n\n \n\nSelect Browse on the top right and select the data file you want to import.\nThe Data Preview window will let you see if it is importing it in the right format.\nYou can change the Import Options below.\nClick on the 📋 icon above the Code Preview window to copy the code.\nClick on Cancel to exit out of the Import GUI window\nPaste the code into your Untitled.R script\n\nThe most useful thing here will be the absolute file path."
  },
  {
    "objectID": "slides/slides-class-2.html#rstudio-import-dataset-gui-3",
    "href": "slides/slides-class-2.html#rstudio-import-dataset-gui-3",
    "title": "Class 2",
    "section": "RStudio Import Dataset GUI",
    "text": "RStudio Import Dataset GUI\n \n\n\n \n \n \n\n\n\n\n\n\nExploring Your Data\n\n\nWhen you want to just explore some data and don’t care about creating a reproducible script it can be perfectly acceptable to not copy and paste the code from Code Preview window and just select the Import button."
  },
  {
    "objectID": "slides/slides-class-2.html#types-of-data-files",
    "href": "slides/slides-class-2.html#types-of-data-files",
    "title": "Class 2",
    "section": "Types of Data Files",
    "text": "Types of Data Files\n \n\ncsv\ntab-delimited"
  },
  {
    "objectID": "slides/slides-class-2.html#csv-data-files",
    "href": "slides/slides-class-2.html#csv-data-files",
    "title": "Class 2",
    "section": "csv Data Files",
    "text": "csv Data Files\n \n\n\nCSV stands for “Comma-Separated Values.”\ncsv files are typically saved with .csv file extension (e.g., datafile.csv)\ncsv files are by far the easiest files to import into R and most software programs.\nI suggest any time you want to save/output a data file to your computer, do it in csv format."
  },
  {
    "objectID": "slides/slides-class-2.html#tab-delimited-data-files",
    "href": "slides/slides-class-2.html#tab-delimited-data-files",
    "title": "Class 2",
    "section": "tab-delimited Data Files",
    "text": "tab-delimited Data Files\n \n\n\ntab-delimited files are saved with the more standard .txt file extension (e.g., datafile.txt)\nThere are a lot of different types of delimiters\ntab-delimited files are a little more tedious to import\nYou have to memorize more arguments to import tab-delimited files"
  },
  {
    "objectID": "slides/slides-class-2.html#importing-data-files",
    "href": "slides/slides-class-2.html#importing-data-files",
    "title": "Class 2",
    "section": "Importing Data Files",
    "text": "Importing Data Files\nreadr\n \n\nlibrary(readr)\n\n# csv\ndata_import &lt;- read_csv(\"filepath/datafile.csv\")\n\n# tab-delimited\ndata_import &lt;- read_delim(\"filepath/datafile.txt\", delim = \"\\t\", \n                          escape_double = FALSE, trim_ws = TRUE)\n\n\n\nUse the RStudio Import Dataset GUI to get the filepath that you will need\nIn Class 5 you will learn a better way to specify file paths using RProjects and here::here()"
  },
  {
    "objectID": "slides/slides-class-2.html#merging-data-frames",
    "href": "slides/slides-class-2.html#merging-data-frames",
    "title": "Class 2",
    "section": "Merging Data Frames",
    "text": "Merging Data Frames\n \nYou might find yourself in a situation where you need to import multiple data files and merge them into a single data frame. There are two general classes of merging data\n \n\n\nBind\nJoin"
  },
  {
    "objectID": "slides/slides-class-2.html#bind",
    "href": "slides/slides-class-2.html#bind",
    "title": "Class 2",
    "section": "Bind",
    "text": "Bind\nCombining data frames together by stacking either the rows or columns\n\n \nRow Bind: same columns but different rows and stack them on top of each other"
  },
  {
    "objectID": "slides/slides-class-2.html#bind-1",
    "href": "slides/slides-class-2.html#bind-1",
    "title": "Class 2",
    "section": "Bind",
    "text": "Bind\nCombining data frames together by stacking either the rows or columns\n \nColumn Bind: same rows but different columns and stacks them side-by-side. This is a much less common situation than a row bind and can usually be accomplished with a join instead"
  },
  {
    "objectID": "slides/slides-class-2.html#bind-2",
    "href": "slides/slides-class-2.html#bind-2",
    "title": "Class 2",
    "section": "Bind",
    "text": "Bind\ndplyr\n \n\nlibrary(dplyr)\n\n# row bind\ndata_merged &lt;- bind_rows(data_1, data_2)\n\n# column bind\ndata_merged &lt;- bind_cols(data_1, data_2)"
  },
  {
    "objectID": "slides/slides-class-2.html#join",
    "href": "slides/slides-class-2.html#join",
    "title": "Class 2",
    "section": "Join",
    "text": "Join\nMerging data frames together that have at least one column in common with a mix of shared and unique entries in that column (e.g. Subject IDs).\n\n \n\n\n\n\n\nFor a full list and detailed description of the _join() functions see the dplyr documentation"
  },
  {
    "objectID": "slides/slides-class-2.html#full-join",
    "href": "slides/slides-class-2.html#full-join",
    "title": "Class 2",
    "section": "Full Join",
    "text": "Full Join\nFor the most part you can get away with just knowing how to do a full join using full_join() from the dplyr package\n\n \n\ndata_merged &lt;- full_join(data_1, data_2, by = \"Subject\")\n\n\n\n\n\n\nYou need to specify what are the key column(s) to join by - columns that are common between the data frames.\nOften times there is more than one key column that the data frames need to be joined by:\n\n\n\n\n\ndata_merged &lt;- full_join(data_1, data_2, by = c(\"Subject\", \"Session\"))"
  },
  {
    "objectID": "slides/slides-class-2.html#restructure-1",
    "href": "slides/slides-class-2.html#restructure-1",
    "title": "Class 2",
    "section": "Restructure",
    "text": "Restructure\n \nThe exact same data can be structured in different ways\n\nThere are two main formats that any data set can be structured as:\n \n\n\nWide: Variables are spread out across columns, making the data frame wider\n \n\n\n\nID\nStress\nCreativity\nMemory\n\n\n\n\n1\n5\n7\n8\n\n\n2\n3\n6\n7\n\n\n3\n4\n8\n6\n\n\n\n\n\n\nLong: Variables and values are spread across rows, making the data frame longer\n \n\n\n\nID\nTest Type\nScore\n\n\n\n\n1\nStress\n5\n\n\n1\nCreativity\n7\n\n\n1\nMemory\n8\n\n\n2\nStress\n3\n\n\n2\nCreativity\n6\n\n\n2\nMemory\n7\n\n\n3\nStress\n4\n\n\n3\nCreativity\n8\n\n\n3\nMemory\n6"
  },
  {
    "objectID": "slides/slides-class-2.html#restructure-2",
    "href": "slides/slides-class-2.html#restructure-2",
    "title": "Class 2",
    "section": "Restructure",
    "text": "Restructure\n \nAnd actually, you can have a mix of wide and long formatted data in a single data frame.\n \n\n\n\n\n\n\n\n\n\n\nParticipant ID\nSession\nStress Level\nCreativity\nMemory\n\n\n\n\n1\n1\n5\n7\n8\n\n\n1\n2\n4\n8\n9\n\n\n1\n3\n3\n9\n10\n\n\n2\n1\n6\n6\n7\n\n\n2\n2\n5\n7\n8\n\n\n2\n3\n4\n8\n9\n\n\n3\n1\n4\n8\n6\n\n\n3\n2\n3\n9\n7\n\n\n3\n3\n2\n10\n8"
  },
  {
    "objectID": "slides/slides-class-2.html#restructure-3",
    "href": "slides/slides-class-2.html#restructure-3",
    "title": "Class 2",
    "section": "Restructure",
    "text": "Restructure\n \n\nA good rule of thumb for formatting data is to have your variables (IVs and DVs) each have their own column.\nThis often results in:\n\nMeasured variables in wide format\nExperimental conditions or repeated-measures in long format\n\nRestructuring data involves changing the structure from long-to-wide (wider) or wide-to-long (longer)\nThe tidyr package provides useful functions to do this:\n\npivot_wider() “widens” data from long-to-wide\npivot_longer() “lengthens” data from wide-to-long"
  },
  {
    "objectID": "slides/slides-class-2.html#pivot_wider",
    "href": "slides/slides-class-2.html#pivot_wider",
    "title": "Class 2",
    "section": "pivot_wider()",
    "text": "pivot_wider()\n \n\n\nUsing the example data sets on previous slides, let’s restructure the long data frame to a wide format\nFirst let’s create the data frame - you can just copy and paste this code in an Untitled.R script:\n\n\n \n\ndata_long &lt;- data.frame(\n  ParticipantID = rep(1:3, each = 3),\n  TestType = rep(c(\"Stress Level\", \"Creativity\", \"Memory\"), times = 3),\n  Score = c(5, 7, 8, 3, 6, 7, 4, 8, 6)\n  )\n\nView(data_long)"
  },
  {
    "objectID": "slides/slides-class-2.html#pivot_wider-1",
    "href": "slides/slides-class-2.html#pivot_wider-1",
    "title": "Class 2",
    "section": "pivot_wider()",
    "text": "pivot_wider()\n \nThe two main arguments to specify in pivot_wider() are\n\n\nnames_from: The column name that contains the variables to create new columns by (e.g. “Test Type”). The values in this column will become column names in the wider data format.\nvalues_from: The column name that contains the values (e.g. “Score”).\n\n\n\nNow we can use pivot_wider() to convert it to a wide format:\n \n\nlibrary(tidyr)\n\ndata_wide &lt;- data_long |&gt;\n  pivot_wider(names_from = TestType,\n              values_from = Score)\n\nView(data_wide)"
  },
  {
    "objectID": "slides/slides-class-2.html#section",
    "href": "slides/slides-class-2.html#section",
    "title": "Class 2",
    "section": "",
    "text": "Column Names\n\n\nR does not like column names to have spaces in them, but it does allow it.\nNotice how in data_wide the column Stress Level contains a space. This is because the value in data_long had a space, which was not a problem then.\nclean_names() from janitor provides a convenient way to get rid of spaces and replace them with an _\n\nlibrary(janitor)\n\ndata_wide_clean &lt;- clean_names(data_wide, case = \"parse\")"
  },
  {
    "objectID": "slides/slides-class-2.html#pivot_longer",
    "href": "slides/slides-class-2.html#pivot_longer",
    "title": "Class 2",
    "section": "pivot_longer()",
    "text": "pivot_longer()\n \nThe three main arguments to specify in pivot_longer() are:\n\n\ncols: The column names that will be restructured to a longer format\nnames_to: The new column name that will contain values which correspond to the column names in the wide data\nvalues_to: The new column name that will contain the actual values in the wide data\n\n\n\nUsing pivot_longer() we can restructure the data back to long format:\n \n\ndata_long_again &lt;- data_wide |&gt;\n  pivot_longer(cols = any_of(c(\"Stress Level\", \"Creativity\", \"Memory\")),\n               names_to = \"TestType\",\n               values_to = \"Score\")\n\nView(data_long_again)"
  },
  {
    "objectID": "slides/slides-class-2.html#mixed-wide-and-long",
    "href": "slides/slides-class-2.html#mixed-wide-and-long",
    "title": "Class 2",
    "section": "Mixed Wide and Long",
    "text": "Mixed Wide and Long\n \nConverting from a wide data format to a mix of wide and long can be more complicated\n\nLet’s say we have a wide data set with multiple sessions of Stress , Creativity, and Memory.\n \nCopy and paste this:\n\ndata_sessions_wide &lt;- tibble(\n  ParticipantID = 1:3,\n  StressLevel_S1 = c(5, 6, 4),\n  Creativity_S1 = c(7, 6, 8),\n  Memory_S1 = c(8, 7, 6),\n  StressLevel_S2 = c(4, 5, 3),\n  Creativity_S2 = c(8, 7, 9),\n  Memory_S2 = c(9, 8, 7),\n  StressLevel_S3 = c(3, 4, 2),\n  Creativity_S3 = c(9, 8, 10),\n  Memory_S3 = c(10, 9, 8)\n)\n\nView(data_sessions_wide)"
  },
  {
    "objectID": "slides/slides-class-2.html#mixed-wide-and-long-1",
    "href": "slides/slides-class-2.html#mixed-wide-and-long-1",
    "title": "Class 2",
    "section": "Mixed Wide and Long",
    "text": "Mixed Wide and Long\n \nLet’s restructure this to 4 columns: Session, Stress Level, Creativity, and Memory.\nThere are two strategies for doing this:\n\nUsing pivot_longer(), separate(), and then pivot_wider()\nUse more complicated syntax in pivot_longer()\n\n\n\n# 1. Using pivot_longer(), separate(), and then pivot_wider()\ndata_sessions_1 &lt;- data_sessions_wide |&gt;\n  pivot_longer(cols = contains(\"_S\"),\n               names_to = \"Session\",\n               values_to = \"Score\") |&gt;\n  separate(Session, into = c(\"Test\", \"Session\")) |&gt;\n  pivot_wider(names_from = Test,\n              values_from = Score)\n\n# 2. Use more complicated syntax in pivot_longer()\ndata_sessions_2 &lt;- data_sessions_wide |&gt;\n  pivot_longer(cols = contains(\"_S\"),\n               names_to = c(\".value\", \"Session\"),\n               names_pattern = \"(.*)_(S\\\\d)\")"
  },
  {
    "objectID": "slides/slides-class-2.html#tidy-select-functions",
    "href": "slides/slides-class-2.html#tidy-select-functions",
    "title": "Class 2",
    "section": "Tidy Select Functions",
    "text": "Tidy Select Functions\n \n\n\n\n\n\n\nNote\n\n\nYou may find yourself in a situation where you need to select multiple columns in a argument but it can be tedious to type each every column, especially if the number of columns is larger.\nThere are what is known as tidy select functions to easily select column names, particularly if there is a consistent pattern to those column names.\nThis can be very useful in functions like pivot_longer(). In the examples provided on previous slides, we used some tidy select functions: any_of() and contains().\nTo learn more about what tidy select functions are available and what they do read the tidy select documentation."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "The purpose of this course is for you to gain a basic level of proficiency in 1) working with data, 2) data visualization, and 3) statistical computation in R. This course will cover the basics in each of these areas and from there you should be equipped to continue learning more on your own and from other courses.\nAlthough it will be applicable to a wide-range of disciplines, it is aimed for the undergraduate student in psychology. As such, in terms of statistical computation, the course only covers how to perform the basics of ANOVA and Regression that is typically taught in the psychology curriculum.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#course-format",
    "href": "index.html#course-format",
    "title": "Welcome!",
    "section": "Course Format",
    "text": "Course Format\nBefore starting the course you should read the following sections\n📖 What is R?\n📖 Prerequisites\nYou can navigate to different sections of the course on the left sidebar.\nMost pages will also have a page navigation on the right sidebar where you can navigate to different sections of the page you are currently on.\n\nClasses\nThe landing page for each class contains the class materials:\n📘 the actual content of the class\n🖥️ slides\nand more\nClass 1 - An Introduction to Working with Data in R\nClass 2 - Importing, Merging, and Restructuring Data\nClass 3 - Data Transformation\nClass 4 - Reproducible Projects\nClass 5 - Data Preparation\nClass 6 - Data Scoring\nClass 7 - Quarto Documents\nClass 8 - Data Visualization\nClass 9 - Statistical Analysis: Regression\nClass 10 - Statistical Analysis: ANOVA",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "classes/class-8.html",
    "href": "classes/class-8.html",
    "title": "Class 8",
    "section": "",
    "text": "The main objective of this class is to get familiar with the basics of creating data visualizations in R.",
    "crumbs": [
      "Classes",
      "Class 8"
    ]
  },
  {
    "objectID": "classes/class-8.html#outline",
    "href": "classes/class-8.html#outline",
    "title": "Class 8",
    "section": "Outline",
    "text": "Outline\n\nggplot2\nData and Aesthetic Layers\nGeometries Layer\nFacets and Statistics Layer\nCoordinates Layer\nTheme Layer\nCommon Types of Plots",
    "crumbs": [
      "Classes",
      "Class 8"
    ]
  },
  {
    "objectID": "classes/class-8.html#class-materials",
    "href": "classes/class-8.html#class-materials",
    "title": "Class 8",
    "section": "Class Materials",
    "text": "Class Materials\n📘 Class 8: Data Visualization\n🖥️ Slides - Full Screen\nPress M on the slides to bring up the menu to access options such as navigating to different sections",
    "crumbs": [
      "Classes",
      "Class 8"
    ]
  },
  {
    "objectID": "classes/class-5.html",
    "href": "classes/class-5.html",
    "title": "Class 5",
    "section": "",
    "text": "The main objective of this class is to understand the steps typically involved in the data preparation stage: creating a tidy raw data file from a messy raw data file.",
    "crumbs": [
      "Classes",
      "Class 5"
    ]
  },
  {
    "objectID": "classes/class-5.html#outline",
    "href": "classes/class-5.html#outline",
    "title": "Class 5",
    "section": "Outline",
    "text": "Outline\n\nSetup Project\nData\nTemplate R Script\nSetup\nImport Data\nTidy Data\nSave Data",
    "crumbs": [
      "Classes",
      "Class 5"
    ]
  },
  {
    "objectID": "classes/class-5.html#class-materials",
    "href": "classes/class-5.html#class-materials",
    "title": "Class 5",
    "section": "Class Materials",
    "text": "Class Materials\n📘 Class 5: Data Preparation",
    "crumbs": [
      "Classes",
      "Class 5"
    ]
  },
  {
    "objectID": "classes/class-2.html",
    "href": "classes/class-2.html",
    "title": "Class 2",
    "section": "",
    "text": "The main objective of this class is to get a basic handling on importing data, merging multiple data frames, and restructuring data frames between wide and long formats.",
    "crumbs": [
      "Classes",
      "Class 2"
    ]
  },
  {
    "objectID": "classes/class-2.html#prepare",
    "href": "classes/class-2.html#prepare",
    "title": "Class 2",
    "section": "Prepare",
    "text": "Prepare\nBefore starting this class:\n📦 Install readr, dplyr, tidyr, ggplot2 , Hmisc , RColorBrewer\nDownload sample data files:\n⬇️ class_2_cog_data.csv\n⬇️ class_2_mood_data.txt",
    "crumbs": [
      "Classes",
      "Class 2"
    ]
  },
  {
    "objectID": "classes/class-2.html#outline",
    "href": "classes/class-2.html#outline",
    "title": "Class 2",
    "section": "Outline",
    "text": "Outline\n\nImport: readr\n\nFile paths\nread_csv() and read_delim()\n\nMerge: dplyr\n\nbind_() functions\njoin_() functions\n\nRestructure: tidyr\n\npivot_wider()\npivot_longer()",
    "crumbs": [
      "Classes",
      "Class 2"
    ]
  },
  {
    "objectID": "classes/class-2.html#class-materials",
    "href": "classes/class-2.html#class-materials",
    "title": "Class 2",
    "section": "Class Materials",
    "text": "Class Materials\n📘 Class 2: Importing, Merging, and Restructuring Data\n✏️ Learning Activity\n🖥️ Slides - Full Screen\nPress M on the slides to bring up the menu to access options such as navigating to different sections",
    "crumbs": [
      "Classes",
      "Class 2"
    ]
  },
  {
    "objectID": "classes/class-1.html",
    "href": "classes/class-1.html",
    "title": "Class 1",
    "section": "",
    "text": "The main objective of this class is to get you a basic level of understanding of how to work with data in R.",
    "crumbs": [
      "Classes",
      "Class 1"
    ]
  },
  {
    "objectID": "classes/class-1.html#prepare",
    "href": "classes/class-1.html#prepare",
    "title": "Class 1",
    "section": "Prepare",
    "text": "Prepare\nBefore starting this class:\n📖 Read the Prerequisites page",
    "crumbs": [
      "Classes",
      "Class 1"
    ]
  },
  {
    "objectID": "classes/class-1.html#outline",
    "href": "classes/class-1.html#outline",
    "title": "Class 1",
    "section": "Outline",
    "text": "Outline\n\nBasics of using R\nData Frames\nBrief intro to data transformation, graphical visualization, and staistical computation",
    "crumbs": [
      "Classes",
      "Class 1"
    ]
  },
  {
    "objectID": "classes/class-1.html#class-materials",
    "href": "classes/class-1.html#class-materials",
    "title": "Class 1",
    "section": "Class Materials",
    "text": "Class Materials\n📘 Class 1: An Introduction to Working with Data in R\n🖥️ Slides - Full Screen\nPress M on the slides to bring up the menu to access options such as navigating to different sections",
    "crumbs": [
      "Classes",
      "Class 1"
    ]
  },
  {
    "objectID": "what-is-R.html",
    "href": "what-is-R.html",
    "title": "What is R?",
    "section": "",
    "text": "According to the R website\n\nR is a free software environment for statistical computing and graphics.\n\nLet’s unpack this a bit.\n\nFree is nice!\nStatistical computing is a general term referring to a large class of techniques that involves statistics, machine learning, and more.\nGraphics refers to creating visualizations of data and output from statistical computing.\n\nIt’s really all about data! We live in a data rich world. Our personal lives, the media, and the workplace are inundated with data. But data is often times obscure and not intuitive compared to how we interact with real-world objects. It is hidden behind numbers stored in columns, rows, and complex databases. There are also more units of data that we can realistically process and understand. As a result, data can easily be misleading and at worse be used to intentionally deceive and lie (see How to Lie with Statistics).\nA fundamental skill for the modern person, therefore, is to have some level of competency with working with and understanding data. Where it comes from, how it can be transformed, basic concepts about statistics and probability, and the graphical visualization of data.\nSo where does R come in?\nR is only one of many tools that are available to learn about data, process it, understand it with statistics, and visualize it for the purpose of communication and understanding.\nR is a coding language. There are pros and cons to this. Any coding language requires a steep learning curve but the underlying logic of most coding languages is the same, and therefore; it can introduce you to a world coding that allows a powerful level of control and customization that goes beyond what we can achieve through the more clunky interface of real-world objects and graphical user interfaces (GUI) on our monitors.\nDebates on which programming language you should learn and use are rampant on the internet and social media. For the basic undergraduate psychology student, R has a lot of advantages. Beyond that one may want to learn Python, Julia, or Matlab.\nRegardless of which programming language you learn, working with data through code provides a challenge that will open you up to the world of data. You will gain an appreciation for the level of mundanity and complexity that is involved in processing the vast amounts of data in this world. Through working with data yourself, you will also become a better consumer of data and information that you see in your own work, the news, and social media.\nIt all starts with gaining a basic level of proficiency in 1) working with data, 2) data visualization, and 3) statistical computation. This course will cover the basics in each of these areas using R and from there you should be equipped to continue learning more on your own and from other courses.",
    "crumbs": [
      "Course Information",
      "What is R?"
    ]
  },
  {
    "objectID": "sample_report.html",
    "href": "sample_report.html",
    "title": "Example Report",
    "section": "",
    "text": "Setup\n\n\nRequired Packages\nPlot Theme\nTable Theme\n\n\n\n\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(knitr)\nlibrary(kableExtra)\nlibrary(sjPlot)\nlibrary(ggplot2)\nlibrary(afex)\nlibrary(lme4)\nlibrary(lmerTest)\nlibrary(parameters)\nlibrary(effectsize)\nlibrary(ggeffects)\nlibrary(modelbased)\nlibrary(modeloutput)\n\n\n\n\n# set global ggplot theme\ntheme_spacious &lt;- function(font.size = 14, bold = TRUE){\n  key.size &lt;- trunc(font.size * .8)\n  if (bold == TRUE) {\n    face.type &lt;- \"bold\"\n  } else {\n    face.type &lt;- \"plain\"\n  }\n\n  theme(text = element_text(size = font.size),\n        axis.title.x = element_text(margin = margin(t = 15, r = 0,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        axis.title.y = element_text(margin = margin(t = 0, r = 15,\n                                                    b = 0, l = 0),\n                                    face = face.type),\n        legend.title = element_text(face = face.type),\n        legend.spacing = unit(20, \"pt\"),\n        legend.text = element_text(size = key.size),\n        plot.title = element_text(face = face.type, hjust = .5,\n                                  margin = margin(b = 10)),\n        plot.caption = element_text(hjust = 0, size = key.size,\n                                    margin = margin(t = 20)),\n        strip.background = element_rect(fill = \"white\", color = \"white\"),\n        strip.text = element_text(color = \"black\",\n                                  face = face.type))\n}\n\noutput_theme &lt;- theme_linedraw() + \n  theme_spacious(font.size = 12) + \n  theme(panel.border = element_rect(color = \"gray\"),\n        axis.line.x = element_line(color = \"gray\"),\n        axis.line.y = element_line(color = \"gray\"),\n        panel.grid.minor.x = element_blank(),\n        panel.grid.minor.y = element_blank())\n\ntheme_set(output_theme)\n\n\n\n\ntable_theme &lt;- function(x, digits = 3, title = NULL, note = NULL) {\n  kable(x, digits = digits, caption = title) |&gt;\n    kable_classic(position = \"left\") |&gt;\n    kable_styling(full_width = FALSE, position = \"left\") |&gt;\n    footnote(general = note)\n}\n\n\n\n\nData\n\n\nImport Data\nGet Data Ready For Models\n\n\n\n\nrecall_import &lt;- read_csv(here(\"data\", \"Recall_Data.csv\"))\n\n\n\n\nrecall_data &lt;- recall_import |&gt;\n  mutate(Memory_Strategy = factor(Memory_Strategy,\n                                    levels = c(\"Rote Repetition\", \n                                               \"Visual Imagery\")),\n         Presentation_Rate = factor(Presentation_Rate,\n                                    levels = c(1, 2, 4)))\n\n\n\n\nANOVA\n\n\nModel\nFigures\nSummary Output\n\n\n\n\nanova_2way &lt;- aov_car(Recall_Performance ~ \n                      Presentation_Rate*Memory_Strategy + \n                      Error(Subject/Presentation_Rate),\n                    data = recall_data)\n\nContrasts set to contr.sum for the following variables: Memory_Strategy\n\n\n\nCodeanova_tables(anova_2way, \n             contrast = c(\"Presentation_Rate\", \"Memory_Strategy\"), \n             at = c(\"Presentation_Rate\", \"Memory_Strategy\"))\n\n\n\n\n\n\n\nANOVA Table: Recall_Performance\n\n\nTerm\nSS\nSS Error\ndf\ndf Error\nMS\nMS Error\nF\np\nηp2\n\nωp2\n\n\n\n\n\nMemory_Strategy\n8957.952\n7007.126\n1.000\n 88.000\n79.626\n 0.708\n112.500\n&lt;0.001\n0.561\n0.553\n\n\nPresentation_Rate\n5953.815\n9445.486\n1.950\n171.619\n55.037\n 0.992\n 55.469\n&lt;0.001\n0.387\n0.260\n\n\nMemory_Strategy:Presentation_Rate\n 272.792\n9445.486\n1.950\n171.619\n55.037\n21.655\n  2.541\n    0.083\n0.028\n0.010\n\n\n\n\nModel: aov_car(Recall_Performance ~ (Presentation_Rate) * (Memory_Strategy) + Error(Subject/(Presentation_Rate)))\n\n\ndf correction: Greenhouse-Geisser\n\n\nN = 90\n\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Presentation_Rate\n\n\nLevel 1\nLevel 2\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\n\n1\n2\n −6.093\n −8.091 — −4.095\n1.005\n88 \n −6.061\n&lt;0.001\n−0.562\n\n\n1\n4\n−11.496\n−13.703 — −9.288\n1.111\n88 \n−10.348\n&lt;0.001\n−1.060\n\n\n2\n4\n −5.402\n −7.697 — −3.108\n1.155\n88 \n −4.679\n&lt;0.001\n−0.498\n\n\n\np-values are uncorrected.\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Memory_Strategy\n\n\nLevel 1\nLevel 2\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\nRote Repetition\nVisual Imagery\n−11.520\n−13.678 — −9.362\n1.086\n88 \n−10.607\n&lt;0.001\n−1.062\n\n\np-values are uncorrected.\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Presentation_Rate x Memory_Strategy\n\n\nLevel 1\nLevel 2\nMemory_Strategy\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\n\n1\n2\nRote Repetition\n −8.500\n−11.326 — −5.674 \n1.422\n88 \n−5.978\n&lt;0.001\n−0.784\n\n\n1\n2\nVisual Imagery\n −3.687\n −6.512 — −0.861 \n1.422\n88 \n−2.593\n    0.011\n−0.340\n\n\n1\n4\nRote Repetition\n−13.149\n−16.271 — −10.027\n1.571\n88 \n−8.369\n&lt;0.001\n−1.212\n\n\n1\n4\nVisual Imagery\n −9.842\n−12.964 — −6.720 \n1.571\n88 \n−6.265\n&lt;0.001\n−0.908\n\n\n2\n4\nRote Repetition\n −4.649\n −7.894 — −1.404 \n1.633\n88 \n−2.847\n    0.005\n−0.429\n\n\n2\n4\nVisual Imagery\n −6.156\n −9.400 — −2.911 \n1.633\n88 \n−3.770\n&lt;0.001\n−0.568\n\n\n\np-values are uncorrected.\n\n\n\n\n\n\n\n\nPost-hoc Comparisons: Memory_Strategy x Presentation_Rate\n\n\nLevel 1\nLevel 2\nPresentation_Rate\nDifference\nCI 95%\nSE\ndf\nt\np\nCohen's D\n\n\n\n\nRote Repetition\nVisual Imagery\n1\n−14.227\n−17.464 — −10.989\n1.629\n88 \n−8.732\n&lt;0.001\n−1.312\n\n\nRote Repetition\nVisual Imagery\n2\n −9.413\n−12.687 — −6.139 \n1.647\n88 \n−5.714\n&lt;0.001\n−0.868\n\n\nRote Repetition\nVisual Imagery\n4\n−10.920\n−14.328 — −7.512 \n1.715\n88 \n−6.368\n&lt;0.001\n−1.007\n\n\n\np-values are uncorrected.\n\n\n\n\n\n\n\n\n\nCodeggplot(recall_data, aes(x = Presentation_Rate, y = Recall_Performance,\n                 color = Memory_Strategy, fill = Memory_Strategy)) +\n  geom_flat_violin(aes(fill = Memory_Strategy),\n                   position = position_nudge(x = .1, y = 0),\n                   adjust = 1.5, trim = FALSE, \n                   alpha = .5, colour = NA) +\n  geom_point(aes(as.numeric(Presentation_Rate) - .15), \n             position = position_jitter(width = .05), alpha = .2) +\n  stat_summary(aes(group = Memory_Strategy),\n               fun = mean, geom = \"line\", linewidth = 1) +\n  stat_summary(fun = mean, geom = \"point\", size = 3) + \n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", \n               width = .1) +\n  labs(x = \"Presentation_Rate\", y = \"Recall Performance\") +\n  scale_color_brewer(palette = \"Set1\", name = \"Memory Strategy\") +\n  scale_fill_brewer(palette = \"Set1\") +\n  guides(fill = \"none\")\n\n\n\n\n\n\n\n\n\n\nCodesummary(anova_2way)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                                  Sum Sq num Df Error SS den Df   F value\n(Intercept)                       102348      1   7007.1     88 1285.3515\nMemory_Strategy                     8958      1   7007.1     88  112.4997\nPresentation_Rate                   5954      2   9445.5    176   55.4694\nMemory_Strategy:Presentation_Rate    273      2   9445.5    176    2.5415\n                                   Pr(&gt;F)    \n(Intercept)                       &lt; 2e-16 ***\nMemory_Strategy                   &lt; 2e-16 ***\nPresentation_Rate                 &lt; 2e-16 ***\nMemory_Strategy:Presentation_Rate 0.08164 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMauchly Tests for Sphericity\n\n                                  Test statistic p-value\nPresentation_Rate                        0.97448 0.32474\nMemory_Strategy:Presentation_Rate        0.97448 0.32474\n\n\nGreenhouse-Geisser and Huynh-Feldt Corrections\n for Departure from Sphericity\n\n                                   GG eps Pr(&gt;F[GG])    \nPresentation_Rate                 0.97511    &lt; 2e-16 ***\nMemory_Strategy:Presentation_Rate 0.97511    0.08311 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                                     HF eps   Pr(&gt;F[HF])\nPresentation_Rate                 0.9969213 2.353114e-19\nMemory_Strategy:Presentation_Rate 0.9969213 8.181690e-02\n\n\n\n\n\nFooter\n\n\nSession Info\nCitations\nCSS Styling\n\n\n\n\nCodesessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS 14.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] modeloutput_0.0.1 modelbased_0.8.6  ggeffects_1.2.3   effectsize_0.8.3 \n [5] parameters_0.21.1 lmerTest_3.1-3    afex_1.3-0        lme4_1.1-33      \n [9] Matrix_1.6-0      ggplot2_3.4.2     sjPlot_2.8.14     kableExtra_1.3.4 \n[13] knitr_1.43        dplyr_1.1.2       readr_2.1.4       here_1.0.1       \n\nloaded via a namespace (and not attached):\n  [1] gridExtra_2.3       sandwich_3.0-2      rlang_1.1.1        \n  [4] magrittr_2.0.3      multcomp_1.4-25     compiler_4.3.0     \n  [7] systemfonts_1.0.4   vctrs_0.6.2         reshape2_1.4.4     \n [10] rvest_1.0.3         stringr_1.5.0       crayon_1.5.2       \n [13] pkgconfig_2.0.3     fastmap_1.1.1       backports_1.4.1    \n [16] labeling_0.4.2      utf8_1.2.3          rmarkdown_2.22     \n [19] tzdb_0.4.0          nloptr_2.0.3        purrr_1.0.1        \n [22] bit_4.0.5           xfun_0.39           jsonlite_1.8.4     \n [25] sjmisc_2.8.9        cluster_2.1.4       broom_1.0.5        \n [28] parallel_4.3.0      R6_2.5.1            RColorBrewer_1.1-3 \n [31] stringi_1.7.12      rpart_4.1.19        car_3.1-2          \n [34] boot_1.3-28.1       numDeriv_2016.8-1.1 estimability_1.4.1 \n [37] Rcpp_1.0.10         modelr_0.1.11       zoo_1.8-12         \n [40] base64enc_0.1-3     nnet_7.3-18         splines_4.3.0      \n [43] tidyselect_1.2.0    rstudioapi_0.14     abind_1.4-5        \n [46] yaml_2.3.7          codetools_0.2-19    sjlabelled_1.2.0   \n [49] lattice_0.21-8      tibble_3.2.1        plyr_1.8.8         \n [52] withr_2.5.0         bayestestR_0.13.1   coda_0.19-4        \n [55] evaluate_0.21       foreign_0.8-84      survival_3.5-5     \n [58] xml2_1.3.4          pillar_1.9.0        carData_3.0-5      \n [61] checkmate_2.2.0     insight_0.19.2      generics_0.1.3     \n [64] vroom_1.6.3         rprojroot_2.0.3     hms_1.1.3          \n [67] commonmark_1.9.0    munsell_0.5.0       scales_1.2.1       \n [70] minqa_1.2.5         xtable_1.8-4        glue_1.6.2         \n [73] Hmisc_5.1-0         emmeans_1.8.6       tools_4.3.0        \n [76] data.table_1.14.8   webshot_0.5.4       mvtnorm_1.2-0      \n [79] grid_4.3.0          tidyr_1.3.0         datawizard_0.7.1   \n [82] colorspace_2.1-0    nlme_3.1-162        performance_0.10.4 \n [85] htmlTable_2.4.1     Formula_1.2-5       cli_3.6.1          \n [88] fansi_1.0.4         viridisLite_0.4.2   gt_0.9.0.9000      \n [91] svglite_2.1.1       sjstats_0.18.2      gtable_0.3.3       \n [94] sass_0.4.7          digest_0.6.31       TH.data_1.1-2      \n [97] farver_2.1.1        htmlwidgets_1.6.2   htmltools_0.5.5    \n[100] lifecycle_1.0.3     httr_1.4.6          bit64_4.0.5        \n[103] MASS_7.3-58.4      \n\n\n\n\n\nCodelapply(names(sessionInfo()$otherPkgs), citation)\n\n[[1]]\nTo cite package 'modeloutput' in publications use:\n\n  Tsukahara J (2023). _modeloutput: Get full output from statistical\n  models in nice looking tables_. R package version 0.0.1.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {modeloutput: Get full output from statistical models in nice looking tables},\n    author = {Jason Tsukahara},\n    year = {2023},\n    note = {R package version 0.0.1},\n  }\n\n[[2]]\nTo cite 'modelbased' in publications use:\n\n  Makowski, D., Ben-Shachar, M. S., Patil, I., & Lüdecke, D. (2020).\n  Estimation of Model-Based Predictions, Contrasts and Means. CRAN.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Estimation of Model-Based Predictions, Contrasts and Means.},\n    author = {Dominique Makowski and Mattan S. Ben-Shachar and Indrajeet Patil and Daniel Lüdecke},\n    journal = {CRAN},\n    year = {2020},\n    url = {https://github.com/easystats/modelbased},\n  }\n\n[[3]]\nTo cite package 'ggeffects' in publications use:\n\n  Lüdecke D (2018). \"ggeffects: Tidy Data Frames of Marginal Effects\n  from Regression Models.\" _Journal of Open Source Software_, *3*(26),\n  772. doi:10.21105/joss.00772 &lt;https://doi.org/10.21105/joss.00772&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {ggeffects: Tidy Data Frames of Marginal Effects from Regression Models.},\n    volume = {3},\n    doi = {10.21105/joss.00772},\n    number = {26},\n    journal = {Journal of Open Source Software},\n    author = {Daniel Lüdecke},\n    year = {2018},\n    pages = {772},\n  }\n\n[[4]]\nTo cite effectsize in publications use:\n\n  Ben-Shachar M, Lüdecke D, Makowski D (2020). effectsize: Estimation\n  of Effect Size Indices and Standardized Parameters. Journal of Open\n  Source Software, 5(56), 2815. doi: 10.21105/joss.02815\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {{e}ffectsize: Estimation of Effect Size Indices and Standardized Parameters},\n    author = {Mattan S. Ben-Shachar and Daniel Lüdecke and Dominique Makowski},\n    year = {2020},\n    journal = {Journal of Open Source Software},\n    volume = {5},\n    number = {56},\n    pages = {2815},\n    publisher = {The Open Journal},\n    doi = {10.21105/joss.02815},\n    url = {https://doi.org/10.21105/joss.02815},\n  }\n\n[[5]]\nTo cite package 'parameters' in publications use:\n\n  Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting,\n  Computing and Exploring the Parameters of Statistical Models using\n  R.\" _Journal of Open Source Software_, *5*(53), 2445.\n  doi:10.21105/joss.02445 &lt;https://doi.org/10.21105/joss.02445&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Extracting, Computing and Exploring the Parameters of Statistical Models using {R}.},\n    volume = {5},\n    doi = {10.21105/joss.02445},\n    number = {53},\n    journal = {Journal of Open Source Software},\n    author = {Daniel Lüdecke and Mattan S. Ben-Shachar and Indrajeet Patil and Dominique Makowski},\n    year = {2020},\n    pages = {2445},\n  }\n\n[[6]]\nTo cite lmerTest in publications use:\n\n  Kuznetsova A, Brockhoff PB, Christensen RHB (2017). \"lmerTest\n  Package: Tests in Linear Mixed Effects Models.\" _Journal of\n  Statistical Software_, *82*(13), 1-26. doi:10.18637/jss.v082.i13\n  &lt;https://doi.org/10.18637/jss.v082.i13&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {{lmerTest} Package: Tests in Linear Mixed Effects Models},\n    author = {Alexandra Kuznetsova and Per B. Brockhoff and Rune H. B. Christensen},\n    journal = {Journal of Statistical Software},\n    year = {2017},\n    volume = {82},\n    number = {13},\n    pages = {1--26},\n    doi = {10.18637/jss.v082.i13},\n  }\n\n[[7]]\nTo cite package 'afex' in publications use:\n\n  Singmann H, Bolker B, Westfall J, Aust F, Ben-Shachar M (2023).\n  _afex: Analysis of Factorial Experiments_. R package version 1.3-0,\n  &lt;https://CRAN.R-project.org/package=afex&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {afex: Analysis of Factorial Experiments},\n    author = {Henrik Singmann and Ben Bolker and Jake Westfall and Frederik Aust and Mattan S. Ben-Shachar},\n    year = {2023},\n    note = {R package version 1.3-0},\n    url = {https://CRAN.R-project.org/package=afex},\n  }\n\n[[8]]\nTo cite lme4 in publications use:\n\n  Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015).\n  Fitting Linear Mixed-Effects Models Using lme4. Journal of\n  Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01.\n\nA BibTeX entry for LaTeX users is\n\n  @Article{,\n    title = {Fitting Linear Mixed-Effects Models Using {lme4}},\n    author = {Douglas Bates and Martin M{\\\"a}chler and Ben Bolker and Steve Walker},\n    journal = {Journal of Statistical Software},\n    year = {2015},\n    volume = {67},\n    number = {1},\n    pages = {1--48},\n    doi = {10.18637/jss.v067.i01},\n  }\n\n[[9]]\nTo cite package 'Matrix' in publications use:\n\n  Bates D, Maechler M, Jagan M (2023). _Matrix: Sparse and Dense Matrix\n  Classes and Methods_. R package version 1.6-0,\n  &lt;https://CRAN.R-project.org/package=Matrix&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {Matrix: Sparse and Dense Matrix Classes and Methods},\n    author = {Douglas Bates and Martin Maechler and Mikael Jagan},\n    year = {2023},\n    note = {R package version 1.6-0},\n    url = {https://CRAN.R-project.org/package=Matrix},\n  }\n\n[[10]]\nTo cite ggplot2 in publications, please use\n\n  H. Wickham. ggplot2: Elegant Graphics for Data Analysis.\n  Springer-Verlag New York, 2016.\n\nA BibTeX entry for LaTeX users is\n\n  @Book{,\n    author = {Hadley Wickham},\n    title = {ggplot2: Elegant Graphics for Data Analysis},\n    publisher = {Springer-Verlag New York},\n    year = {2016},\n    isbn = {978-3-319-24277-4},\n    url = {https://ggplot2.tidyverse.org},\n  }\n\n[[11]]\nTo cite package 'sjPlot' in publications use:\n\n  Lüdecke D (2023). _sjPlot: Data Visualization for Statistics in\n  Social Science_. R package version 2.8.14,\n  &lt;https://CRAN.R-project.org/package=sjPlot&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {sjPlot: Data Visualization for Statistics in Social Science},\n    author = {Daniel Lüdecke},\n    year = {2023},\n    note = {R package version 2.8.14},\n    url = {https://CRAN.R-project.org/package=sjPlot},\n  }\n\n[[12]]\nTo cite package 'kableExtra' in publications use:\n\n  Zhu H (2021). _kableExtra: Construct Complex Table with 'kable' and\n  Pipe Syntax_. R package version 1.3.4,\n  &lt;https://CRAN.R-project.org/package=kableExtra&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {kableExtra: Construct Complex Table with 'kable' and Pipe Syntax},\n    author = {Hao Zhu},\n    year = {2021},\n    note = {R package version 1.3.4},\n    url = {https://CRAN.R-project.org/package=kableExtra},\n  }\n\n[[13]]\nTo cite package 'knitr' in publications use:\n\n  Xie Y (2023). _knitr: A General-Purpose Package for Dynamic Report\n  Generation in R_. R package version 1.43, &lt;https://yihui.org/knitr/&gt;.\n\n  Yihui Xie (2015) Dynamic Documents with R and knitr. 2nd edition.\n  Chapman and Hall/CRC. ISBN 978-1498716963\n\n  Yihui Xie (2014) knitr: A Comprehensive Tool for Reproducible\n  Research in R. In Victoria Stodden, Friedrich Leisch and Roger D.\n  Peng, editors, Implementing Reproducible Computational Research.\n  Chapman and Hall/CRC. ISBN 978-1466561595\n\nTo see these entries in BibTeX format, use 'print(&lt;citation&gt;,\nbibtex=TRUE)', 'toBibtex(.)', or set\n'options(citation.bibtex.max=999)'.\n\n[[14]]\nTo cite package 'dplyr' in publications use:\n\n  Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A\n  Grammar of Data Manipulation_. R package version 1.1.2,\n  &lt;https://CRAN.R-project.org/package=dplyr&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {dplyr: A Grammar of Data Manipulation},\n    author = {Hadley Wickham and Romain François and Lionel Henry and Kirill Müller and Davis Vaughan},\n    year = {2023},\n    note = {R package version 1.1.2},\n    url = {https://CRAN.R-project.org/package=dplyr},\n  }\n\n[[15]]\nTo cite package 'readr' in publications use:\n\n  Wickham H, Hester J, Bryan J (2023). _readr: Read Rectangular Text\n  Data_. R package version 2.1.4,\n  &lt;https://CRAN.R-project.org/package=readr&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {readr: Read Rectangular Text Data},\n    author = {Hadley Wickham and Jim Hester and Jennifer Bryan},\n    year = {2023},\n    note = {R package version 2.1.4},\n    url = {https://CRAN.R-project.org/package=readr},\n  }\n\n[[16]]\nTo cite package 'here' in publications use:\n\n  Müller K (2020). _here: A Simpler Way to Find Your Files_. R package\n  version 1.0.1, &lt;https://CRAN.R-project.org/package=here&gt;.\n\nA BibTeX entry for LaTeX users is\n\n  @Manual{,\n    title = {here: A Simpler Way to Find Your Files},\n    author = {Kirill Müller},\n    year = {2020},\n    note = {R package version 1.0.1},\n    url = {https://CRAN.R-project.org/package=here},\n  }\n\n\n\n\n\n.tab-content {\n  border-style: none;\n}\n\nh1 {\n  color: #005098;\n}\n\nh2 {\n  color: #96834a !important;\n  font-weight: 600 !important;\n}\n\na {\n  color: #005098;\n}\n\na:hover {\n  color: #96834a !important;\n}\n\n.quarto-title-meta-heading {\n  color: #96834a;\n  font-weight: 600 !important;\n}\n\n.sidebar nav[role=doc-toc] ul&gt;li&gt;a, .sidebar nav[role=doc-toc] ul&gt;li&gt;ul&gt;li&gt;a {\n  color: #005098 !important;\n  border-left: 2px solid #ECE5D7;\n  border-left-color: solid #ECE5D7;\n}\n\n.sidebar nav[role=doc-toc] ul&gt;li&gt;a.active, .sidebar nav[role=doc-toc] ul&gt;li&gt;ul&gt;li&gt;a.active {\n  color: #005098 !important;\n  font-weight: 600;\n  border-left: 2px solid #CBB879;\n  border-left-color: solid #CBB879;\n}\n\n.sidebar nav[role=doc-toc] ul&gt;li&gt;a:hover, .sidebar nav[role=doc-toc] ul&gt;li&gt;ul&gt;li&gt;a:hover {\n  color: #005098 !important;\n  font-weight: 600;\n  border-left: 2px solid #CBB879;\n  border-left-color: solid #CBB879;\n}\n\n.nav-link {\n  color: #495057;\n}\n\n.nav-tabs .nav-link.active, .nav-tabs .nav-item.show .nav-link {\n  color: #96834a !important;\n}\n\n.code-tools-button {\n  color: #96834a !important;\n}\n\n.dropdown-toggle {\n  color: #005098 !important;\n}"
  },
  {
    "objectID": "classes/class-3.html",
    "href": "classes/class-3.html",
    "title": "Class 3",
    "section": "",
    "text": "The main objective of this class is to get familiar with the basic functions in dplyr for performing basic data transformations.",
    "crumbs": [
      "Classes",
      "Class 3"
    ]
  },
  {
    "objectID": "classes/class-3.html#prepare",
    "href": "classes/class-3.html#prepare",
    "title": "Class 3",
    "section": "Prepare",
    "text": "Prepare\nBefore starting this class:\n📦 Install the gt package\nDownload sample data files:\n⬇️ class_3_repetition_rawdata.txt\n⬇️ class_3_mnemonic_rawdata.csv",
    "crumbs": [
      "Classes",
      "Class 3"
    ]
  },
  {
    "objectID": "classes/class-3.html#outline",
    "href": "classes/class-3.html#outline",
    "title": "Class 3",
    "section": "Outline",
    "text": "Outline\n\nThe tidyverse and dplyr\nRename columns: rename()\nFilter rows: filter()\nSelect columns: select()\nCompute and transform values: mutate()\nAggregate data: summarise()",
    "crumbs": [
      "Classes",
      "Class 3"
    ]
  },
  {
    "objectID": "classes/class-3.html#class-materials",
    "href": "classes/class-3.html#class-materials",
    "title": "Class 3",
    "section": "Class Materials",
    "text": "Class Materials\n📘 Class 3: Data Transformation\n🖥️ Slides - Full Screen\nPress M on the slides to bring up the menu to access options such as navigating to different sections",
    "crumbs": [
      "Classes",
      "Class 3"
    ]
  },
  {
    "objectID": "classes/class-7.html",
    "href": "classes/class-7.html",
    "title": "Class 7",
    "section": "",
    "text": "The main objective of this class is to learn how to use Quarto Documents to create an HTML report that contains data visualizations and statistical analyses.",
    "crumbs": [
      "Classes",
      "Class 7"
    ]
  },
  {
    "objectID": "classes/class-7.html#outline",
    "href": "classes/class-7.html#outline",
    "title": "Class 7",
    "section": "Outline",
    "text": "Outline\n\nYAML Header\nMarkdown\nR Code Chunks\nRender Document\nAdditional Elements",
    "crumbs": [
      "Classes",
      "Class 7"
    ]
  },
  {
    "objectID": "classes/class-7.html#class-materials",
    "href": "classes/class-7.html#class-materials",
    "title": "Class 7",
    "section": "Class Materials",
    "text": "Class Materials\n📘 Class 7: Quarto Documents\n🖥️ Slides - Full Screen\nPress M on the slides to bring up the menu to access options such as navigating to different sections",
    "crumbs": [
      "Classes",
      "Class 7"
    ]
  },
  {
    "objectID": "classes/class-4.html",
    "href": "classes/class-4.html",
    "title": "Class 4",
    "section": "",
    "text": "The main objective of this class is to learn what it means to have a reproducible project and how to organize a project to meet reproducibility requirements.",
    "crumbs": [
      "Classes",
      "Class 4"
    ]
  },
  {
    "objectID": "classes/class-4.html#outline",
    "href": "classes/class-4.html#outline",
    "title": "Class 4",
    "section": "Outline",
    "text": "Outline\n\nReproducibility\nProject Workflow\nFile Organization\nImporting Data",
    "crumbs": [
      "Classes",
      "Class 4"
    ]
  },
  {
    "objectID": "classes/class-4.html#class-materials",
    "href": "classes/class-4.html#class-materials",
    "title": "Class 4",
    "section": "Class Materials",
    "text": "Class Materials\n📘 Class 4: Reproducible Projects\n🖥️ Slides - Full Screen\nPress M on the slides to bring up the menu to access options such as navigating to different sections",
    "crumbs": [
      "Classes",
      "Class 4"
    ]
  },
  {
    "objectID": "prerequisites.html",
    "href": "prerequisites.html",
    "title": "Prerequisites",
    "section": "",
    "text": "If you do not have R or RStudio installed on your computer, then follow the install instructions below.\nIf you already have R or RStudio installed on your computer, then is it recommended to Update Software for this course.",
    "crumbs": [
      "Course Information",
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#sec-install-software",
    "href": "prerequisites.html#sec-install-software",
    "title": "Prerequisites",
    "section": "Install Software",
    "text": "Install Software\n\nInstall R\nFirst you need to download the latest version of R from their website https://www.r-project.org\n\nSelect CRAN on the left, just under Download\nSelect the first option under 0-Cloud\nSelect the download option depending on your computer\nSelect the base installation (for Windows) or the Latest Release (for Mac)\nOpen and Run the installation file\n\n\n\nInstall RStudio\nThe easiest way to interact with R is through the RStudio environment. To do this you need to download RStudio\n\nSelect the Free version of RStudio Desktop\nSelect the download option depending on your computer",
    "crumbs": [
      "Course Information",
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#sec-update-software",
    "href": "prerequisites.html#sec-update-software",
    "title": "Prerequisites",
    "section": "Update Software",
    "text": "Update Software\n\nUpdate R\nIf you already have R installed, but want to update it to the most current version follow these steps.\nWarning: When updating R (not RStudio), it may remove all packages you have installed\nFirst check what version of R you have installed.\n\nOpen RStudio\nIn the console window you will see the R version you are running (e.g., R version 4.1.0)\nIf you have an R version older than 4.0.0 than you need to update R.\nRun the following lines of code in your console window. This is an easy way to re-install all your currently installed packages. This step will save a list of packages to re-install later.\n\n\n# Save current packages and their versions to object called ip\n\nip &lt;- installed.packages()\nip\n\n# Save the object as an .rds file\n\nsaveRDS(ip, \"CurrentPackages.rds\")\n\n\nExit out of all R or RStudio windows\nDownload and install the latest version of R (see the section on installing R above)\nOpen RStudio\nCheck if your previously installed packages are installed using the Packages tab in the bottom right window\nIf you need to re-install your previous packages, then run the following lines of code\n\n\n# After updating R, load the file and reinstall packages\n\nip &lt;- readRDS(\"CurrentPackages.rds\")\n\ninstall.packages(ip[,1])\n\n\n\nUpdate RStudio\nGo to Help -&gt; Check for Updates",
    "crumbs": [
      "Course Information",
      "Prerequisites"
    ]
  },
  {
    "objectID": "prerequisites.html#getting-to-know-rstudio",
    "href": "prerequisites.html#getting-to-know-rstudio",
    "title": "Prerequisites",
    "section": "Getting to Know RStudio",
    "text": "Getting to Know RStudio\nWhile R is the actual programming software that executes the code, RStudio is an environment for interacting with R, writing R scripts, managing and organizing projects, and much more. When you open RStudio, it will open a window to the R console within the RStudio environment.\nGo ahead an open the RStudio application on your computer.\nWhen you open a fresh session of RStudio there are 3 window panes open. The Console window, the Environment window, and the Files window. Go ahead and navigate to File -&gt; New File -&gt; R Script. You should now see something similar to the image below\n\n\n\n\n\nFigure 1: RStudio window panes\n\n\n\n\n\n\n\n\nThere are 4 window panes and each one has it’s own set of tabs associated with it:\n\nThe Console window (the bottom left window pane) is where code is executed and output is displayed.\nThe Source window (the top left window pane) is where you will write your code to create a script file. When you open a new script file you will see a blank sheet where you can start writing the script. When you execute lines of code from here you will see it being executed in the Console window.\nThe Source window is also where you can view data frames you have just imported or created. In the image above, notice the different tabs in the Source window. There are two “Untitled” script files open and one data frame called ‘data’.\nThe Environment window (top right window pane) is where you can see any data frames, variables, or functions you have created. Go ahead and type the following in your Console window and hit enter.\n\n\nwelcome_message &lt;- \"hello\"\n\nYou should now see the variable welcome_message in the Environment window pane\n\nThe Files window (the bottom right window pane) is where you can see your computer’s directories, plots you create, manage packages, and see help documentation.\n\nYou can also Customize RStudio settings and appearances.\n\nCustomizing RStudio\nComing soon…",
    "crumbs": [
      "Course Information",
      "Prerequisites"
    ]
  },
  {
    "objectID": "slides/slides-class-1.html#prepare",
    "href": "slides/slides-class-1.html#prepare",
    "title": "Class 1",
    "section": "Prepare",
    "text": "Prepare\n \nBefore starting this class:\n📖 Read the Prerequisites page\n \nOutline\n\n\nR Basics\nData Frames\nBrief intro to\n\nData transformation\nGraphical visualization\nStatistical analysis"
  },
  {
    "objectID": "slides/slides-class-1.html#script-files",
    "href": "slides/slides-class-1.html#script-files",
    "title": "Class 1",
    "section": "Script Files",
    "text": "Script Files\n \nTo create a new R script go to\nFile -&gt; New File -&gt; R Script\n \nThis course will refer to two types of R script files:\n\nReproducible script file: Script file for actually processing and analyzing your data. Can reproduce your steps of processing and analysis.\n\nThis is the file you actually save to process your data\nIs commented and polished enough to share with others.\n\n\n\n\nScratchpad script file: A script file for testing, debugging, and exploring your data.\n\nOften saved as Untitled.R or not saved at all\nAlternatively, you can just execute code directly in the console"
  },
  {
    "objectID": "slides/slides-class-1.html#sec-running-r-code",
    "href": "slides/slides-class-1.html#sec-running-r-code",
    "title": "Class 1",
    "section": "Running R Code",
    "text": "Running R Code\nTwo ways of executing R code\n \n\n\nTyping code in an R script file and executing R code line-by-line Ctrl + Enter.\nTyping code directly in the console window\n\n\n\n1 + 2\n3 * 9"
  },
  {
    "objectID": "slides/slides-class-1.html#sec-creating-r-objects",
    "href": "slides/slides-class-1.html#sec-creating-r-objects",
    "title": "Class 1",
    "section": "Creating R Objects",
    "text": "Creating R Objects\n \n\n\nObjects are created using the assignment operator, &lt;-.\nobject &lt;- functions or values.\n\n\n\nGo ahead and type the following two lines of code in your scratchpad script file/console and execute the lines of code.\n \n\nmy_first_object &lt;- \"hello\"\nmy_second_object &lt;- c(5,6,7,8)\n\n \n\n\nYou should now see my_first_object and my_second_object in your Environment window\nNote that R is case sensitive"
  },
  {
    "objectID": "slides/slides-class-1.html#sec-using-functions",
    "href": "slides/slides-class-1.html#sec-using-functions",
    "title": "Class 1",
    "section": "Using Functions",
    "text": "Using Functions\nAnything you do in R is by using functions\n \n\n\nLearning R is learning what functions are available and how to use them.\nExample: there is a function to create a sequence of numbers, seq().\n\n\n\nseq(1, 100, by = 10)\n\n \n\n\n\nFunctions take arguments\nIf you don’t label argument names, then the order of arguments matters!\n\n\n\nseq(from = 1, to = 100, by = 10)\nseq(to = 100, by = 10, from = 1)\nseq(1, 100, 10)"
  },
  {
    "objectID": "slides/slides-class-1.html#helper-function",
    "href": "slides/slides-class-1.html#helper-function",
    "title": "Class 1",
    "section": "Helper Function",
    "text": "Helper Function\n?function_name()\n \n\nYou should make frequent use of the helper function ?\n\ne.g., ?seq()\n\nThe names of arguments\nWhat the arguments do\nArgument default values\n\nYou don’t have to and you almost never will specify all the possible arguments.\nIn some cases it might be important to know what the default value of an argument is."
  },
  {
    "objectID": "slides/slides-class-1.html#r-packages",
    "href": "slides/slides-class-1.html#r-packages",
    "title": "Class 1",
    "section": "R Packages",
    "text": "R Packages\n \n\nFunctions are organized in R packages\nR comes with a set of R packages and functions\nDevelopers and other researchers have created a lot of R packages specifically for use in psychology research\nMost R packages are hosted on The Comprehensive R Archive Network - CRAN.\n\nOthers may be hosted on GitHub"
  },
  {
    "objectID": "slides/slides-class-1.html#install-and-load-packages",
    "href": "slides/slides-class-1.html#install-and-load-packages",
    "title": "Class 1",
    "section": "Install and Load Packages",
    "text": "Install and Load Packages\n \nTo install packages from CRAN is easy\n\ninstall.packages(\"dplyr\")\n\n \n\nInstalling the package installs it on your computer\nWhen you want to use the functions in the package you need to load the package into your current environment\n\n\n\nlibrary(dplyr)"
  },
  {
    "objectID": "slides/slides-class-1.html#example-data-set",
    "href": "slides/slides-class-1.html#example-data-set",
    "title": "Class 1",
    "section": "Example Data Set",
    "text": "Example Data Set\nWe will use a data set from the palmerpenguins package"
  },
  {
    "objectID": "slides/slides-class-1.html#data-frames-1",
    "href": "slides/slides-class-1.html#data-frames-1",
    "title": "Class 1",
    "section": "Data Frames",
    "text": "Data Frames\n \n\n\nLet’s create a new script - a reproducible script to use for this class\nYou should always load packages at the top of the script\n\n\n\n\n# load packages\nlibrary(palmerpenguins)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# import data\ndata_import &lt;- penguins\n\n \n\n\n\n\n\n\n\n\nNote\n\n\nCommenting\nIt is a good idea to comment your code to provide organization and clarity as to what the code is doing"
  },
  {
    "objectID": "slides/slides-class-1.html#viewing-the-data",
    "href": "slides/slides-class-1.html#viewing-the-data",
    "title": "Class 1",
    "section": "Viewing the Data",
    "text": "Viewing the Data\nIn scratchpad script / console\n \n\nView(data_import)"
  },
  {
    "objectID": "slides/slides-class-1.html#viewing-the-data-1",
    "href": "slides/slides-class-1.html#viewing-the-data-1",
    "title": "Class 1",
    "section": "Viewing the Data",
    "text": "Viewing the Data\nIn scratchpad script / console\n \nGet columns names\n\ncolnames(data_import)\n## [1] \"species\"           \"island\"            \"bill_length_mm\"   \n## [4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n## [7] \"sex\"               \"year\"\n\n \nSneak peak of data\n\nhead(data_import)\n## # A tibble: 6 × 8\n##   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n##   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n## 1 Adelie  Torgersen           39.1          18.7               181        3750\n## 2 Adelie  Torgersen           39.5          17.4               186        3800\n## 3 Adelie  Torgersen           40.3          18                 195        3250\n## 4 Adelie  Torgersen           NA            NA                  NA          NA\n## 5 Adelie  Torgersen           36.7          19.3               193        3450\n## 6 Adelie  Torgersen           39.3          20.6               190        3650\n## # ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;"
  },
  {
    "objectID": "slides/slides-class-1.html#viewing-the-data-2",
    "href": "slides/slides-class-1.html#viewing-the-data-2",
    "title": "Class 1",
    "section": "Viewing the Data",
    "text": "Viewing the Data\nIn scratchpad script / console\n \n\n\nUse $ to refer to a column in a data frame\n\n\nGet unique values in a column\n\nunique(data_import$species)\n## [1] Adelie    Gentoo    Chinstrap\n## Levels: Adelie Chinstrap Gentoo"
  },
  {
    "objectID": "slides/slides-class-1.html#types-of-values",
    "href": "slides/slides-class-1.html#types-of-values",
    "title": "Class 1",
    "section": "Types of Values",
    "text": "Types of Values\n \nClasses are types of values that exist in R. Here are a list of some common value types:\n\n\ncharacter (or non-numeric) \"hello\", \"goodbye\"\ndouble (or numeric) 2, 32.55\ninteger 5, 99\nlogical TRUE, FALSE\nmissing NA NaN"
  },
  {
    "objectID": "slides/slides-class-1.html#types-of-values-1",
    "href": "slides/slides-class-1.html#types-of-values-1",
    "title": "Class 1",
    "section": "Types of Values",
    "text": "Types of Values\nIn scratchpad script / console\n \nTo evaluate the type of values in a column you can use typeof()\n\ntypeof(data_import$bill_depth_mm)\n## [1] \"double\"\ntypeof(data_import$flipper_length_mm)\n## [1] \"integer\"\n\n \nTo change the class of values in an object you can use as.character() , as.numeric() , as.double() , as.integer() , as.logical() functions.\n\nas.character(data_import$bill_depth_mm)\n##   [1] \"18.7\" \"17.4\" \"18\"   NA     \"19.3\" \"20.6\" \"17.8\" \"19.6\" \"18.1\" \"20.2\"\n##  [11] \"17.1\" \"17.3\" \"17.6\" \"21.2\" \"21.1\" \"17.8\" \"19\"   \"20.7\" \"18.4\" \"21.5\"\n##  [21] \"18.3\" \"18.7\" \"19.2\" \"18.1\" \"17.2\" \"18.9\" \"18.6\" \"17.9\" \"18.6\" \"18.9\"\n##  [31] \"16.7\" \"18.1\" \"17.8\" \"18.9\" \"17\"   \"21.1\" \"20\"   \"18.5\" \"19.3\" \"19.1\"\n##  [41] \"18\"   \"18.4\" \"18.5\" \"19.7\" \"16.9\" \"18.8\" \"19\"   \"18.9\" \"17.9\" \"21.2\"\n##  [51] \"17.7\" \"18.9\" \"17.9\" \"19.5\" \"18.1\" \"18.6\" \"17.5\" \"18.8\" \"16.6\" \"19.1\"\n##  [61] \"16.9\" \"21.1\" \"17\"   \"18.2\" \"17.1\" \"18\"   \"16.2\" \"19.1\" \"16.6\" \"19.4\"\n##  [71] \"19\"   \"18.4\" \"17.2\" \"18.9\" \"17.5\" \"18.5\" \"16.8\" \"19.4\" \"16.1\" \"19.1\"\n##  [81] \"17.2\" \"17.6\" \"18.8\" \"19.4\" \"17.8\" \"20.3\" \"19.5\" \"18.6\" \"19.2\" \"18.8\"\n##  [91] \"18\"   \"18.1\" \"17.1\" \"18.1\" \"17.3\" \"18.9\" \"18.6\" \"18.5\" \"16.1\" \"18.5\"\n## [101] \"17.9\" \"20\"   \"16\"   \"20\"   \"18.6\" \"18.9\" \"17.2\" \"20\"   \"17\"   \"19\"  \n## [111] \"16.5\" \"20.3\" \"17.7\" \"19.5\" \"20.7\" \"18.3\" \"17\"   \"20.5\" \"17\"   \"18.6\"\n## [121] \"17.2\" \"19.8\" \"17\"   \"18.5\" \"15.9\" \"19\"   \"17.6\" \"18.3\" \"17.1\" \"18\"  \n## [131] \"17.9\" \"19.2\" \"18.5\" \"18.5\" \"17.6\" \"17.5\" \"17.5\" \"20.1\" \"16.5\" \"17.9\"\n## [141] \"17.1\" \"17.2\" \"15.5\" \"17\"   \"16.8\" \"18.7\" \"18.6\" \"18.4\" \"17.8\" \"18.1\"\n## [151] \"17.1\" \"18.5\" \"13.2\" \"16.3\" \"14.1\" \"15.2\" \"14.5\" \"13.5\" \"14.6\" \"15.3\"\n## [161] \"13.4\" \"15.4\" \"13.7\" \"16.1\" \"13.7\" \"14.6\" \"14.6\" \"15.7\" \"13.5\" \"15.2\"\n## [171] \"14.5\" \"15.1\" \"14.3\" \"14.5\" \"14.5\" \"15.8\" \"13.1\" \"15.1\" \"14.3\" \"15\"  \n## [181] \"14.3\" \"15.3\" \"15.3\" \"14.2\" \"14.5\" \"17\"   \"14.8\" \"16.3\" \"13.7\" \"17.3\"\n## [191] \"13.6\" \"15.7\" \"13.7\" \"16\"   \"13.7\" \"15\"   \"15.9\" \"13.9\" \"13.9\" \"15.9\"\n## [201] \"13.3\" \"15.8\" \"14.2\" \"14.1\" \"14.4\" \"15\"   \"14.4\" \"15.4\" \"13.9\" \"15\"  \n## [211] \"14.5\" \"15.3\" \"13.8\" \"14.9\" \"13.9\" \"15.7\" \"14.2\" \"16.8\" \"14.4\" \"16.2\"\n## [221] \"14.2\" \"15\"   \"15\"   \"15.6\" \"15.6\" \"14.8\" \"15\"   \"16\"   \"14.2\" \"16.3\"\n## [231] \"13.8\" \"16.4\" \"14.5\" \"15.6\" \"14.6\" \"15.9\" \"13.8\" \"17.3\" \"14.4\" \"14.2\"\n## [241] \"14\"   \"17\"   \"15\"   \"17.1\" \"14.5\" \"16.1\" \"14.7\" \"15.7\" \"15.8\" \"14.6\"\n## [251] \"14.4\" \"16.5\" \"15\"   \"17\"   \"15.5\" \"15\"   \"13.8\" \"16.1\" \"14.7\" \"15.8\"\n## [261] \"14\"   \"15.1\" \"15.2\" \"15.9\" \"15.2\" \"16.3\" \"14.1\" \"16\"   \"15.7\" \"16.2\"\n## [271] \"13.7\" NA     \"14.3\" \"15.7\" \"14.8\" \"16.1\" \"17.9\" \"19.5\" \"19.2\" \"18.7\"\n## [281] \"19.8\" \"17.8\" \"18.2\" \"18.2\" \"18.9\" \"19.9\" \"17.8\" \"20.3\" \"17.3\" \"18.1\"\n## [291] \"17.1\" \"19.6\" \"20\"   \"17.8\" \"18.6\" \"18.2\" \"17.3\" \"17.5\" \"16.6\" \"19.4\"\n## [301] \"17.9\" \"19\"   \"18.4\" \"19\"   \"17.8\" \"20\"   \"16.6\" \"20.8\" \"16.7\" \"18.8\"\n## [311] \"18.6\" \"16.8\" \"18.3\" \"20.7\" \"16.6\" \"19.9\" \"19.5\" \"17.5\" \"19.1\" \"17\"  \n## [321] \"17.9\" \"18.5\" \"17.9\" \"19.6\" \"18.7\" \"17.3\" \"16.4\" \"19\"   \"17.3\" \"19.7\"\n## [331] \"17.3\" \"18.8\" \"16.6\" \"19.9\" \"18.8\" \"19.4\" \"19.5\" \"16.5\" \"17\"   \"19.8\"\n## [341] \"18.1\" \"18.2\" \"19\"   \"18.7\""
  },
  {
    "objectID": "slides/slides-class-1.html#factors",
    "href": "slides/slides-class-1.html#factors",
    "title": "Class 1",
    "section": "Factors",
    "text": "Factors\nIn scratchpad script / console\n \n\ntypeof(data_import$species)\n## [1] \"integer\"\nunique(data_import$species)\n## [1] Adelie    Gentoo    Chinstrap\n## Levels: Adelie Chinstrap Gentoo\nis.factor(data_import$species)\n## [1] TRUE\n\n \n\n\nFactors are a special type of column that represent levels of a category with an order to those levels.\nThe actual values in Factors can be of type character, double, integer, or logical.\nFactors become especially important in data visualization and statistical analysis."
  },
  {
    "objectID": "slides/slides-class-1.html#creating-factors",
    "href": "slides/slides-class-1.html#creating-factors",
    "title": "Class 1",
    "section": "Creating Factors",
    "text": "Creating Factors\nIn scratchpad script / console\n \nYou can set a column of values as a factor by using factor()\n\nfactor(data_import$year, levels = c(2007, 2008, 2009))"
  },
  {
    "objectID": "slides/slides-class-1.html#palmerpenguins",
    "href": "slides/slides-class-1.html#palmerpenguins",
    "title": "Class 1",
    "section": "palmerpenguins",
    "text": "palmerpenguins\n \nLet’s take a look at three variables\n\nspecies\nflipper length\nbody mass"
  },
  {
    "objectID": "slides/slides-class-1.html#data-transformation-1",
    "href": "slides/slides-class-1.html#data-transformation-1",
    "title": "Class 1",
    "section": "Data Transformation",
    "text": "Data Transformation\n \n\n\nCompute the mean flipper length and body mass for each species of penguin\n\n\n\n# transform data\ndata_plot &lt;- data_import |&gt;\n  mutate(.by = species,\n         flipper_length_mm.mean = mean(flipper_length_mm, na.rm = TRUE),\n         body_mass_g.mean = mean(body_mass_g, na.rm = TRUE))\n\n \n\n\n\nStrategy: Stay in the data frame!\n\nStore variables and computations in columns in the data frame\n\n\n\n\n\nNot advised\n\nflipper_length_mm.mean &lt;- mean(data_import$flipper_length_mm, na.rm = TRUE)\nbody_mass_g.mean &lt;- mean(data_import$body_mass_g, na.rm = TRUE)"
  },
  {
    "objectID": "slides/slides-class-1.html#data-transformation-2",
    "href": "slides/slides-class-1.html#data-transformation-2",
    "title": "Class 1",
    "section": "Data Transformation",
    "text": "Data Transformation\n \n\n\nCompute the mean flipper length and body mass for each species of penguin\n\n\n\ndata_plot &lt;- data_import |&gt;\n  mutate(.by = species,\n         flipper_length_mm.mean = mean(flipper_length_mm, na.rm = TRUE),\n         body_mass_g.mean = mean(body_mass_g, na.rm = TRUE))\n\n \n\nThe |&gt; notation says pass data_import into the mutate() function\nThen the result of mutate() is assigned to a new object, data_plot"
  },
  {
    "objectID": "slides/slides-class-1.html#data-transformation-3",
    "href": "slides/slides-class-1.html#data-transformation-3",
    "title": "Class 1",
    "section": "Data Transformation",
    "text": "Data Transformation\n \n\n\nCompute the mean flipper length and body mass for each species of penguin\n\n\n\ndata_plot &lt;- data_import |&gt;\n  mutate(.by = species,\n         flipper_length_mm.mean = mean(flipper_length_mm, na.rm = TRUE),\n         body_mass_g.mean = mean(body_mass_g, na.rm = TRUE))\n\n\n\nView(data_plot)"
  },
  {
    "objectID": "slides/slides-class-1.html#ggplot2---data-and-aesthetics-layer",
    "href": "slides/slides-class-1.html#ggplot2---data-and-aesthetics-layer",
    "title": "Class 1",
    "section": "ggplot2 - data and aesthetics layer",
    "text": "ggplot2 - data and aesthetics layer\n \n\n# visualize data\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species))"
  },
  {
    "objectID": "slides/slides-class-1.html#ggplot2---geometries-layer",
    "href": "slides/slides-class-1.html#ggplot2---geometries-layer",
    "title": "Class 1",
    "section": "ggplot2 - geometries layer",
    "text": "ggplot2 - geometries layer\n \n\n# visualize data\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species)) +\n  geom_point()"
  },
  {
    "objectID": "slides/slides-class-1.html#ggplot2---theme",
    "href": "slides/slides-class-1.html#ggplot2---theme",
    "title": "Class 1",
    "section": "ggplot2 - theme",
    "text": "ggplot2 - theme\n \n\n# visualize data\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species)) +\n  geom_point() +\n  theme_classic()"
  },
  {
    "objectID": "slides/slides-class-1.html#ggplot2",
    "href": "slides/slides-class-1.html#ggplot2",
    "title": "Class 1",
    "section": "ggplot2",
    "text": "ggplot2\n \n\n# visualize data\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species)) +\n  geom_point() +\n  geom_hline(aes(yintercept = body_mass_g.mean, color = species)) +\n  geom_vline(aes(xintercept = flipper_length_mm.mean, color = species)) +\n  theme_classic()"
  },
  {
    "objectID": "slides/slides-class-1.html#correlation",
    "href": "slides/slides-class-1.html#correlation",
    "title": "Class 1",
    "section": "Correlation",
    "text": "Correlation\n \n\n# statistical analysis\ncor.test(data_import$body_mass_g, data_import$flipper_length_mm)\n## \n##  Pearson's product-moment correlation\n## \n## data:  data_import$body_mass_g and data_import$flipper_length_mm\n## t = 32.722, df = 340, p-value &lt; 2.2e-16\n## alternative hypothesis: true correlation is not equal to 0\n## 95 percent confidence interval:\n##  0.843041 0.894599\n## sample estimates:\n##       cor \n## 0.8712018"
  },
  {
    "objectID": "slides/slides-class-1.html#class-1-reproducible-script",
    "href": "slides/slides-class-1.html#class-1-reproducible-script",
    "title": "Class 1",
    "section": "Class 1: Reproducible Script",
    "text": "Class 1: Reproducible Script\n \n\n# load packages\nlibrary(palmerpenguins)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# import data\ndata_import &lt;- penguins\n\n# transform data\ndata_plot &lt;- data_import |&gt;\n  mutate(.by = species,\n         flipper_length_mm.mean = mean(flipper_length_mm, na.rm = TRUE),\n         body_mass_g.mean = mean(body_mass_g, na.rm = TRUE))\n\n# visualize data\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species)) +\n  geom_point() +\n  geom_hline(aes(yintercept = body_mass_g.mean, color = species)) +\n  geom_vline(aes(xintercept = flipper_length_mm.mean, color = species)) +\n  theme_classic()\n\n# statistical analysis\ncor.test(data_import$body_mass_g, data_import$flipper_length_mm)"
  },
  {
    "objectID": "slides/slides-class-3.html#prepare",
    "href": "slides/slides-class-3.html#prepare",
    "title": "Class 3",
    "section": "Prepare",
    "text": "Prepare\n \nBefore starting this class:\n📦 Install the gt package\n \nDownload sample data files: (right-click to download linked file)\n⬇️ class_3_repetition_rawdata.txt\n⬇️ class_3_mnemonic_rawdata.csv"
  },
  {
    "objectID": "slides/slides-class-3.html#outline",
    "href": "slides/slides-class-3.html#outline",
    "title": "Class 3",
    "section": "Outline",
    "text": "Outline\n \n\n\nThe tidyverse and dplyr\nRename columns: rename()\nFilter rows: filter()\nSelect columns: select()\nCompute and transform values: mutate()\nAggregate data: summarise()"
  },
  {
    "objectID": "slides/slides-class-3.html#this-is-the-way",
    "href": "slides/slides-class-3.html#this-is-the-way",
    "title": "Class 3",
    "section": "This is The Way",
    "text": "This is The Way\n \nAlthough you will be learning R in this class, it might be more appropriate to say that you are learning the tidyverse.\n \n\nThe tidyverse is a set of packages that share an underlying design philosophy, grammar, and data structures. The tidyverse consists of packages that are simple and intuitive to use and will take you from importing data (with readr), restructuring and transforming data (with tidyr and dplyr), and to graphically visualizing data (with ggplot2)."
  },
  {
    "objectID": "slides/slides-class-3.html#section",
    "href": "slides/slides-class-3.html#section",
    "title": "Class 3",
    "section": "",
    "text": "The language of the dplyr package will be the underlying framework for how you will think about manipulating and transforming data in R."
  },
  {
    "objectID": "slides/slides-class-3.html#section-1",
    "href": "slides/slides-class-3.html#section-1",
    "title": "Class 3",
    "section": "",
    "text": "dplyr uses intuitive language that you are already familiar with.\n\nrename() renames columns\nfilter() filters rows based on their values in specified columns\nselect() selects (or removes) columns\nmutate() creates new columns based on transformation from other columns, or edits values within existing columns\nsummarise() aggregates across rows to create a summary statistic (means, standard deviations, etc.)\n\n\nFor more information on these functions Visit the dplyr webpage"
  },
  {
    "objectID": "slides/slides-class-3.html#example-data-set-1",
    "href": "slides/slides-class-3.html#example-data-set-1",
    "title": "Class 3",
    "section": "Example Data Set",
    "text": "Example Data Set\n \nUse what you learned in Class 2 and import the two data files:\n⬇️ class_3_repetition_rawdata.txt\n⬇️ class_3_mnemonic_rawdata.csv\n \nTry to figure out how to import the data yourself (hint: use the Import Datatset GUI to help identify the correct file path and import parameters)\n \n\n\nShow the Code\nlibrary(readr)\n\nrepetition_import &lt;- read_delim(\"data/class_3_repetition_rawdata.txt\", \n                                delim = \"\\t\", escape_double = FALSE, \n                                trim_ws = TRUE)\n\nmnemonic_import &lt;- read_csv(\"data/class_3_mnemonic_rawdata.csv\")"
  },
  {
    "objectID": "slides/slides-class-3.html#example-data-set-2",
    "href": "slides/slides-class-3.html#example-data-set-2",
    "title": "Class 3",
    "section": "Example Data Set",
    "text": "Example Data Set\n \nThese data come from a hypothetical (I made it up) research study to compare the effectiveness of two memory techniques, a mnemonic technique and a spaced repetition technique, for improving memory retention. Participants were randomly assigned to one of the two memory techniques and completed 3 memory tests (A, B, and C). The number of correctly recalled words for each memory test was recorded in the two data files by research assistants."
  },
  {
    "objectID": "slides/slides-class-3.html#example-data-set-3",
    "href": "slides/slides-class-3.html#example-data-set-3",
    "title": "Class 3",
    "section": "Example Data Set",
    "text": "Example Data Set\n \nUse what you learned from Class 1 to explore the data\n\n\nwhat are the column names?\nwhat type of values are in each column?\n\n\n\nIt turns out that the research assistant who ran participants in the spaced repetition condition did not follow the lab’s protocol for recording data 🤦‍♀️\nThey:\n\nused wrong column names,\nrecorded the memory tests as X, Y, and Z (A, B, and C, respectively),\nleft out what condition these data were from\ngave some particpants less than 3 memory tests! 🤬"
  },
  {
    "objectID": "slides/slides-class-3.html#rename",
    "href": "slides/slides-class-3.html#rename",
    "title": "Class 3",
    "section": "rename()",
    "text": "rename()\n \nFirst, let’s fix the RA’s mistake by renaming the columns in the spaced repetition data as they are named in the mnemonic data. We can do so using the rename() function. The format for this function looks something like:\n \n\nrename(new_name = old_name)\n\n\n\nHere is how we would rename the columns in the spaced repetition data we imported.\n \n\nlibrary(dplyr)\n\nrepetition_data &lt;- repetition_import |&gt;\n  rename(participant_id = `subject number`,\n         word_list = List,\n         recall_correct = recallCorrect)\n\n\n\n\nFor more options on how to use rename() see the documentation here"
  },
  {
    "objectID": "slides/slides-class-3.html#filter",
    "href": "slides/slides-class-3.html#filter",
    "title": "Class 3",
    "section": "filter()",
    "text": "filter()\n \nfilter() is an inclusive filter and requires the use of logical statements.\n\n\nHere are a list of some commone logical operators in R:\n\n\nIn addition to the logical operators, other functions can be used in filter(), such as:\n\nis.na() - include if missing\n!is.na() - include if not missing\nbetween() - values that are between a certain range of numbers\nnear() - values that are near a certain value\n\n\n\n\nFor more options on how to use filter() see the documentation here."
  },
  {
    "objectID": "slides/slides-class-3.html#filter-1",
    "href": "slides/slides-class-3.html#filter-1",
    "title": "Class 3",
    "section": "filter()",
    "text": "filter()\n \nLet’s remove rows that correspond to those participants that did not complete 3 memory tests. It turns out that those participants were always ran on Thursday or Friday, must have been a bad day for the research assistant 😢.\n \nWe can use filter() to remove rows that have Thursday or Friday in the day column.\n \n\nrepetition_data &lt;- repetition_data |&gt;\n  filter(day != \"Thursday\", day != \"Friday\")"
  },
  {
    "objectID": "slides/slides-class-3.html#select",
    "href": "slides/slides-class-3.html#select",
    "title": "Class 3",
    "section": "select()",
    "text": "select()\n \nselect() allows you to select which columns to keep and/or remove.\n \n\nselect(columns, to, keep)\n\n\n\n\nselect(-columns, -to, -remove)\n\n\n\n \nselect() can be used with more complex operators and tidyselect functions, see the documentation here."
  },
  {
    "objectID": "slides/slides-class-3.html#select-1",
    "href": "slides/slides-class-3.html#select-1",
    "title": "Class 3",
    "section": "select()",
    "text": "select()\n \nFor the repetition data, let’s only keep the following columns\n\n\nparticipant_id\nword_list\nrecall_correct\n\n\n\nrepetition_data &lt;- repetition_data |&gt;\n  select(participant_id, word_list, recall_correct)\n\n\nAnother way to do this would be:\n\nrepetition_data &lt;- repetition_data |&gt;\n  select(-day, -time, -computer_station)"
  },
  {
    "objectID": "slides/slides-class-3.html#mutate",
    "href": "slides/slides-class-3.html#mutate",
    "title": "Class 3",
    "section": "mutate()",
    "text": "mutate()\n \nmutate() is a very powerful function. It basically allows you to do any computation or transformation on the values in the data frame. See the full documentation here.\n \n\nThe basic format for mutate goes something like:\n\nmutate(column_name = value,\n       another_col = a_function(),\n       last_col = col1 + col2)\n\n\n\n\nWithin mutate() the = sign functions similarly to the assignment operator &lt;-, where the result of whatever is on the right-hand side of = gets assigned to the column that is specified on the left-hand side (an existing column or a new one you are creating)."
  },
  {
    "objectID": "slides/slides-class-3.html#mutate-1",
    "href": "slides/slides-class-3.html#mutate-1",
    "title": "Class 3",
    "section": "mutate()",
    "text": "mutate()\nAdd a new column\n \nWe need to create a column specifying what condition the spaced repetition data came from, dang RA!\n\n \n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(condition = \"spaced repetition\")\n\n\n\n\nEasy!\nNow let’s do something a little more complicated."
  },
  {
    "objectID": "slides/slides-class-3.html#case_when",
    "href": "slides/slides-class-3.html#case_when",
    "title": "Class 3",
    "section": "case_when()",
    "text": "case_when()\n \ncase_when() is basically a sequence of if else type of statements where each statement is evaluated, if it is true then it is given a certain value, else the next statement is evaluated, and so on.\n\n \nThe basic format of case_when() looks like:\n\nmutate(a_column = case_when(a logical statement ~ a value,\n                            another statement ~ another value,\n                            .default = and another value))"
  },
  {
    "objectID": "slides/slides-class-3.html#case_when-1",
    "href": "slides/slides-class-3.html#case_when-1",
    "title": "Class 3",
    "section": "case_when()",
    "text": "case_when()\n \nLet’s see an example of this with the spaced repetition data. We need to change the values in the word_list column so that X is A, Y is B, and Z is C.\n \n\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(word_list = case_when(word_list == \"X\" ~ \"A\",\n                               word_list == \"Y\" ~ \"B\",\n                               word_list == \"Z\" ~ \"C\"))\n\n\n\n\nJust to be clear, you can create an entirely new column this way\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(new_word_list = case_when(word_list == \"X\" ~ \"A\",\n                                   word_list == \"Y\" ~ \"B\",\n                                   word_list == \"Z\" ~ \"C\"))"
  },
  {
    "objectID": "slides/slides-class-3.html#by",
    "href": "slides/slides-class-3.html#by",
    "title": "Class 3",
    "section": ".by =",
    "text": ".by =\n \nThis next computation is not necessary for our example data set but I want to demonstrate the use of mutate(.by = ).\n \nThis option is very handy if you want to perform functions separately on different groups or splits of the data frame."
  },
  {
    "objectID": "slides/slides-class-3.html#by-1",
    "href": "slides/slides-class-3.html#by-1",
    "title": "Class 3",
    "section": ".by =",
    "text": ".by =\n \nFor example, let’s calculate the mean for each word list separately.\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(.by = word_list, \n         word_list_mean = mean(recall_correct))\n\n\n\nCompare this with\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(word_list_mean = mean(recall_correct))\n\n\n\n\nYou can use multiple columns in .by =\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(.by = c(participant_id, word_list), \n         word_list_mean = mean(recall_correct))\n\nIt doesn’t make much sense in this case"
  },
  {
    "objectID": "slides/slides-class-3.html#rowwise",
    "href": "slides/slides-class-3.html#rowwise",
    "title": "Class 3",
    "section": "rowwise()",
    "text": "rowwise()\n \nrowwise() is used when you want to perform operations row by row, treating each row as a single group. This is useful when you want to aggregate data (e.g., mean()) across multiple columns.\n \n\nThe data set we are working with does not provide a good demonstration of this so let’s create a different set of data to look at how to use rowwise()\n\ndata_sample &lt;- data.frame(ID = 1:5,\n                          Q1 = sample(1:50, 5),\n                          Q2 = sample(1:50, 5),\n                          Q3 = sample(1:50, 5))\n\n\n\n\n\n\n  \n    \n    \n      ID\n      Q1\n      Q2\n      Q3\n    \n  \n  \n    1.000\n17.000\n30.000\n31.000\n    2.000\n11.000\n15.000\n37.000\n    3.000\n39.000\n34.000\n11.000\n    4.000\n1.000\n38.000\n17.000\n    5.000\n16.000\n4.000\n19.000"
  },
  {
    "objectID": "slides/slides-class-3.html#rowwise-1",
    "href": "slides/slides-class-3.html#rowwise-1",
    "title": "Class 3",
    "section": "rowwise()",
    "text": "rowwise()\n \nLet’s say we want to calculate each participant’s mean response across these three columns.\n \n\n\ndata_sample &lt;- data_sample |&gt;\n  rowwise() |&gt;\n  mutate(Q_mean = mean(c(Q1, Q2, Q3))) |&gt;\n  ungroup()\n\n\n\n\n\n\n  \n    \n    \n      ID\n      Q1\n      Q2\n      Q3\n      Q_mean\n    \n  \n  \n    1.000\n17.000\n30.000\n31.000\n26.000\n    2.000\n11.000\n15.000\n37.000\n21.000\n    3.000\n39.000\n34.000\n11.000\n28.000\n    4.000\n1.000\n38.000\n17.000\n18.667\n    5.000\n16.000\n4.000\n19.000\n13.000\n  \n  \n  \n    \n       \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nYou NEED to ungroup() the data frame whenever you are done with rowwise()"
  },
  {
    "objectID": "slides/slides-class-3.html#rowwise-2",
    "href": "slides/slides-class-3.html#rowwise-2",
    "title": "Class 3",
    "section": "rowwise()",
    "text": "rowwise()\n \nNote the difference when you don’t use rowwise(), it calculates the mean across all rows in the data\n \n\ndata_sample &lt;- data_sample |&gt;\n  mutate(Q_mean = mean(c(Q1, Q2, Q3)))\n\n\n\n\n\n\n  \n    \n    \n      ID\n      Q1\n      Q2\n      Q3\n      Q_mean\n    \n  \n  \n    1.000\n17.000\n30.000\n31.000\n21.333\n    2.000\n11.000\n15.000\n37.000\n21.333\n    3.000\n39.000\n34.000\n11.000\n21.333\n    4.000\n1.000\n38.000\n17.000\n21.333\n    5.000\n16.000\n4.000\n19.000\n21.333"
  },
  {
    "objectID": "slides/slides-class-3.html#putting-it-all-together",
    "href": "slides/slides-class-3.html#putting-it-all-together",
    "title": "Class 3",
    "section": "Putting it all together",
    "text": "Putting it all together\n \n\nrepetition_data &lt;- repetition_import |&gt;\n  rename(participant_id = `subject number`,\n         word_list = List,\n         recall_correct = recallCorrect) |&gt;\n  filter(day != \"Thursday\", day != \"Friday\") |&gt;\n  select(participant_id, word_list, recall_correct) |&gt;\n  mutate(condition = \"spaced repetition\",\n         word_list = case_when(word_list == \"X\" ~ \"A\",\n                               word_list == \"Y\" ~ \"B\",\n                               word_list == \"Z\" ~ \"C\")) |&gt;\n  mutate(.by = word_list, \n         word_list_mean = mean(recall_correct))\n\n\n\nmnemonic_data &lt;- mnemonic_import |&gt;\n  select(participant_id, condition, word_list, recall_correct)\n\n\n\ndata_merged &lt;- bind_rows(mnemonic_data, repetition_data) |&gt;\n  select(-word_list_mean) |&gt;\n  arrange(participant_id)"
  },
  {
    "objectID": "slides/slides-class-3.html#summarise",
    "href": "slides/slides-class-3.html#summarise",
    "title": "Class 3",
    "section": "summarise()",
    "text": "summarise()\n \nThe thing is, we don’t really care about performance on each individual word_list (A, B, and C). We care about the participant’s overall performance, aggregated across all three word lists. To aggregrate data using dplyr we can use summarise().\n \n\nThe result of summarise() is a reduced data frame with fewer rows.\nThe code inside of summarise() looks a lot like the code we could put in mutate().\nThe difference is that mutate() does not collapse the data frame but summarise() does."
  },
  {
    "objectID": "slides/slides-class-3.html#summarise-1",
    "href": "slides/slides-class-3.html#summarise-1",
    "title": "Class 3",
    "section": "summarise()",
    "text": "summarise()\n \nLet’s calculate the mean recall performance by condition and participant. This will result in one row per participant (because it is a between-subject design).\n\n \n\ndata_scores &lt;- data_merged |&gt;\n  summarise(.by = c(participant_id, condition),\n            recall_correct_mean = mean(recall_correct))\n\n\n\n\n\n\n  \n    \n    \n      participant_id\n      condition\n      recall_correct_mean\n    \n  \n  \n    1.000\nspaced repetition\n3.000\n    2.000\nmnemonic\n7.333\n    4.000\nmnemonic\n5.000\n    5.000\nspaced repetition\n5.000\n    6.000\nmnemonic\n6.667\n    8.000\nmnemonic\n5.333\n    9.000\nspaced repetition\n3.333\n    10.000\nmnemonic\n4.000\n    12.000\nmnemonic\n8.667\n    13.000\nspaced repetition\n5.000\n    14.000\nmnemonic\n7.000\n    16.000\nmnemonic\n7.333\n    17.000\nspaced repetition\n5.333\n    19.000\nspaced repetition\n6.667"
  },
  {
    "objectID": "slides/slides-class-3.html#summarise-2",
    "href": "slides/slides-class-3.html#summarise-2",
    "title": "Class 3",
    "section": "summarise()",
    "text": "summarise()\n \nNotice the difference when you don’t use .by =\n\ndata_scores &lt;- data_merged |&gt;\n  summarise(recall_correct_mean = mean(recall_correct))\n\n\n\n\n\n\n\n  \n    \n    \n      recall_correct_mean\n    \n  \n  \n    5.690"
  },
  {
    "objectID": "slides/slides-class-3.html#summarise-3",
    "href": "slides/slides-class-3.html#summarise-3",
    "title": "Class 3",
    "section": "summarise()",
    "text": "summarise()\n \nYou can calculate other summary statistics such as:\n\ndata_scores &lt;- data_merged |&gt;\n  summarise(.by = c(particpant_id, condition),\n            recall_correct_mean = mean(recall_correct),\n            recall_correct_sd = sd(recall_correct),\n            recall_correct_sum = sum(recall_correct),\n            recall_correct_min = min(recall_correct),\n            recall_correct_max = max(recall_correct))"
  },
  {
    "objectID": "slides/slides-class-3.html#ggplot2",
    "href": "slides/slides-class-3.html#ggplot2",
    "title": "Class 3",
    "section": "ggplot2",
    "text": "ggplot2\n \nLet’s plot the data to see what the difference in memory recall is for the two types of strategy:\n\n\nShow Code\nlibrary(ggplot2)\n\nggplot(data_scores, aes(condition, recall_correct_mean)) +\n  geom_point(position = position_jitter(width = .1, seed = 88), alpha = .3) +\n  stat_summary(fun = mean, geom = \"point\", \n               color = \"firebrick\", size = 3) +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", \n               color = \"firebrick\", width = .2) +\n  coord_cartesian(ylim = c(0, 10)) +\n  scale_x_discrete(labels = c(\"Mnemonic\", \"Spaced Recognition\")) +\n  labs(title = \"Recal Performance for Mnemonic and Spaced Recognition\",\n       y = \"Recall Performance\",\n       x = \"\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(size = 14),\n        axis.title.y = element_text(size = 14),\n        axis.text.y = element_text(size = 12))"
  },
  {
    "objectID": "slides/slides-class-3.html#reproducible-script",
    "href": "slides/slides-class-3.html#reproducible-script",
    "title": "Class 3",
    "section": "Reproducible Script",
    "text": "Reproducible Script\n\n# load packages\nlibrary(readr)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(ggplot2)\n\n# import data\nrepetition_import &lt;- read_delim(\"data/class_3_repetition_rawdata.txt\", \n                                delim = \"\\t\", escape_double = FALSE, \n                                trim_ws = TRUE)\n\nmnemonic_import &lt;- read_csv(\"data/class_3_mnemonic_rawdata.csv\")\n\n# trasnform data\nrepetition_data &lt;- repetition_import |&gt;\n  rename(participant_id = `subject number`,\n         word_list = List,\n         recall_correct = recallCorrect) |&gt;\n  filter(day != \"Thursday\", day != \"Friday\") |&gt;\n  select(participant_id, word_list, recall_correct) |&gt;\n  mutate(condition = \"spaced repetition\",\n         word_list = case_when(word_list == \"X\" ~ \"A\",\n                               word_list == \"Y\" ~ \"B\",\n                               word_list == \"Z\" ~ \"C\")) |&gt;\n  mutate(.by = word_list, \n         word_list_mean = mean(recall_correct))\n\nmnemonic_data &lt;- mnemonic_import |&gt;\n  select(participant_id, condition, word_list, recall_correct)\n\n# merge data\ndata_merged &lt;- bind_rows(mnemonic_data, repetition_data) |&gt;\n  select(-word_list_mean) |&gt;\n  arrange(participant_id)\n\n# aggregate data\ndata_scores &lt;- data_merged |&gt;\n  summarise(.by = c(participant_id, condition),\n            recall_correct_mean = mean(recall_correct))\n\n# plot aggregate data\nggplot(data_scores, aes(condition, recall_correct_mean)) +\n  geom_point(position = position_jitter(width = .1, seed = 88), alpha = .3) +\n  stat_summary(fun = mean, geom = \"point\", \n               color = \"firebrick\", size = 3) +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", \n               color = \"firebrick\", width = .2) +\n  coord_cartesian(ylim = c(0, 10)) +\n  scale_x_discrete(labels = c(\"Mnemonic\", \"Spaced Recognition\")) +\n  labs(title = \"Recal Performance for Mnemonic and Spaced Recognition\",\n       y = \"Recall Performance\",\n       x = \"\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(size = 14),\n        axis.title.y = element_text(size = 14),\n        axis.text.y = element_text(size = 12))"
  },
  {
    "objectID": "slides/slides-class-4.html#outline",
    "href": "slides/slides-class-4.html#outline",
    "title": "Class 4",
    "section": "Outline",
    "text": "Outline\n \n\nReproducibility\nProject Workflow\nFile Organization\nImporting Data"
  },
  {
    "objectID": "slides/slides-class-4.html#reproducibility-vs.-just-getting-it-done",
    "href": "slides/slides-class-4.html#reproducibility-vs.-just-getting-it-done",
    "title": "Class 4",
    "section": "Reproducibility vs. Just Getting it Done",
    "text": "Reproducibility vs. Just Getting it Done\n \n\n\nProject organization is often overlooked at the expense of “just getting it done”\nHowever, the “just getting it done” approach can lead to a lot of unintended consequences:\n\nInefficient Workflow\nTime Inefficiency\nIncreased Errors\nDifficulty in Scaling the Project\nBarriers to Revising Analysis\nChallenges in Publishing and Sharing\nReproducibility Issues\n\nSimply using R does not get around any of this\nThe extra demand of writing code can make the “just getting it done” approach more tempting"
  },
  {
    "objectID": "slides/slides-class-4.html#so-what-is-the-solution",
    "href": "slides/slides-class-4.html#so-what-is-the-solution",
    "title": "Class 4",
    "section": "So What is the Solution?",
    "text": "So What is the Solution?\n \nThe solution is to slow down and give some thought to the organization of your project and it’s reproducibility.\n \n\nFrontloading effort saves future headaches.\n\n\n \nPart of the scientific process involves carefully documenting every step in our procedures"
  },
  {
    "objectID": "slides/slides-class-4.html#what-does-reproducibility-mean",
    "href": "slides/slides-class-4.html#what-does-reproducibility-mean",
    "title": "Class 4",
    "section": "What Does Reproducibility Mean?",
    "text": "What Does Reproducibility Mean?\n \n\nReproducibility means that all data processing and analysis steps can be fully reproduced using only the original raw data files and the execution of the R scripts. There are different levels of reproducibility (I made these up):\n \n\n\nPartially reproducible - only some data processing and analysis steps can be reproduced, which may be due to a lack of original raw data files, the “just get it done” approach, or the use of proprietary and non-reproducible software.\nMinimally reproducible (acceptable) - all data processing and analysis steps can be reproduced on any research team members computer without any modifications needed.\nModerately reproducible (desired) - meets the minimal level plus other people not involved in the research project can reproduce the steps with minimal modifications.\nHighly reproducible (good luck!) - fully reproducible without major modifications needed by people not involved in the research project 5 - 10+ years from now."
  },
  {
    "objectID": "slides/slides-class-4.html#simply-using-r-does-not-guarantee-that-your-project-is-reproducible",
    "href": "slides/slides-class-4.html#simply-using-r-does-not-guarantee-that-your-project-is-reproducible",
    "title": "Class 4",
    "section": "Simply using R does not guarantee that your project is reproducible",
    "text": "Simply using R does not guarantee that your project is reproducible\n \n \n\nTo ensure at least a moderate level of reproducibility, consider the following criteria (this is not an exhaustive list):\n\n\nYour statistical analysis (the final step) can be fully reproduced from the raw data files and your R scripts\nYour code can be reproduced on other computers without any modifications\nYour data and R scripts are organized and documented in a way that makes them easily understandable\n\n\n\n\nIt is important to take the time and think about the organization of your project, files, data, and scripts."
  },
  {
    "objectID": "slides/slides-class-4.html#data-analysis-workflow",
    "href": "slides/slides-class-4.html#data-analysis-workflow",
    "title": "Class 4",
    "section": "Data Analysis Workflow",
    "text": "Data Analysis Workflow\nA good starting point for organizing your project is to map out the steps required for processing and analyzing your data\n \n\nA typical data analysis workflow looks something like this:\n\n\n\n\n\n \n\n\nI suggest using this data analysis workflow as a starting point for organizing your project:\n\nOrganize your folders and files to match this workflow\nCreate separate scripts for each stage"
  },
  {
    "objectID": "slides/slides-class-4.html#file-organization",
    "href": "slides/slides-class-4.html#file-organization",
    "title": "Class 4",
    "section": "File Organization",
    "text": "File Organization\nGood project organization starts with easy to understand folder and file organization. You want this organization to match your data analysis workflow:\n \n\n\n\n\ndata folder\nNotice how the structure of the data folder follows the data analysis workflow"
  },
  {
    "objectID": "slides/slides-class-4.html#file-organization-1",
    "href": "slides/slides-class-4.html#file-organization-1",
    "title": "Class 4",
    "section": "File Organization",
    "text": "File Organization\nGood project organization starts with easy to understand folder and file organization. You want this organization to match your data analysis workflow:\n \n\n\n\n\ndata folder\nNotice how the structure of the data folder follows the data analysis workflow"
  },
  {
    "objectID": "slides/slides-class-4.html#file-organization-2",
    "href": "slides/slides-class-4.html#file-organization-2",
    "title": "Class 4",
    "section": "File Organization",
    "text": "File Organization\nGood project organization starts with easy to understand folder and file organization. You want this organization to match your data analysis workflow:\n \n\n\n\n\nR folder\nPut all your R scripts in one folder\nAppend a prefix number and suffix corresponding to the order to be ran and what stage of the data analysis workflow it is in:\n\n1_tidyraw.R\n2_score_clean.R\n3_merge.R\n\nThese should be cleaned up, commented, and easy to understand\n\nUntitled.R: scratchpad to test out code"
  },
  {
    "objectID": "slides/slides-class-4.html#file-organization-3",
    "href": "slides/slides-class-4.html#file-organization-3",
    "title": "Class 4",
    "section": "File Organization",
    "text": "File Organization\nGood project organization starts with easy to understand folder and file organization. You want this organization to match your data analysis workflow:\n \n\n\n\n\nanalyses folder\nQuarto documents (Class 5) that you will use to genearate reports for exploring your data, creating data visualizations, and conduct statistical analyses\n\nMain Analyses.qmd\n\nThese documents should be cleaned up, well organized, and easy to understand.\n\nUntitled.qmd: scratchpad to test out code"
  },
  {
    "objectID": "slides/slides-class-4.html#file-organization-4",
    "href": "slides/slides-class-4.html#file-organization-4",
    "title": "Class 4",
    "section": "File Organization",
    "text": "File Organization\nGood project organization starts with easy to understand folder and file organization. You want this organization to match your data analysis workflow:\n \n\n\n\n\nmainscript\nYou might also consider creating a mainscript.R or mainscript.qmd file to source all your R scripts and Quarto documents, rather than opening and sourcing each R script and Quarto document one at a time.\n\n## data preparation\nsource(\"R/1_tidyraw.R\")\n\n## data scoring\nsource(\"R/2_score_clean.R\")\nsource(\"R/3_merge.R\")\n\n## statistical analysis\nlibrary(quarto)\nquarto_render(\"analyses/Main Analyses.qmd\")"
  },
  {
    "objectID": "slides/slides-class-4.html#file-organization-5",
    "href": "slides/slides-class-4.html#file-organization-5",
    "title": "Class 4",
    "section": "File Organization",
    "text": "File Organization\nGood project organization starts with easy to understand folder and file organization. You want this organization to match your data analysis workflow:\n \n\n\n\n\nmainscript\nYou might also consider creating a mainscript.R or mainscript.qmd file to source all your R scripts and Quarto documents, rather than opening and sourcing each R script and Quarto document one at a time.\n\n## data preparation\nsource(\"R/1_tidyraw.R\")\n\n## data scoring\nsource(\"R/2_score_clean.R\")\nsource(\"R/3_merge.R\")\n\n## statistical analysis\nlibrary(quarto)\nquarto_render(\"analyses/Main Analyses.qmd\")"
  },
  {
    "objectID": "slides/slides-class-4.html#using-file-paths-to-import-data",
    "href": "slides/slides-class-4.html#using-file-paths-to-import-data",
    "title": "Class 4",
    "section": "Using File Paths to Import Data",
    "text": "Using File Paths to Import Data\n \n\nUse setwd()\nUse the RStudio Import Dataset GUI\nUse RProjects and here()"
  },
  {
    "objectID": "slides/slides-class-4.html#using-file-paths-to-import-data-1",
    "href": "slides/slides-class-4.html#using-file-paths-to-import-data-1",
    "title": "Class 4",
    "section": "Using File Paths to Import Data",
    "text": "Using File Paths to Import Data\n \n\nUse setwd()\nUse the RStudio Import Dataset GUI\nUse RProjects and here()"
  },
  {
    "objectID": "slides/slides-class-4.html#file-paths",
    "href": "slides/slides-class-4.html#file-paths",
    "title": "Class 4",
    "section": "File Paths",
    "text": "File Paths\nR needs to know the full file path to the file on your computer in order to import it - this is what is referred to as an absolute file path. Absolute file paths start at the root directory of your computer and might look something like:\n\n \n\nOn Macs:\nUsers/username/projects/project_name/data/a_file.csv\nOn Windows:\nC:\\username\\projects\\project_name\\data\\a_file.csv\n\nRelative file paths on the other hand, start from a folder - typically a project folder\n\ndata/a_file.csv"
  },
  {
    "objectID": "slides/slides-class-4.html#file-paths-1",
    "href": "slides/slides-class-4.html#file-paths-1",
    "title": "Class 4",
    "section": "File Paths",
    "text": "File Paths\n \n\n\nRelative file paths need to be used in order for your project to meet even a minimal level of reproducibility.\nHowever, at some point your computer does need to know the absolute file path to your project folder.\nA convenient and reproducible way of doing this is by using a combination of RStudio Projects and here::here() ."
  },
  {
    "objectID": "slides/slides-class-4.html#rstudio-projects",
    "href": "slides/slides-class-4.html#rstudio-projects",
    "title": "Class 4",
    "section": "RStudio Projects",
    "text": "RStudio Projects\nRStudio Projects are convenient for a number of reasons, but the most useful thing is setting a file marker for where the root directory of your project folder is located.\n \n\nTo create an RStudio Project:\n\nCreate a folder for your project (if you do not have one yet)\nFile -&gt; New Project…\nChoose Existing Directory -&gt; Browse to your project folder -&gt; Create Project\n\n\n\n \n\n\n\nWhen working on your project, you should always open RStudio by opening the .Rproj file"
  },
  {
    "objectID": "slides/slides-class-4.html#rstudio-projects-1",
    "href": "slides/slides-class-4.html#rstudio-projects-1",
    "title": "Class 4",
    "section": "RStudio Projects",
    "text": "RStudio Projects\n \nYou can also see which RStudio project is open and open RStudio projects in the very top-right corner of RStudio."
  },
  {
    "objectID": "slides/slides-class-4.html#herehere",
    "href": "slides/slides-class-4.html#herehere",
    "title": "Class 4",
    "section": "here::here()",
    "text": "here::here()\nIn combination with RStudio projects the here package offers a convenient way of specifying relative file paths.\n \n\nWhen you load the here package with library(here) it will search for the .Rproj file and start file paths at that point whenever the here() function is used.\n \n\nlibrary(here)\n\nhere() starts at /Users/jtsukahara3/GitHub Repos/r-for-psychology-students\n\n\n \n\n\nNotice how that where here() starts is an absolute file path to your project folder.\nYou did not have to specify the absolute file path in code. Meaning this is a reproducible way for the absolute file path to automatically be set."
  },
  {
    "objectID": "slides/slides-class-4.html#herehere-1",
    "href": "slides/slides-class-4.html#herehere-1",
    "title": "Class 4",
    "section": "here::here()",
    "text": "here::here()\n \nNow you can use a relative file path inside of here()\n \n\nhere(\"data/a_file.csv\")\n\n[1] \"/Users/jtsukahara3/GitHub Repos/r-for-psychology-students/data/a_file.csv\"\n\n\n \nEvery time you use here() you know that the file path will start at where you have your .Rproj file saved.\n \n\nYou can visually separate the folder path and the file name, making your script easier to read.\n \n\nhere(\"data\", \"a_file.csv\")\n\n[1] \"/Users/jtsukahara3/GitHub Repos/r-for-psychology-students/data/a_file.csv\""
  },
  {
    "objectID": "slides/slides-class-4.html#herehere-2",
    "href": "slides/slides-class-4.html#herehere-2",
    "title": "Class 4",
    "section": "here::here()",
    "text": "here::here()\n \nYou can then use here() inside of import and and output functions:\n \n\nlibrary(readr)\nlibrary(here)\n\ndata_import &lt;- read_csv(here(\"data\", \"a_file.csv\"))\n\nwrite_csv(data_import, here(\"data\", \"a_new_file.csv\"))"
  },
  {
    "objectID": "slides/slides-class-4.html#psyworkflow",
    "href": "slides/slides-class-4.html#psyworkflow",
    "title": "Class 4",
    "section": "psyworkflow",
    "text": "psyworkflow\nWriting organized, clean, and easy to understand R code is hard\n\n \nI have developed an R package psyworkflow that contains R script templates you can use\n\n\n \nInstall\nFirst, if you do not have the devtools package installed:\n\ninstall.packages(\"devtools\")\n\n \nInstall the psyworkflow package from my GitHub repository using the devtools package:\n\ndevtools::install_github(\"dr-JT/psyworkflow\")\n\n \n\nSession -&gt; Restart R\n\n \nSee documentation on psyworkflow"
  },
  {
    "objectID": "slides/slides-class-4.html#download-r-script-templates",
    "href": "slides/slides-class-4.html#download-r-script-templates",
    "title": "Class 4",
    "section": "Download R Script Templates",
    "text": "Download R Script Templates\nIf you already have an RProject setup and just want to download some of the R script templates you can do so with the get_template() function.\n \n\npsyworkflow::get_template()\n\n \nTo see what the options are type in the console window\n\n?psyworkflow::get_template"
  },
  {
    "objectID": "slides/slides-class-4.html#download-r-script-templates-1",
    "href": "slides/slides-class-4.html#download-r-script-templates-1",
    "title": "Class 4",
    "section": "Download R Script Templates",
    "text": "Download R Script Templates\n \n\n# ---- Setup -------------------------------------------------------------------\n# packages\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(purrr) # delete if not importing a batch of files\n\n# directories\nimport_dir &lt;- \"data/raw/messy\"\noutput_dir &lt;- \"data/raw\"\n\n# file names\ntask &lt;- \"taskname\"\nimport_file &lt;- paste(task, \".txt\", sep = \"\")\noutput_file &lt;- paste(task, \"raw.csv\", sep = \"_\")\n# ------------------------------------------------------------------------------\n\n# ---- Import Data -------------------------------------------------------------\n# to import a single file\ndata_import &lt;- read_delim(here(import_dir, import_file), delim = \"\\t\",\n                          escape_double = FALSE, trim_ws = TRUE)\n\n# alternatively to import a batch of files...\n# change the arguments in purrr::map_df() depending on type of data files\n# this example is for files created from eprime and needs encoding = \"UCS-2LE\"\nfiles &lt;- list.files(here(import_dir, task), pattern = \".txt\", full.names = TRUE)\ndata_import &lt;- files |&gt;\n  map_df(read_delim, delim = \"\\t\",\n         escape_double = FALSE, trim_ws = TRUE, na = \"NULL\",\n         locale = locale(encoding = \"UCS-2LE\"))\n# ------------------------------------------------------------------------------\n\n# ---- Tidy Data ---------------------------------------------------------------\ndata_raw &lt;- data_import |&gt;\n  rename() |&gt;\n  filter() |&gt;\n  mutate() |&gt;\n  select()\n# ------------------------------------------------------------------------------\n\n# ---- Save Data ---------------------------------------------------------------\nwrite_csv(data_raw, here(output_dir, output_file))\n# ------------------------------------------------------------------------------\n\nrm(list = ls())"
  },
  {
    "objectID": "slides/slides-class-4.html#create-a-new-project",
    "href": "slides/slides-class-4.html#create-a-new-project",
    "title": "Class 4",
    "section": "Create a New Project",
    "text": "Create a New Project\nI have made a RStudio Project template that will setup a folder and file organization for you\n \nClose RStudio and reopen a new instance of RStudio (not from an RProject file).\n \nTo create an RProject from this template:\n \n\nFile -&gt; New Project… -&gt; New Directory -&gt; Research Study (you might need to scroll down to see it)"
  },
  {
    "objectID": "slides/slides-class-4.html#create-a-new-project-1",
    "href": "slides/slides-class-4.html#create-a-new-project-1",
    "title": "Class 4",
    "section": "Create a New Project",
    "text": "Create a New Project\nThis will bring up a window to customize the template:\n\nType in whatever you want for the Directory Name - this will end up being the name of the project folder and RProject file.\nClick on Browse… and create the project on your desktop, for now.\nKeep all the defaults and select Create Project.\nGive it some time, and it will reopen RStudio from the newly created RProject. Take a look at the file pane and you can see that the folders have been created, and R Script templates downloaded."
  },
  {
    "objectID": "slides/slides-class-4.html#reproducibility-vs.-just-getting-it-done-1",
    "href": "slides/slides-class-4.html#reproducibility-vs.-just-getting-it-done-1",
    "title": "Class 4",
    "section": "Reproducibility vs. Just Getting it Done",
    "text": "Reproducibility vs. Just Getting it Done\n \n\n\nProject organization is often overlooked at the expense of “just getting it done”\nHowever, the “just getting it done” approach can lead to a lot of unintended consequences:\n\nInefficient Workflow\nTime Inefficiency\nIncreased Errors\nDifficulty in Scaling the Project\nBarriers to Revising Analysis\nChallenges in Publishing and Sharing\nReproducibility Issues"
  },
  {
    "objectID": "slides/slides-class-4.html#simply-using-r-does-not-guarantee-that-your-project-is-reproducible-1",
    "href": "slides/slides-class-4.html#simply-using-r-does-not-guarantee-that-your-project-is-reproducible-1",
    "title": "Class 4",
    "section": "Simply using R does not guarantee that your project is reproducible",
    "text": "Simply using R does not guarantee that your project is reproducible\n \n \nTo ensure at least a moderate level of reproducibility, consider the following criteria (this is not an exhaustive list):\n\n\nYour statistical analysis (the final step) can be fully reproduced from the raw data files and your R scripts\nYour code can be reproduced on other computers without any modifications\nYour data and R scripts are organized and documented in a way that makes them easily understandable\n\n\nIt is important to take the time and think about the organization of your project, files, data, and scripts."
  },
  {
    "objectID": "supplemental/github_copilot.html",
    "href": "supplemental/github_copilot.html",
    "title": "GitHub Copilot",
    "section": "",
    "text": "I highly recommend, I insist really, that you make use of generative AIs to assist you in writing code. They can be useful for:\nChatGPT is obviously a great resource, but another generative AI specifically for writing code is GitHub Copilot.\nGitHub Copilot can be added as an extension in a lot of different IDE programming software, including RStudio.",
    "crumbs": [
      "Supplemental",
      "GitHub Copilot"
    ]
  },
  {
    "objectID": "supplemental/github_copilot.html#copilot-in-rstudio",
    "href": "supplemental/github_copilot.html#copilot-in-rstudio",
    "title": "GitHub Copilot",
    "section": "Copilot in RStudio",
    "text": "Copilot in RStudio\nBefore adding GitHub Copilot to RStudio, you will need to\n\nLogin to GitHub either through your GT login or your personal account\nApply to GitHub Global Campus as a student\n\nYou will need to verify your student status with documentation (picture of student ID will work)\n\n\n\nDocuments that prove your current student status include a picture of your school ID with current enrollment date, class schedule, transcript, and affiliation or enrollment verification letter.\n\n\nSetup GitHub Copilot in RStudio\nUsing Copilot in RStudio\n\nCopilot offers autocomplete-style suggestions as you code as “ghost text”. \n\n\nUsing comments with Copilot\n\nYou can provide more extensive instructions, using comments, for Copilot to generate multiple lines of code\n\n# import Recall_Data.csv and plot the effect of Memory Strategy and\n# Presentation Rate on Recall Performance\n\nWhich might generate something like:\n\n# load packages\nlibrary(readr)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(here)\n\n# import data\nrecall_data &lt;- read_csv(here(\"data/Recall_Data.csv\"))\n\n# plot data\nggplot(recall_data, aes(x = Presentation_Rate, y = Recall_Performance, \n                        color = Memory_Strategy, group = Memory_Strategy)) +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", width = .25) +\n  stat_summary(fun = mean, geom = \"line\") +\n  stat_summary(fun = mean, geom = \"point\") +\n  coord_cartesian(ylim = c(0, 100)) +\n  theme_classic()\n\n\n\n\n\n\n\n\nAnd this code works! I would probably modify the plot somewhat, such as the y-axis beeing too large.\nAlso notice that the organization and packages used are the same as I have used in this workshop. This is because Copilot indexed my files in this project and used that as context.\nTo allow Copilot to index files you need to turn on the option in\n\nTools -&gt; Global Options -&gt; Copilot",
    "crumbs": [
      "Supplemental",
      "GitHub Copilot"
    ]
  },
  {
    "objectID": "supplemental/tips-tricks.html",
    "href": "supplemental/tips-tricks.html",
    "title": "Useful Tips",
    "section": "",
    "text": "When working with functions, it can be difficult to remember the argument names and values you need to specify. However, there is a helper function that can make this process much easier: ?. By typing ?function_name() in the console, you can access the function’s documentation and quickly figure out what arguments you need to provide. This can save you a lot of time and frustration, especially when working with complex functions.\n\n?seq()",
    "crumbs": [
      "Supplemental",
      "Tips & Tricks"
    ]
  },
  {
    "objectID": "supplemental/tips-tricks.html#helper-function",
    "href": "supplemental/tips-tricks.html#helper-function",
    "title": "Useful Tips",
    "section": "",
    "text": "When working with functions, it can be difficult to remember the argument names and values you need to specify. However, there is a helper function that can make this process much easier: ?. By typing ?function_name() in the console, you can access the function’s documentation and quickly figure out what arguments you need to provide. This can save you a lot of time and frustration, especially when working with complex functions.\n\n?seq()",
    "crumbs": [
      "Supplemental",
      "Tips & Tricks"
    ]
  },
  {
    "objectID": "supplemental/tips-tricks.html#generative-ai",
    "href": "supplemental/tips-tricks.html#generative-ai",
    "title": "Useful Tips",
    "section": "Generative AI",
    "text": "Generative AI\nGenerative AI can be a useful assistant to both learning and writing R code. It will make mistakes but that is what actually makes it a useful learning tool, it can also help you discover ways of doing things you wouldn’t have thought of before.\nStart out small, if you are not immediately sure how to proceed with writing R code for something you want to do then prompt an AI model to write some code and provide an explanation for you. Continuing prompting it and/or edit the code to suit your specific need.\nYou should also start using AI models to assist you in other areas of your work as well. Again, just start out small. Get in the habit and setup a workflow where an AI model is right at your fingertips, just a few clicks of the mouse or keyboard away.",
    "crumbs": [
      "Supplemental",
      "Tips & Tricks"
    ]
  },
  {
    "objectID": "supplemental/tips-tricks.html#store-frequently-used-code-for-reuse",
    "href": "supplemental/tips-tricks.html#store-frequently-used-code-for-reuse",
    "title": "Useful Tips",
    "section": "Store Frequently Used Code For Reuse",
    "text": "Store Frequently Used Code For Reuse\nIf you find yourself using the same or similar sequences of code repeatedly, it can be incredibly helpful to have a central location where you can store your frequently used code and easily retrieve it at any time. While GitHub is a popular option for this, it requires learning a new system. Notion is a program I personally use and recommend, but a simple folder on your desktop with R scripts is also a viable option.\nWithout a central location for frequently used code, you may find yourself spending a significant amount of time and effort searching through previous projects to locate the code you need. This can be a daunting task, requiring a good memory and a lot of time. Having a singular place to go to for all your frequently used code can make this process much easier and save you time and energy in the long run.",
    "crumbs": [
      "Supplemental",
      "Tips & Tricks"
    ]
  },
  {
    "objectID": "supplemental/tips-tricks.html#use-templates",
    "href": "supplemental/tips-tricks.html#use-templates",
    "title": "Useful Tips",
    "section": "Use Templates!",
    "text": "Use Templates!\nCreating your own templates and/or templates for your lab is highly recommended. This will save you a significant amount of time and effort, enabling you to start working with your data more quickly and set up new data analysis projects with ease. Additionally, consider creating an R package that include Quarto documents for analyses and reports. This will help streamline your workflow even further.\nI have developed several R packages for the lab that contain useful templates and documents. Please make use of them.",
    "crumbs": [
      "Supplemental",
      "Tips & Tricks"
    ]
  },
  {
    "objectID": "supplemental/tips-tricks.html#limit-number-of-packages",
    "href": "supplemental/tips-tricks.html#limit-number-of-packages",
    "title": "Useful Tips",
    "section": "Limit Number of Packages",
    "text": "Limit Number of Packages\nWhen using R, it’s recommended to limit the number of packages you use. You may be surprised at how much you can accomplish with just a few packages. Limiting your package usage makes it easier to manage your installed packages, and also helps with the learning curve, as you don’t have to memorize functions from a large number of packages.",
    "crumbs": [
      "Supplemental",
      "Tips & Tricks"
    ]
  },
  {
    "objectID": "supplemental/tips-tricks.html#ask-a-friend",
    "href": "supplemental/tips-tricks.html#ask-a-friend",
    "title": "Useful Tips",
    "section": "Ask a Friend",
    "text": "Ask a Friend\nWhile there are many functions available for most tasks, finding the right one can be a challenge. Instead of spending time on long and convoluted solutions, consider asking friends or colleagues if they know of a package or function that could help you accomplish what you need. Collaborating with others is a great way to discover new functions and tools that you may not have known existed.",
    "crumbs": [
      "Supplemental",
      "Tips & Tricks"
    ]
  },
  {
    "objectID": "supplemental/tips-tricks.html#google-search",
    "href": "supplemental/tips-tricks.html#google-search",
    "title": "Useful Tips",
    "section": "Google Search",
    "text": "Google Search\nThis section may be less relevant now, given the rise of generative AI models. However, Google can still be a valuable tool for finding R solutions quickly. To get more targeted results, try including the name of the package or function you think might help you in your search phrase. If you use dplyr frequently, for example, use dplyr in your search phrase to find solutions that are consistent with your preferred way of working.\nIf you’re unsure of which function to use, try including the function name in your search phrase. You can also use Google to find more detailed documentation for specific packages or functions. However, it’s best to avoid links that start with https://cran.r-project.org or https://www.rdocumentation.org, as these are usually just copies of the ? help documentation.\nInstead, look for links that include https://github.com. GitHub repos often include links to more extensive documentation, such as the GitHub repo for the popular dplyr package (https://github.com/tidyverse/dplyr), which has a link on the right side of the repo page to detailed documentation on all the functions in the package.",
    "crumbs": [
      "Supplemental",
      "Tips & Tricks"
    ]
  },
  {
    "objectID": "supplemental/tips-tricks.html#explore-functions-in-a-package",
    "href": "supplemental/tips-tricks.html#explore-functions-in-a-package",
    "title": "Useful Tips",
    "section": "Explore Functions in a Package",
    "text": "Explore Functions in a Package\nAdditionally, there may be functions in the packages you already use that you have yet to discover. Take some time to explore all the different functions within a package, particularly those that you use frequently. The GitHub repository for a package is a great resource for exploring all of its functions. To access it, simply type the name of the package followed by the term “GitHub” into a search engine.",
    "crumbs": [
      "Supplemental",
      "Tips & Tricks"
    ]
  },
  {
    "objectID": "activities/activities-class-3.html",
    "href": "activities/activities-class-3.html",
    "title": "Class 3 Learning Activity",
    "section": "",
    "text": "For this activity we will work with a real data set from a paper published in Psychological Science (one of the leading journals in psychology).\n📄 Download the paper (optional)\n⬇️ Download the data\nIn this research, Dawtry, Sutton, and Sibley (2015) wanted to examine why people differ in their assessments of the increasing wealth inequality within developed nations. Previous research reveals that most people desire a society in which the overall level of wealth is high and that wealth is spread somewhat equally across society. However, support for this approach to income distribution changes across the social strata. In particular, wealthy people tend to view society as already wealthy and thus are satisfied with the status quo, and less likely to support redistribution. In their paper Dawtry et al., (2015) sought to examine why this is the case. The authors propose that one reason wealthy people tend to view the current system is fair is because their social-circle is comprised of other wealthy people, which biases their perceptions of wealth, which leads them to overestimate the mean level of wealth across society.\nTo test this hypothesis, the authors conducted a study with 305 participants, recruited from an online participant pool. Participants reported their own annual household income, the income level of those within their own social circle, and the income for the entire population. Participants also rated their perception of the level of equality/inequality across their social circle and across society, their level of satisfaction with and perceived fairness of the current system, their attitudes toward redistribution of wealth (measured using a four-item scale), and their political preference.\nKey variables we will look at:"
  },
  {
    "objectID": "activities/activities-class-3.html#setup",
    "href": "activities/activities-class-3.html#setup",
    "title": "Class 3 Learning Activity",
    "section": "Setup",
    "text": "Setup\n\nCreate a new R script and save it as class_3_activity_firstlastname.R\nLoad the following packages at the top of your script\n\nreadr, dplyr, gt, ggplot2\n\nImport the data file\nTake some time to explore the data.\n\nWhat are the column names?\nWhat type of values are in the columns?\nHow many participants are in the study?\n\nhint: use a combination of length() and unique()"
  },
  {
    "objectID": "activities/activities-class-3.html#rename-and-filter",
    "href": "activities/activities-class-3.html#rename-and-filter",
    "title": "Class 3 Learning Activity",
    "section": "Rename and Filter",
    "text": "Rename and Filter\n\nRename the level of satisfaction and perceived fairness columns\nIn the previous step, you should have noticed how these column names are not ideal. They contain spaces and even a special character ? . You will need to use the special quotation mark ` `to reference these column names in rename() , e.g., `column name with spaces` You can find these special quotation marks to the left of the 1 key and above the tab key.\nFilter by only keeping rows in which Political_Preference is not missing NA . Note how many fewer rows there are in the data after filtering.\nhint: use filter(!is.na()) to evaluate whether values in Political_Preference are NOT ! missing is.na()\n\n\nShow cheat code\nfilter(!is.na(Political_Preference))"
  },
  {
    "objectID": "activities/activities-class-3.html#select-and-transform",
    "href": "activities/activities-class-3.html#select-and-transform",
    "title": "Class 3 Learning Activity",
    "section": "Select and Transform",
    "text": "Select and Transform\n\nSelect only the columns that contain the key variables we are interested in.\nReverse score redist2 and redist4, so that 6=1, 5=2, 4=3, 3=4, 2=5, 1=6.\nUse mutate() and case_when()\nAggregate values across rows\n\nCalculate a single variable representing participant’s mean attitude on redistrubtion of wealth\nCalculate a single variable representing participant’s mean perception that the current systen is satisfactory and fair.\n\nUse a combination of rowwise() and mutate()"
  },
  {
    "objectID": "activities/activities-class-3.html#summarise",
    "href": "activities/activities-class-3.html#summarise",
    "title": "Class 3 Learning Activity",
    "section": "Summarise",
    "text": "Summarise\n\nCreate a new data frame summarizing the values for attitude on redistribution and the combined satisfactory and fairness variable for each level of political preference. (calculate the mean when summarizing)\nUse summarise(.by = )\nCreate a table of this summarized data frame\nUse gt() from the gt package, e.g.,\n\ngt(new_data)"
  },
  {
    "objectID": "activities/activities-class-3.html#plot",
    "href": "activities/activities-class-3.html#plot",
    "title": "Class 3 Learning Activity",
    "section": "Plot",
    "text": "Plot\n\nCreate a line plot of this summarized data frame\nYou can copy and paste this, but you might need to change the name of variables to match how you labeled them.\ndata_summary, redist_mean, and fairnesss_satisfactory_mean\n\nggplot(data_summary, aes(Political_Preference)) +\n  geom_line(aes(y = redist_mean, color = \"redist\")) +\n  geom_line(aes(y = fairness_satisfactory_mean, color = \"fair/satis\")) +\n  coord_cartesian(xlim = c(1, 9.1), ylim = c(1, 9)) +\n  scale_x_continuous(breaks = 1:9, \n                     labels = \n                       c(\"1\\nLiberal\", \"2\", \"3\", \"4\", \n                         \"5\", \"6\", \"7\", \"8\", \"9\\nConservative\")) +\n  scale_y_continuous(breaks = 1:9,\n                     labels = c(\"Strongly\\nDisagree\", \"2\", \"3\", \"4\", \n                                \"5\", \"6\", \"7\", \"8\", \"Strongly\\nAgree\")) +\n  scale_color_manual(values = c(\"redist\" = \"steelblue\",\n                                \"fair/satis\" = \"firebrick\"),\n                     name = \"\",\n                     labels = c(\"Fairness/Satisfactory of Current System\",\n                                \"Redistribution Preference\")) +\n  theme_light() +\n  theme(legend.position = \"top\") +\n  labs(title = \"Economic Attitdues by Political Preference\",\n       x = \"Political Preference\",\n       y = \"Attitude\")\n\n\n\nCheck Your Work\nYou should attempt to complete the activity without looking at this code\n\n\nShow Code\n# load packages\nlibrary(readr)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(ggplot2)\n\n# import data\ndata_import &lt;- read_csv(\"data/Dawtry Sutton and Sibley 2015 Study 1a.csv\")\n\n# data transformation\ndata &lt;- data_import |&gt;\n  rename(fairness = `current system is fair?`,\n         satisfactory = `current system is satisfactory?`) |&gt;\n  filter(!is.na(Political_Preference)) |&gt;\n  select(fairness, satisfactory, redist1, redist2, redist3, redist4,\n         Social_Circle_Mean_Income, Political_Preference) |&gt;\n  mutate(redist2_recode = case_when(redist2 == 6 ~ 1,\n                                    redist2 == 5 ~ 2,\n                                    redist2 == 4 ~ 3,\n                                    redist2 == 3 ~ 4,\n                                    redist2 == 2 ~ 5,\n                                    redist2 == 1 ~ 6),\n         redist4_recode = case_when(redist4 == 6 ~ 1,\n                                    redist4 == 5 ~ 2,\n                                    redist4 == 4 ~ 3,\n                                    redist4 == 3 ~ 4,\n                                    redist4 == 2 ~ 5,\n                                    redist4 == 1 ~ 6)) |&gt;\n  rowwise() |&gt;\n  mutate(redist = mean(c(redist1, redist2, redist3, redist4)),\n         fairness_satisfactory = mean(c(fairness, satisfactory))) |&gt;\n  ungroup()\n\n# aggregate data\ndata_summary &lt;- data |&gt;\n  summarise(.by = Political_Preference,\n            redist_mean = mean(redist),\n            fairness_satisfactory_mean = mean(fairness_satisfactory)) |&gt;\n  arrange(Political_Preference)\n\ngt(data_summary)\n\n# line plot of summary data\nggplot(data_summary, aes(Political_Preference)) +\n  geom_line(aes(y = redist_mean, color = \"redist\")) +\n  geom_line(aes(y = fairness_satisfactory_mean, color = \"fair/satis\")) +\n  coord_cartesian(xlim = c(1, 9), ylim = c(1, 9)) +\n  scale_x_continuous(breaks = 1:9, \n                     labels = \n                       c(\"1\\nLiberal\", \"2\", \"3\", \"4\", \n                         \"5\", \"6\", \"7\", \"8\", \"9\\nConservative\")) +\n  scale_y_continuous(breaks = 1:9,\n                     labels = c(\"Strongly\\nDisagree\", \"2\", \"3\", \"4\", \n                                \"5\", \"6\", \"7\", \"8\", \"Strongly\\nAgree\")) +\n  scale_color_manual(values = c(\"redist\" = \"steelblue\",\n                                \"fair/satis\" = \"firebrick\"),\n                     name = \"\",\n                     labels = c(\"Fairness/Satisfactory of Current System\",\n                                \"Redistribution Preference\")) +\n  theme_light() +\n  theme(legend.position = \"top\") +\n  labs(title = \"Economic Attitdues by Political Preference\",\n       x = \"Political Preference\",\n       y = \"Attitude\")\n\nggsave(\"images/economic_attitudes_by_political_preference.png\",\n       width = 6, height = 4, dpi = 300)"
  },
  {
    "objectID": "lectures/lectures-class-1.html",
    "href": "lectures/lectures-class-1.html",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "",
    "text": "This course does not require that you already have experience with R, but it would greatly benefit you to have at least a basic understanding of how R works. In this first class we will only cover the bare bones that will be needed to get you started. For a more complete intro to the basics of R see the page on R Basics.\nAs you go through the classes in this course, I encourage you to experiment. If you are curious what happens if you write the code slightly differently, go ahead and try it out. See what happens. If it is not what you expected spend some time figuring out why."
  },
  {
    "objectID": "lectures/lectures-class-1.html#sec-new-script-file",
    "href": "lectures/lectures-class-1.html#sec-new-script-file",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "New Script File",
    "text": "New Script File\nTo create a new R script go to\nFile -&gt; New File -&gt; R Script\nThis should have opened a blank Script window called Untitled.\nThe Script window is a file where you are saving your code. This is where you will write, edit, delete, and re-write your code.\nThis course will refer to two types of R script files:\n\nReproducible script file: Script file for actually processing and analyzing your data. Can reproduce your steps of processing and analysis.\n\nThe purpose of the Reproducible script file is to create a document, that can be saved on your computer and shared with others. It should only include code that is necessary to process your data. Therefore, you only want to type in code in the R script file that you intend to save and is necessary for processing your data.\n\nScratchpad script file: A script file for testing, debugging, and exploring your data.\n\nOften saved as Untitled.R or not saved at all\nThe purpose of the scratchpad script file is to write R code that is not intended to be saved and is not a necessary step for processing your data. For instance, you might want to view a data frame (more on that later), check what are the unique values in a column, get the names of all the columns in a data frame. These will help you to write your R code, but are not necessary steps for actually processing your data once you have the R code written. Therefore, you can just write the code directly in the R Console window and execute the code there - that way it won’t clutter up your Reproducible script file.\n\n\n\n\n\n\n\n\nTip\n\n\n\nCreate two script files for this class.\n\nOne will be a reproducible script file you can save at the end of the class to reproduce same data processing, visualization, and statistics we will do at the end.\nThe other will be a scratchpad script file. You can choose whether you want to save that script or not."
  },
  {
    "objectID": "lectures/lectures-class-1.html#sec-running-r-code",
    "href": "lectures/lectures-class-1.html#sec-running-r-code",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "Running R Code",
    "text": "Running R Code\nThroughout this course you will be introduced to several ways of executing or “running” R code. For now, you need to be aware of two ways of doing so.\n\nTyping code in an R script file and executing R code line-by-line Ctrl + Enter\nTyping code directly in the console window\n\nTo execute R code in an R script file line-by-line you just need to type in some R code, put the cursor anywhere on that line, and hit Ctrl + Enter.\nIn a scratchpad script file, run each line one-by-one.\n\n1 + 2\n3 * 9\n\nNotice how the lines of code and their output were printed to the Console window. No matter how you execute R code it gets passed to the Console window anyways.\nType the same lines of code as above but this time directly in the Console window, one at a time, and hit enter."
  },
  {
    "objectID": "lectures/lectures-class-1.html#sec-creating-r-objects",
    "href": "lectures/lectures-class-1.html#sec-creating-r-objects",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "Creating R Objects",
    "text": "Creating R Objects\nIn R, you will create what are called objects that store some information. That could be a single value like 5, an entire table of data with rows and columns, and even more complex objects. Objects are created using the assignment operator, &lt;-.\nEverything on the left hand side of the assignment operator &lt;- is an object. Everything on the right hand side of &lt;- are functions or values. Go ahead and execute the following lines of code.\n\nmy_first_object &lt;- \"hello\"\nmy_first_object\n\n[1] \"hello\"\n\nmy_second_object &lt;- c(5,6,7,8)\nmy_second_object\n\n[1] 5 6 7 8\n\n\nYou just assigned the value \"hello\" to an object named my_first_object. Note that R is case sensitive, my_first_object would be considered a different object as my_First_object.\nYou also created my_second_object that stores a vector of four values: 5, 6, 7, and 8. The c() function can be used to create a vector of values."
  },
  {
    "objectID": "lectures/lectures-class-1.html#sec-using-functions",
    "href": "lectures/lectures-class-1.html#sec-using-functions",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "Using Functions",
    "text": "Using Functions\nAnything you do in R is by using functions. In fact, learning R is just learning what functions are available and how to use them.\nFunctions start with the name of the function followed by parentheses function_name(). Inside the () is where you specify certain arguments separated by commas , . Some arguments are optional and some are required for the function to work.\nFor example, there is a function to create a sequence of numbers, seq().\n\nseq(1, 100, by = 10)\n\n [1]  1 11 21 31 41 51 61 71 81 91\n\n\nIn the seq() function above we specified three arguments, separated by commas. The first two arguments were set without specifying the argument name, however the third argument we used the argument name by to define seq(by = 10). If you don’t explicitly use the argument name it will implicitly assume an argument based on the order it is entered, depending on how the author created the function.\n\n\n\n\n\n\nHelper Function\n\n\n\nA handy tip is to frequently make use of the helper function, ?. Type ?seq into the R console. Helper documentation will be provided for that function and as you can see, the first argument defined is from and the second argument is to.\n\n\nThe order of arguments only matters if you do not specify argument names\nSpecifying the actual argument names, the above code is identical to the three following examples:\n\nseq(from = 1, to = 100, by = 10)\nseq(to = 100, by = 10, from = 1)\nseq(1, 100, 10)\n\nThere are also default values that arguments take, which means if you don’t define an argument it will take on the default value. The helper documentation shows that the from argument has a default of from = 1, therefore we could even leave out the from = argument because we were using the default value.\n\nseq(to = 100, by = 10)\n\nWhat this means is that it can be important to know what the default values are for functions you are using and you can figure that out with the helper function ?"
  },
  {
    "objectID": "lectures/lectures-class-1.html#sec-r-packages",
    "href": "lectures/lectures-class-1.html#sec-r-packages",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "R Packages",
    "text": "R Packages\nThe community of R users have developed a vast number of functions that expand on the functions that come with R. Many of the functions developed by R users allow you to do more complicated things with your data without having to be an advanced R programmer. And the great thing is that as more psychology researchers use R, the more functions there are specifically for psychological research.\nFunctions that R users develop are collected in what are called packages. Most R packages are hosted on The Comprehensive R Archive Network - CRAN. Some other packages, ones that are in more developmental stages and may not be as stable, are hosted on GitHub.\n\nInstall and Load Packages\nTo install packages from CRAN is easy. Simply type into the console window: install.packages(\"packagename\")\nFor example:\n\ninstall.packages(\"dplyr\")\n\nOnce you have a package installed, you can load that package into your current environment. Your R Environment consists of things such as objects (variables) you have created, data you have imported, and functions you have loaded. Your R Environment are like the tools and objects you have available to you and are working with.\nWhen you load a package you are bringing the functions from that package into your environment so you can start using them. To load a package is easy: library(package_name)\nFor example:\n\nlibrary(dplyr)"
  },
  {
    "objectID": "lectures/lectures-class-1.html#sec-data-frames",
    "href": "lectures/lectures-class-1.html#sec-data-frames",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "Data Frames",
    "text": "Data Frames\nThe main type of R object that you will be working with are data frames. You are probably already familiar with data frames. Excel uses this type of data structure, it is just rows and columns of data.\nMany R packages come loaded with data sets. Let’s take a look at a fun data set from the palmerpenguins package, do some simple transformations of the data, visualize, and do a simple statistical analysis.\n\n\n\n\n\nFirst, install the package\n\ninstall.packages(\"palmerpenguins\")\n\nThe install function should just be typed into the Console because this is a step that you only need to perform once. Go ahead and install dplyr and ggplot2 packages as well.\nThe library() function to load packages, however, is a necessary step for processing the data, therefore, it needs to be included in the reproducible script file.\nLoad palmerpenguins , dplyr , and ggplot2 packages. We will use dplyr to do some simple transformation of the data and ggplot2 to visualize the data.\n\n# load packages\nlibrary(palmerpenguins)\nlibrary(dplyr)\nlibrary(ggplot2)\n\nWhen you load palmerpenguins there is a data frame now available in your environment called penguins. However, it is not explicitly listed in your environment because it came from a package and not something you created. This is not required, but for the sake of being able to see the data frame in the Environment window, let’s assign the penguins data frame to a new data frame called data_import.\n\ndata_import &lt;- penguins\n\n\n\n\n\n\n\nNote\n\n\n\nI prefer to name data frames that I import with “import” that way it is clear which data frame is the original one. Then I create new data frames (R objects) with a different name. This allows me to easily identify and go back to the original data after I have done some transformations on it.\n\n\n\nViewing the Data\nLet’s first get to know this data, how it is structured, and what kind of values it stores. You can view a data frame by selecting it in the Environment window or by using the View() function.\n\nView(data_import)\n\n\n\n\n\n\n\nNote\n\n\n\nDo you think View() should be included in the R script or just typed directly into the Console?\n\n\nBy viewing the data we can see that there are columns that contain information such as the species of the penguin, the island it belongs to, some size dimensions, and more.\n\n\n\n\n\n\nNote\n\n\n\nNotice how the column names are simple but also convey useful information for someone to easily understand this data. For instance, the the column bill_length_mm is not only straightforward but conveys the unit of measurement. It is not always possible to create both concise and information rich column names like these. When that is the case you can go on the side of being concise while providing documentation elsewhere that provides more detail.\nThis principle of easy to understand is important and something we will keep coming back to.\n\n\nThis data frame has a small number of columns so they are all easy to see. However, some data sets you work with will have a lot more columns that are difficult to view on a single page. In those cases, it can be useful to get a list of the column names printed to the Console. This can be done using the colnames() function.\n\ncolnames(data_import)\n\nDoing so also allows you to copy and paste the column names from the console into your R script. This is a good strategy to avoid typos that can cause you headaches when writing R code.\nIt is important to understand what are the values and types of values stored in each column of your data. To get an initial peak at the data, you can use the head() function.\n\nhead(data_import)\n\nYou can only see the first 10 rows, but you can already see some useful information. For instance, the type of values are noted in gray below the column names between &lt; &gt;. We will discuss these in more detail soon, but notice that the column year is of type &lt;int&gt; meaning integer. Integers are simple numbers with no decimal places.\nYou may also notice that some columns contain NA values. These are missing values and are important to know if you have any in your data.\nTo get more information as to the values in each column you can use the unique() function along with a $ notation. $ is a notation to reference a certain column in a data frame. For example, to reference the species column in data_import you would specify data_import$species. unique() will get the unique set of values in a column of data. This is useful to evaluate what values are contained in a column.\n\nunique(data_import$species)\n\nIt looks like there are three unique values in the species column, Adelie, Gentoo, and Chinstrap. The species column is a type or class of values that are known as factors, again more on this in a bit. You could see this when we used head() with the notation &lt;fct&gt; meaning factor. But you can also see this because unique() also displayed the levels of the factor. Levels mean that there is a specified order to the values.\n\n\n\n\n\n\nNote\n\n\n\nWhat are the unique values in the year column? Does this column seem like it is a factor? What about sex?\n\n\n\n\nTypes of Values\nClasses are types of values that exist in R. Here are a list of some common value types:\n\ncharacter (or non-numeric) \"hello\", \"goodbye\"\ndouble (or numeric) 2, 32.55\ninteger 5, 99\nlogical TRUE, FALSE\nmissing NA NaN\n\nTo evaluate the type of values in a column you can use typeof()\n\ntypeof(data_import$bill_depth_mm)\ntypeof(data_import$flipper_length_mm)\n\nTo change the class of values in an object you can use as.character() , as.numeric() , as.double() , as.integer() , as.logical() functions.\n\nas.character(data_import$bill_depth_mm)\n\n\n\nFactors\nNotice that if you evaluate the type of values in species you get an “integer”. This is probably surprising to you because 1) They look like character values (non-numeric), and 2) I told you earlier that the species column is a factor. Factors are a special type of column, that represent levels of a category with an order to those levels. The actual values in Factors can be of type character, double, integer, or logical. However, they are represented as integers corresponding to the order of the levels. Factors become especially important in data visualization and statistical analysis.\nYou can set a column of values as a factor by using factor()\n\nfactor(data_import$year, levels = c(2007, 2008, 2009))\n\n\n\n\n\n\n\nNote\n\n\n\nNote that this line of code does not actually change the values in data_import (neither did the as.character(data_import$bill_depth_mm) line of code above). Don’t believe me? Run unique(data_import$year) or head(data_import).\nWhy do you think this is the case?\nIt is because we did not use the assignment operator. We simply printed the result of this function to the Console. In order to actually change the values in a data frame you need to assign &lt;- the result of the function factor() to a column in the data frame. In this case, to the values in the column species in the data_import object, data_import$species.\n\n\n\n\n\n\n\n\nNote\n\n\n\nHow did I know how to use the argument name levels = in factor()? You can learn about arguments a function can take, and what they do using the helper function ?. For instance type ?factor() in the console. In the Help window, you can see there are a number of arguments that can be specified in factor(). For levels, it states that it is an optional vector of the unique values that x might have taken. This tells us we need to supply a vector of unique values. You can use the c() function to create a vector of values. Type c(2007, 2008, 2009) in the Console. You can see there are three elements in the vector for each year. We specify this vector in the levels argument to tell factor() that these are the unique values in the data_import$year column."
  },
  {
    "objectID": "lectures/lectures-class-1.html#transforming-data",
    "href": "lectures/lectures-class-1.html#transforming-data",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "Transforming Data",
    "text": "Transforming Data\nJust for the fun of it, let’s do a simple transformation on the data, visualize a relationship between three variables, and statistically test a relationship between two variables. Three variables that we will look at are species, flipper_length_mm , and body_mass_g.\nFirst, let’s compute the mean flipper length and body mass for each species of penguin and store them in columns in the data frame. Because we are now changing the original data frame, let’s go ahead and call it something different. Because this is the data frame we will eventually plot, why not call it data_plot\n\ndata_plot &lt;- data_import |&gt;\n  mutate(.by = species,\n         flipper_length_mm.mean = mean(flipper_length_mm, na.rm = TRUE),\n         body_mass_g.mean = mean(body_mass_g, na.rm = TRUE))\n\nmutate() comes from the dplyr package and allows you to modify the values in existing columns or create new columns. We will learn more about this function and other functions in dplyr in the next class. But without even knowing much about it you can reasonably guess that we are creating new columns containing the mean of our two variables of interest. Further, we are calculating the mean separately by species. You can view the data frame and see that each species has a different mean value.\nWhat about that first line of code? The |&gt; notation at the end of the line says pass data_import into the mutate() function. This is how mutate() knows where these columns species, flipper_length_mm , and body_mass_g come from. Then the result of mutate() is assigned to a new object, data_plot.\nGo ahead and view data_plot. You can see that it is the same as data_import except it has two new columns, flipper_length_mm.mean and body_mass_g.mean."
  },
  {
    "objectID": "lectures/lectures-class-1.html#visualizing-data",
    "href": "lectures/lectures-class-1.html#visualizing-data",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "Visualizing Data",
    "text": "Visualizing Data\nWe will use the ggplot2 package to visualize the relationship between species, flipper_length_mm , and body_mass_g. Let’s do this step-by-step. First let’s build the data and aesthetic layers. These layers tell ggplot() what data to plot and how we map them onto the scales (e.g., x-axis and y-axis) of the graphic.\n\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species))\n\n\n\n\n\n\n\n\nNote that this only creates the overall structure of the graphic, no data is plotted yet. That is because there are a lot of different ways to visualize the data and we need to specify these visual elements in the geometries or geom layer.\n\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species)) +\n  geom_point()\n\n\n\n\n\n\n\n\nNote how it mapped species onto the color and shape of the data points.\nLet’s make the plot a littler prettier by using a customized theme, theme_classic()\n\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species)) +\n  geom_point() +\n  theme_classic()\n\n\n\n\n\n\n\n\nOptional: We can also add horizontal and vertical lines corresponding to the mean for each species that we calculated earlier.\n\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species)) +\n  geom_point() +\n  geom_hline(aes(yintercept = body_mass_g.mean, color = species)) +\n  geom_vline(aes(xintercept = flipper_length_mm.mean, color = species)) +\n  theme_classic()"
  },
  {
    "objectID": "lectures/lectures-class-1.html#statistical-analysis",
    "href": "lectures/lectures-class-1.html#statistical-analysis",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "Statistical Analysis",
    "text": "Statistical Analysis\nBased on the graphic visualization, it looks like there is a strong relationship between body mass and flipper length, perhaps unsurprisingly. Let’s calculate the correlation between these two variables and test whether it is statistically significant or not.\n\ncor.test(data_import$body_mass_g, data_import$flipper_length_mm)\n\n\n    Pearson's product-moment correlation\n\ndata:  data_import$body_mass_g and data_import$flipper_length_mm\nt = 32.722, df = 340, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.843041 0.894599\nsample estimates:\n      cor \n0.8712018 \n\n\nThe correlation is r = .87 and is statistically significant, p &lt; .05.\nThat was easy!"
  },
  {
    "objectID": "lectures/lectures-class-1.html#class-1-reproducible-script",
    "href": "lectures/lectures-class-1.html#class-1-reproducible-script",
    "title": "Class 1: An Introduction to Working with Data in R",
    "section": "Class 1: Reproducible Script",
    "text": "Class 1: Reproducible Script\n \n\n# load packages\nlibrary(palmerpenguins)\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# import data\ndata_import &lt;- penguins\n\n# transform data\ndata_plot &lt;- data_import |&gt;\n  mutate(.by = species,\n         flipper_length_mm.mean = mean(flipper_length_mm, na.rm = TRUE),\n         body_mass_g.mean = mean(body_mass_g, na.rm = TRUE))\n\n# visualize data\nggplot(data_plot, aes(x = flipper_length_mm, y = body_mass_g,\n                      color = species, shape = species)) +\n  geom_point() +\n  geom_hline(aes(yintercept = body_mass_g.mean, color = species)) +\n  geom_vline(aes(xintercept = flipper_length_mm.mean, color = species)) +\n  theme_classic()\n\n# statistical analysis\ncor.test(data_import$body_mass_g, data_import$flipper_length_mm)\n\n\nIn the rest of the course, we will go into greater depth on transforming data, data visualization, and statistical analysis."
  },
  {
    "objectID": "lectures/lectures-class-3.html",
    "href": "lectures/lectures-class-3.html",
    "title": "Class 3: Data Transformation",
    "section": "",
    "text": "We will cover the basics of data transformation in this class."
  },
  {
    "objectID": "lectures/lectures-class-3.html#this-is-the-way",
    "href": "lectures/lectures-class-3.html#this-is-the-way",
    "title": "Class 3: Data Transformation",
    "section": "This is The Way",
    "text": "This is The Way\nAlthough you will be learning R in this class, it might be more appropriate to say that you are learning the tidyverse.\n\nThe tidyverse is a set of packages that share an underlying design philosophy, grammar, and data structures. The tidyverse consists of packages that are simple and intuitive to use and will take you from importing data (with readr), restructuring and transforming data (with tidyr and dplyr), and to graphically visualizing data (with ggplot2)."
  },
  {
    "objectID": "lectures/lectures-class-3.html#dplyr",
    "href": "lectures/lectures-class-3.html#dplyr",
    "title": "Class 3: Data Transformation",
    "section": "dplyr",
    "text": "dplyr\nThe language of dplyr will be the underlying framework for how you will think about manipulating and transforming data in R.\n\ndplyr uses intuitive language that you are already familiar with. As with any R function, you can think of functions in the dplyr package as verbs that refer to performing a particular action on a data frame.\n\nrename() renames columns\nfilter() filters rows based on their values in specified columns\nselect() selects (or removes) columns\nmutate() creates new columns based on transformation from other columns, or edits values within existing columns\nsummarise() aggregates across rows to create a summary statistic (means, standard deviations, etc.)\n\nFor more information on these functions Visit the dplyr webpage\nFor more detailed instructions on how to use the dplyr functions see the Data Transformation chapter in the popular R for Data Science book."
  },
  {
    "objectID": "lectures/lectures-class-3.html#stay-within-the-data-frame",
    "href": "lectures/lectures-class-3.html#stay-within-the-data-frame",
    "title": "Class 3: Data Transformation",
    "section": "Stay within the Data Frame",
    "text": "Stay within the Data Frame\nNot only is the language of dplyr intuitive but it allows you to perform data manipulations all within the data frame itself, without having to create external variables, lists, for loops, etc.\nIt can be tempting to hold information outside of a data frame but in general I suggest avoiding this strategy. Instead, hold the information in a new column within the data frame itself.\nFor example: A common strategy I see in many R scripts is to hold the mean or count of a column of values outside the data frame and in a new variable in the Environment.\n\ndata &lt;- data.frame(x = c(1,6,4,3,7,5,8,4), \n                   y = c(2,3,2,1,4,6,4,3))\n\ny_mean &lt;- mean(data$y)\n\nThis variable is then used to subtract out the mean from the values in column y\n\nlibrary(dplyr)\n\ndata &lt;- mutate(data, \n               y_new = y - y_mean)\n\n\n\n\n\n\n  \n    \n    \n      x\n      y\n      y_new\n    \n  \n  \n    1.000\n2.000\n−1.125\n    6.000\n3.000\n−0.125\n    4.000\n2.000\n−1.125\n    3.000\n1.000\n−2.125\n    7.000\n4.000\n0.875\n    5.000\n6.000\n2.875\n  \n  \n  \n    \n       \n    \n  \n\n\n\n\nAlthough there is nothing wrong with this approach, in general, I would advise against this strategy.\nA better strategy is to do all this without leaving the data frame data.\n\nlibrary(dplyr)\n\ndata &lt;- data.frame(x = c(1,6,4,3,7,5,8,4), \n                   y = c(2,3,2,1,4,6,4,3))\n\ndata &lt;- mutate(data,\n               y_mean = mean(y),\n               y_new = y - y_mean)\n\n\n\n\n\n\n  \n    \n    \n      x\n      y\n      y_mean\n      y_new\n    \n  \n  \n    1.000\n2.000\n3.125\n−1.125\n    6.000\n3.000\n3.125\n−0.125\n    4.000\n2.000\n3.125\n−1.125\n    3.000\n1.000\n3.125\n−2.125\n    7.000\n4.000\n3.125\n0.875\n    5.000\n6.000\n3.125\n2.875"
  },
  {
    "objectID": "lectures/lectures-class-3.html#example-data-set",
    "href": "lectures/lectures-class-3.html#example-data-set",
    "title": "Class 3: Data Transformation",
    "section": "Example Data Set",
    "text": "Example Data Set\nLet’s use what we learned in Class 2 and import two data files.\n⬇️ class_3_repetition_rawdata.txt\n⬇️ class_3_mnemonic_rawdata.csv\nTry to figure out how to import the data yourself (hint: use the Import Datatset GUI to help identify the correct file path and import parameters)\n\n\nShow the Code\nlibrary(readr)\n\nrepetition_import &lt;- read_delim(\"data/class_3_repetition_rawdata.txt\", \n                                delim = \"\\t\", escape_double = FALSE, \n                                trim_ws = TRUE)\n\nmnemonic_import &lt;- read_csv(\"data/class_3_mnemonic_rawdata.csv\")\n\n\nThese data come from a hypothetical (I made it up) research study to compare the effectiveness of two memory techniques, a mnemonic technique and a spaced repetition technique, for improving memory retention. Participants were randomly assigned to one of the two memory techniques and completed 3 memory tests (A, B, and C). The number of correctly recalled words for each memory test was recorded in the two data files by research assistants.\nUse what you learned from Class 1 to explore the data\n\nwhat are the column names?\nwhat type of values are in each column?\n\nYou will recognize there are some differences between these two data sets even though they both contain memory recall performance on 3 memory tests (A, B, and C). It turns out that the research assistant who ran participants in the spaced repetition condition did not follow the lab’s protocol for recording data 🤦‍♀️\nThey used wrong column names, recorded the memory tests as X, Y, and Z (A, B, and C, respectively), they left out what condition these data were from, and they gave some particpants less than 3 memory tests! 🤬"
  },
  {
    "objectID": "lectures/lectures-class-3.html#rename",
    "href": "lectures/lectures-class-3.html#rename",
    "title": "Class 3: Data Transformation",
    "section": "rename()",
    "text": "rename()\nFirst, let’s fix the RA’s mistake by renaming the columns in the spaced repetition data as they are named in the mnemonic data. We can do so using the rename() function. The format for this function looks something like:\n\nrename(new_name = old_name)\n\nHere is how we would rename the columns in the spaced repetition data we imported.\n\nlibrary(dplyr)\n\nrepetition_data &lt;- repetition_import |&gt;\n  rename(participant_id = `subject number`,\n         word_list = List,\n         recall_correct = recallCorrect)\n\nFor more options on how to use rename() see the documentation here"
  },
  {
    "objectID": "lectures/lectures-class-3.html#filter",
    "href": "lectures/lectures-class-3.html#filter",
    "title": "Class 3: Data Transformation",
    "section": "filter()",
    "text": "filter()\nfilter() is an inclusive filter and requires the use of logical statements. Here are a list of some commone logical operators in R:\n\nIn addition to the logical operators, other functions can be used in filter(), such as:\n\nis.na() - include if missing\n!is.na() - include if not missing\nbetween() - values that are between a certain range of numbers\nnear() - values that are near a certain value\n\nFor more options on how to use filter() see the documentation here.\nLet’s remove rows that correspond to those participants that did not complete 3 memory tests. It turns out that those participants were always ran on Thursday or Friday, must have been a bad day for the research assistant 😢. We can use filter() to remove rows that have Thursday or Friday in the day column.\n\nrepetition_data &lt;- repetition_data |&gt;\n  filter(day != \"Thursday\", day != \"Friday\")"
  },
  {
    "objectID": "lectures/lectures-class-3.html#select",
    "href": "lectures/lectures-class-3.html#select",
    "title": "Class 3: Data Transformation",
    "section": "select()",
    "text": "select()\nselect() allows you to select which columns to keep and/or remove.\n\nselect(columns, to, keep)\n\n\nselect(-columns, -to, -remove)\n\nselect() can be used with more complex operators and tidyselect functions, see the documentation here.\nFor the repetition data, let’s only keep the following columns\n\nparticipant_id\nword_list\nrecall_correct\n\n\nrepetition_data &lt;- repetition_data |&gt;\n  select(participant_id, word_list, recall_correct)\n\nAnother way to do this would be:\n\nrepetition_data &lt;- repetition_data |&gt;\n  select(-day, -time, -computer_station)"
  },
  {
    "objectID": "lectures/lectures-class-3.html#mutate",
    "href": "lectures/lectures-class-3.html#mutate",
    "title": "Class 3: Data Transformation",
    "section": "mutate()",
    "text": "mutate()\nmutate() is a very powerful function. It basically allows you to do any computation or transformation on the values in the data frame. See the full documentation here.\nThe basic format for mutate goes something like:\n\nmutate(column_name = value,\n       another_col = a_function(),\n       last_col = col1 + col2)\n\nWithin mutate() the = sign functions similarly to the assignment operator &lt;-, where the result of whatever is on the right-hand side of = gets assigned to the column that is specified on the left-hand side (an existing column or a new one you are creating).\nI want to demonstrate basic but common examples of using mutate()\nWe need to create a column specifying what condition the spaced repetition data came from, dang RA!\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(condition = \"spaced repetition\")\n\nEasy!\nNow let’s do something a little more complicated.\n\ncase_when()\ncase_when() is basically a sequence of if else type of statements where each statement is evaluated, if it is true then it is given a certain value, else the next statement is evaluated, and so on. The basic format of case_when() looks like:\n\nmutate(a_column = case_when(a logical statement ~ a value,\n                            another statement ~ another value,\n                            .default = and another value))\n\nLet’s see an example of this with the spaced repetition data. We need to change the values in the word_list column so that X is A, Y is B, and Z is C.\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(word_list = case_when(word_list == \"X\" ~ \"A\",\n                               word_list == \"Y\" ~ \"B\",\n                               word_list == \"Z\" ~ \"C\"))\n\nJust to be clear, you can create an entirely new column this way\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(new_word_list = case_when(word_list == \"X\" ~ \"A\",\n                                   word_list == \"Y\" ~ \"B\",\n                                   word_list == \"Z\" ~ \"C\"))\n\n\n\n.by =\nThis next computation is not necessary for our example data set but I want to demonstrate the use of mutate(.by = ). This option is very handy if you want to perform functions separately on different groups or splits of the data frame.\nFor example, let’s calculate the mean for each word list separately.\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(.by = word_list, \n         word_list_mean = mean(recall_correct))\n\nCompare this with\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(word_list_mean = mean(recall_correct))\n\nYou can use multiple columns in .by =\n\nrepetition_data &lt;- repetition_data |&gt;\n  mutate(.by = c(participant_id, word_list), \n         word_list_mean = mean(recall_correct))\n\nIt doesn’t make much sense in this case\nThe .by = option becomes extremely useful when used in summarise() which we will get to in a bit.\n\n\nrowwise()\nWhile .by = is used when performing functions on groups of rows, rowwise() is used when you want to perform operations row by row, treating each row as a single group. This is useful when you want to aggregate data (e.g., mean()) across multiple columns.\nThe data set we are working with does not provide a good demonstration of this so let’s create a different set of data to look at how to use rowwise()\n\ndata_sample &lt;- data.frame(ID = 1:5,\n                          Q1 = sample(1:50, 5),\n                          Q2 = sample(1:50, 5),\n                          Q3 = sample(1:50, 5))\n\n\n\n\n\n\n  \n    \n    \n      ID\n      Q1\n      Q2\n      Q3\n    \n  \n  \n    1.000\n22.000\n12.000\n50.000\n    2.000\n39.000\n29.000\n33.000\n    3.000\n49.000\n26.000\n6.000\n    4.000\n37.000\n4.000\n13.000\n    5.000\n4.000\n42.000\n41.000\n  \n  \n  \n    \n       \n    \n  \n\n\n\n\nHere is an example where we have a single row per participant with columns representing their responses to three different questions. Let’s say we want to calculate their mean response across these three columns.\n\n\n\n\n\n\nImportant\n\n\n\nYou NEED to ungroup() the data frame whenever you are done with rowwise()\n\n\n\ndata_sample &lt;- data_sample |&gt;\n  rowwise() |&gt;\n  mutate(Q_mean = mean(c(Q1, Q2, Q3))) |&gt;\n  ungroup()\n\n\n\n\n\n\n  \n    \n    \n      ID\n      Q1\n      Q2\n      Q3\n      Q_mean\n    \n  \n  \n    1.000\n22.000\n12.000\n50.000\n28.000\n    2.000\n39.000\n29.000\n33.000\n33.667\n    3.000\n49.000\n26.000\n6.000\n27.000\n    4.000\n37.000\n4.000\n13.000\n18.000\n    5.000\n4.000\n42.000\n41.000\n29.000\n  \n  \n  \n    \n       \n    \n  \n\n\n\n\nNote the difference when you don’t use rowwise(), it calculates the mean across all rows in the data\n\ndata_sample &lt;- data_sample |&gt;\n  mutate(Q_mean = mean(c(Q1, Q2, Q3)))\n\n\n\n\n\n\n  \n    \n    \n      ID\n      Q1\n      Q2\n      Q3\n      Q_mean\n    \n  \n  \n    1.000\n22.000\n12.000\n50.000\n27.133\n    2.000\n39.000\n29.000\n33.000\n27.133\n    3.000\n49.000\n26.000\n6.000\n27.133\n    4.000\n37.000\n4.000\n13.000\n27.133\n    5.000\n4.000\n42.000\n41.000\n27.133\n  \n  \n  \n    \n       \n    \n  \n\n\n\n\n\nWe can put all the dplyr functions together through a series of pipes:\n\nrepetition_data &lt;- repetition_import |&gt;\n  rename(participant_id = `subject number`,\n         word_list = List,\n         recall_correct = recallCorrect) |&gt;\n  filter(day != \"Thursday\", day != \"Friday\") |&gt;\n  select(participant_id, word_list, recall_correct) |&gt;\n  mutate(condition = \"spaced repetition\",\n         word_list = case_when(word_list == \"X\" ~ \"A\",\n                               word_list == \"Y\" ~ \"B\",\n                               word_list == \"Z\" ~ \"C\")) |&gt;\n  mutate(.by = word_list, \n         word_list_mean = mean(recall_correct))\n\nLet’s also do one thing to the mnemonic data set and then row bind these two data sets into one data frame.\n\nmnemonic_data &lt;- mnemonic_import |&gt;\n  select(participant_id, condition, word_list, recall_correct)\n\n\ndata_merged &lt;- bind_rows(mnemonic_data, repetition_data) |&gt;\n  select(-word_list_mean) |&gt;\n  arrange(participant_id)"
  },
  {
    "objectID": "lectures/lectures-class-3.html#summarise",
    "href": "lectures/lectures-class-3.html#summarise",
    "title": "Class 3: Data Transformation",
    "section": "summarise()",
    "text": "summarise()\nThe thing is, we don’t really care about performance on each individual word_list (A, B, and C). We care about the participant’s overall performance, aggregated across all three word lists. To aggregrate data using dplyr we can use summarise(). The result of summarise() is a reduced data frame with fewer rows. In this example, we will essentially collapse the three rows corresponding to each word list into a single row containing an aggregated summary statistic (such as a sum or mean value).\nIn a lot of ways, the code inside of summarise() looks a lot like the code we could put in mutate(). The difference is that mutate() does not collapse the data frame but summarise() does.\nTo figure out what to specify in .by = you should think of the data frame that you want to end up with (which columns you want to keep). Ultimately, we will want a data set with participant_id, condition, and mean recall performance - this last one we will create inside of summarise().\n\ndata_scores &lt;- data_merged |&gt;\n  summarise(.by = c(participant_id, condition),\n            recall_correct_mean = mean(recall_correct))\n\n\n\n\n\n\n  \n    \n    \n      participant_id\n      condition\n      recall_correct_mean\n    \n  \n  \n    1.000\nspaced repetition\n3.000\n    2.000\nmnemonic\n7.333\n    4.000\nmnemonic\n5.000\n    5.000\nspaced repetition\n5.000\n    6.000\nmnemonic\n6.667\n    8.000\nmnemonic\n5.333\n    9.000\nspaced repetition\n3.333\n    10.000\nmnemonic\n4.000\n    12.000\nmnemonic\n8.667\n    13.000\nspaced repetition\n5.000\n    14.000\nmnemonic\n7.000\n    16.000\nmnemonic\n7.333\n    17.000\nspaced repetition\n5.333\n    19.000\nspaced repetition\n6.667\n  \n  \n  \n    \n       \n    \n  \n\n\n\n\nYou can calculate other summary statistics such as:\n\ndata_scores &lt;- data_merged |&gt;\n  summarise(.by = c(particpant_id, condition),\n            recall_correct_mean = mean(recall_correct),\n            recall_correct_sd = sd(recall_correct),\n            recall_correct_sum = sum(recall_correct),\n            recall_correct_min = min(recall_correct),\n            recall_correct_max = max(recall_correct))\n\nNotice the difference when you don’t use .by =:\n\ndata_scores &lt;- data_merged |&gt;\n  summarise(recall_correct_mean = mean(recall_correct),\n            recall_correct_sd = sd(recall_correct),\n            recall_correct_sum = sum(recall_correct),\n            recall_correct_min = min(recall_correct),\n            recall_correct_max = max(recall_correct))\n\n\n\n\n\n\n  \n    \n    \n      recall_correct_mean\n      recall_correct_sd\n      recall_correct_sum\n      recall_correct_min\n      recall_correct_max\n    \n  \n  \n    5.690\n2.006\n239.000\n2.000\n9.000"
  },
  {
    "objectID": "lectures/lectures-class-3.html#ggplot2",
    "href": "lectures/lectures-class-3.html#ggplot2",
    "title": "Class 3: Data Transformation",
    "section": "ggplot2",
    "text": "ggplot2\nLet’s plot the data to see what the difference in memory recall is for the two types of strategy:\n\nlibrary(ggplot2)\n\nggplot(data_scores, aes(condition, recall_correct_mean)) +\n  geom_point(position = position_jitter(width = .1, seed = 88), alpha = .3) +\n  stat_summary(fun = mean, geom = \"point\", \n               color = \"firebrick\", size = 3) +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", \n               color = \"firebrick\", width = .2) +\n  coord_cartesian(ylim = c(0, 10)) +\n  scale_x_discrete(labels = c(\"Mnemonic\", \"Spaced Recognition\")) +\n  labs(title = \"Recal Performance for Mnemonic and Spaced Recognition\",\n       y = \"Recall Performance\",\n       x = \"\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(size = 14),\n        axis.title.y = element_text(size = 14),\n        axis.text.y = element_text(size = 12))"
  },
  {
    "objectID": "lectures/lectures-class-3.html#reproducible-script",
    "href": "lectures/lectures-class-3.html#reproducible-script",
    "title": "Class 3: Data Transformation",
    "section": "Reproducible Script",
    "text": "Reproducible Script\n\n\nShow Code\n# load packages\nlibrary(readr)\nlibrary(dplyr)\nlibrary(gt)\nlibrary(ggplot2)\n\n# import data\nrepetition_import &lt;- read_delim(\"data/class_3_repetition_rawdata.txt\", \n                                delim = \"\\t\", escape_double = FALSE, \n                                trim_ws = TRUE)\n\nmnemonic_import &lt;- read_csv(\"data/class_3_mnemonic_rawdata.csv\")\n\n# trasnform data\nrepetition_data &lt;- repetition_import |&gt;\n  rename(participant_id = `subject number`,\n         word_list = List,\n         recall_correct = recallCorrect) |&gt;\n  filter(day != \"Thursday\", day != \"Friday\") |&gt;\n  select(participant_id, word_list, recall_correct) |&gt;\n  mutate(condition = \"spaced repetition\",\n         word_list = case_when(word_list == \"X\" ~ \"A\",\n                               word_list == \"Y\" ~ \"B\",\n                               word_list == \"Z\" ~ \"C\")) |&gt;\n  mutate(.by = word_list, \n         word_list_mean = mean(recall_correct))\n\nmnemonic_data &lt;- mnemonic_import |&gt;\n  select(participant_id, condition, word_list, recall_correct)\n\n# merge data\ndata_merged &lt;- bind_rows(mnemonic_data, repetition_data) |&gt;\n  select(-word_list_mean) |&gt;\n  arrange(participant_id)\n\n# aggregate data\ndata_scores &lt;- data_merged |&gt;\n  summarise(.by = c(participant_id, condition),\n            recall_correct_mean = mean(recall_correct))\n\n# plot aggregate data\nggplot(data_scores, aes(condition, recall_correct_mean)) +\n  geom_point(position = position_jitter(width = .1, seed = 88), alpha = .3) +\n  stat_summary(fun = mean, geom = \"point\", \n               color = \"firebrick\", size = 3) +\n  stat_summary(fun.data = mean_cl_normal, geom = \"errorbar\", \n               color = \"firebrick\", width = .2) +\n  coord_cartesian(ylim = c(0, 10)) +\n  scale_x_discrete(labels = c(\"Mnemonic\", \"Spaced Recognition\")) +\n  labs(title = \"Recal Performance for Mnemonic and Spaced Recognition\",\n       y = \"Recall Performance\",\n       x = \"\") +\n  theme_classic() +\n  theme(axis.text.x = element_text(size = 14),\n        axis.title.y = element_text(size = 14),\n        axis.text.y = element_text(size = 12))\n\n\n\n✏️ Start Learning Activity -&gt;"
  },
  {
    "objectID": "lectures/lectures-class-4.html",
    "href": "lectures/lectures-class-4.html",
    "title": "Class 4: Reproducible Projects",
    "section": "",
    "text": "Up to this point we have not had to give much thought to project organization and reproducibility because you have mainly been working with a single R script and importing one or two data files. However, working on a research project often involves a larger set of R scripts, multiple data files, and a report containing data visualizations and statistical analyses.\nProject organization is often overlooked at the expense of “just getting it done” because it takes more time and forethought to organize a project. However, the “just getting it done” approach can lead to a lot of unintended consequences:\nThe thing is, simply using R does not get around any of this. In fact, sometimes it can exacerbate it because of the extra cognitive demand faced when writing code. This extra demand can make the “just getting it done” approach more tempting. So what is the solution?\nThe solution is to slow down and give some thought to the organization of your project and it’s reproducibility."
  },
  {
    "objectID": "lectures/lectures-class-4.html#reproducible-projects",
    "href": "lectures/lectures-class-4.html#reproducible-projects",
    "title": "Class 4: Reproducible Projects",
    "section": "Reproducible Projects",
    "text": "Reproducible Projects\nPart of the scientific process involves carefully documenting every step in our procedures. Doing so not only ensures higher quality research, but also enables your future self and others to fully reproduce what you did, go back and analyze the data in a different way, or catch errors in the data analysis process. Without a fully reproducible project, it may be difficult or impossible to catch errors that were made.\n\nWhat does reproducibility mean?\nReproducibility means that all data processing and analysis steps can be fully reproduced using only the original raw data files and the execution of the R scripts. There are different levels of reproducibility (I made these up):\n\nPartially reproducible - only some data processing and analysis steps can be reproduced, which may be due to a lack of original raw data files, the “just get it done” approach, or the use of proprietary and non-reproducible software.\nMinimally reproducible (acceptable) - all data processing and analysis steps can be reproduced on any research team members computer without any modifications needed.\nModerately reproducible (desired) - meets the minimal level plus other people not involved in the research project can reproduce the steps with minimal modifications.\nHighly reproducible (good luck!) - fully reproducible without major modifications needed by people not involved in the research project 5 - 10+ years from now.\n\nA minimal level of reproducibility is still acceptable, as achieving more requires significant time and effort. We should strive for a moderate amount of reproducibility but achieving it requires more than just writing code. Your code must be organized, easy to understand, and include notes and documentation. Even if you or someone else attempts to reproduce your steps in the future, they can modify the code to make it work. The highest level of reproducibility is difficult to achieve due to software and code updates. Your code may only work with the current version of R or other packages. There are solutions to this problem of software and code updates, but who knows if those will work in the future!\n\nSimply using R for data analysis does not guarantee that your workflow is reproducible. In fact, there are many non-reproducible ways to use R. To ensure at least a moderate level of reproducibility, consider the following criteria (this is not an exhaustive list):\n\nYour statistical analysis (the final step) can be fully reproduced from the raw data files and your R scripts\nYour code can be reproduced on other computers without any modifications\nYour data and R scripts are organized and documented in a way that makes them easily understandable\n\nThis last criterion is extremely important, but is often overlooked. If others cannot understand your workflow, then it is not moderately reproducible. Therefore, it is important to take the time and think about the organization of your project, files, data, and scripts."
  },
  {
    "objectID": "lectures/lectures-class-4.html#project-workflow",
    "href": "lectures/lectures-class-4.html#project-workflow",
    "title": "Class 4: Reproducible Projects",
    "section": "Project Workflow",
    "text": "Project Workflow\nA good starting point for organizing your project is to map out the steps required for processing and analyzing your data.\nA typical data analysis workflow looks something like this:\n\n\n\n\n\nYou will always start with a messy raw data file. Messy raw data files are hard to understand, have poor column and value labels, contain way too many columns and rows, and are just hard to work with. The initial data preparation stage is all about getting raw data files that are easy to work with.\nThe end product of the data preparation stage is tidy raw data files. Tidy raw data files are easy to understand, have sensible column and value labels, contain only relevant columns and rows, and are easy to work with.\nOnce you have a tidy raw data file you can start on the data analysis stage. The workflow for this stage can vary widely depending on your particular research project. However, there are typically at least two end products of the data analysis stage:\n\nA data file that is ready for statistical analysis\nA report document of the results from your statistical analysis (also includes data visualizations)\n\nI suggest using this data analysis workflow as a starting point for organizing your project:\n\nOrganize your folders and files to match this workflow\nCreate separate scripts for each stage"
  },
  {
    "objectID": "lectures/lectures-class-4.html#file-organization",
    "href": "lectures/lectures-class-4.html#file-organization",
    "title": "Class 4: Reproducible Projects",
    "section": "File Organization",
    "text": "File Organization\nGood project organization starts with easy to understand folder and file organization. You want this organization to match your data analysis workflow:\n\n\nData Folder\nNotice how the structure of the data folder follows the data analysis workflow. The original messy raw data files are stored in data / raw / messy. The tidy raw data files are stored in data / raw. And the processed and cleaned data files are stored in data\nAlternatively, if you only have one original messy raw data file that you are working with you can just put all the data files in data and name the data files appropriately:\n\nThe basic priniciple here is that your data folder organization and data file naming maps onto the end products in your data analysis workflow.\n\n\nR Folder\nI highly recommend that you put all your R scripts in one folder, rather than having them scattered across different folders.\nAdditionally, I recommend that you append a prefix number corresponding to the order in which the scripts need to be ran and a suffix corresponding to what stage of the data analysis workflow it is in:\n\n1_tidyraw.R\n2_score_clean.R\n3_merge.R\n\nUtlimately these scripts should be cleaned up, commented, and easy to understand.\nInitially, coding can be messy as you grapple with determining the precise data processing approach. You might consider creating a script (or a folder of scripts) that are for messing around and figuring out how to process your data:\n\nUntitled.R\n\n\n\nAnalyses Folder\nThe analyses folder will contain Quarto documents (more on these in the next class) that you will use to genearate reports for exploring your data, creating data visualizations, and conduct statistical analyses. This folder will have at least one file:\n\nMain Analyses.qmd\n\nThese document should be cleaned up, well organized, and easy to understand.\nAs with the R scripts, you might like to have a Quarto document (or folder of documents) just for messing around and figuring out how to analyze your data:\n\nUntitled.qmd\n\n\n\nmainscript\nYou might also consider creating a mainscript.R or mainscript.qmd file to source all your R scripts and Quarto documents, rather than opening and sourcing each R script and Quarto document one at a time.\nIt might be a file simply containing:\n\n## data preparation\nsource(\"R/1_tidyraw.R\")\n\n## data scoring\nsource(\"R/2_score_clean.R\")\nsource(\"R/3_merge.R\")\n\n## statistical analysis\nlibrary(quarto)\nquarto_render(\"analyses/Main Analyses.qmd\")\n\nI typically just include the mainscript file in the root directory of the project rather than in the R script folder.\nA complete folder and file organization might look something like:"
  },
  {
    "objectID": "lectures/lectures-class-4.html#importing-data",
    "href": "lectures/lectures-class-4.html#importing-data",
    "title": "Class 4: Reproducible Projects",
    "section": "Importing Data",
    "text": "Importing Data\nUp until now, you have been using absolute file paths and the RStudio Import Dataset GUI for importing files into R. This is not a reproducible way of importing data into R. You can still use the RStudio Import Dataset GUI to figure out what type of data file you are importing (e.g., tab-delimited, csv) but I will now show you a simple and reproducible way of importing data into R.\n\nFile Paths\nR needs to know the full file path to the file on your computer in order to import it - this is what is referred to as an absolute file path. Absolute file paths start at the root directory of your computer and might look something like:\n\nOn Macs:\nUsers/username/projects/project_name/data/a_file.csv\nOn Windows:\nC:\\username\\projects\\project_name\\data\\a_file.csv\n\nRelative file paths on the other hand, start from a folder - typically a project folder\n\ndata/a_file.csv\n\nRelative file paths need to be used in order for your project to meet even a minimal level of reproducibility. A relative file path can be used on different computers as long as the internal organization of folders and files for the project are the same.\nHowever, at some point your computer does need to know the absolute file path to your project folder. A convenient and reproducible way of doing this is by using a combination of RStudio Projects and here::here() .\n\n\nRStudio Projects\nRStudio Projects allow you to open isolated instances of R and RStudio for each of your projects. RStudio projects are convenient for a number of reasons, but the most useful thing is setting a file marker for where the root directory of your project folder is located.\nTo create an RStudio Project:\n\nCreate a folder for your project (if you do not have one yet)\nFile -&gt; New Project…\nChoose Existing Directory -&gt; Browse to your project folder -&gt; Create Project\n\nNotice that there is now a .Rproj file in your project folder\n\nWhen working on your project, you should always open RStudio by opening the .Rproj file\nYou can also see which RStudio project is open and open RStudio projects in the very top-right corner of RStudio.\n\n\n\nhere::here()\nIn combination with RStudio projects the here package offers a convenient way of specifying relative file paths.\nWhen you load the here package with library(here) it will search for the .Rproj file and start file paths at that point whenever the here() function is used.\n\nlibrary(here)\n\nhere() starts at /Users/jtsukahara3/GitHub Repos/r-for-psychology-students\n\n\nNotice how that where here() starts is an absolute file path to your project folder. You did not have to specify the absolute file path in code. Meaning this is a reproducible way for the absolute file path to automatically be set.\nNow you can use a relative file path inside of here()\n\nhere(\"data/a_file.csv\")\n\n[1] \"/Users/jtsukahara3/GitHub Repos/r-for-psychology-students/data/a_file.csv\"\n\n\nEvery time you use here() you know that the file path will start at where you have your .Rproj file saved. Instead of messing around with working directories using setwd() or getwd(), just use here() and RStudio Projects. This becomes especially helpful when working with Quarto documents.\nYou can visually separate the folder path and the file name, making your script easier to read.\n\nhere(\"data\", \"a_file.csv\")\n\n[1] \"/Users/jtsukahara3/GitHub Repos/r-for-psychology-students/data/a_file.csv\"\n\n\nYou can then use here() inside of import and and output functions:\n\nlibrary(readr)\nlibrary(here)\n\ndata_import &lt;- read_csv(here(\"data\", \"a_file.csv\"))\n\nwrite_csv(data_import, here(\"data\", \"a_new_file.csv\"))"
  },
  {
    "objectID": "lectures/lectures-class-4.html#using-templates",
    "href": "lectures/lectures-class-4.html#using-templates",
    "title": "Class 4: Reproducible Projects",
    "section": "Using Templates",
    "text": "Using Templates\nWriting organized, clean, and easy to understand R code is hard. Starting with a template R script can help a lot. For this purpose, I have developed an R package psyworkflow that contains R script templates you can use.\nSee documentation on psyworkflow\n\nInstall\nFirst, if you do not have the devtools package installed:\n\ninstall.packages(\"devtools\")\n\nInstall the psyworkflow package from my GitHub repository using the devtools package:\n\ndevtools::install_github(\"dr-JT/psyworkflow\")\n\nRestart R\n\nSession -&gt; Restart R\n\n\n\nDownload R Script Templates\nIf you already have an RProject setup and just want to download some of the R script templates you can do so with the get_template() function.\n\npsyworkflow::get_template()\n\nTo see what the options are type in the console window\n\n?psyworkflow::get_template\n\n\n\nShow Tidy Template Script\n# ---- Setup -------------------------------------------------------------------\n# packages\nlibrary(here)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(purrr) # delete if not importing a batch of files\n\n# directories\nimport_dir &lt;- \"data/raw/messy\"\noutput_dir &lt;- \"data/raw\"\n\n# file names\ntask &lt;- \"taskname\"\nimport_file &lt;- paste(task, \".txt\", sep = \"\")\noutput_file &lt;- paste(task, \"raw.csv\", sep = \"_\")\n# ------------------------------------------------------------------------------\n\n# ---- Import Data -------------------------------------------------------------\n# to import a single file\ndata_import &lt;- read_delim(here(import_dir, import_file), delim = \"\\t\",\n                          escape_double = FALSE, trim_ws = TRUE)\n\n# alternatively to import a batch of files...\n# change the arguments in purrr::map_df() depending on type of data files\n# this example is for files created from eprime and needs encoding = \"UCS-2LE\"\nfiles &lt;- list.files(here(import_dir, task), pattern = \".txt\", full.names = TRUE)\ndata_import &lt;- files |&gt;\n  map_df(read_delim, delim = \"\\t\",\n         escape_double = FALSE, trim_ws = TRUE, na = \"NULL\",\n         locale = locale(encoding = \"UCS-2LE\"))\n# ------------------------------------------------------------------------------\n\n# ---- Tidy Data ---------------------------------------------------------------\ndata_raw &lt;- data_import |&gt;\n  rename() |&gt;\n  filter() |&gt;\n  mutate() |&gt;\n  select()\n# ------------------------------------------------------------------------------\n\n# ---- Save Data ---------------------------------------------------------------\nwrite_csv(data_raw, here(output_dir, output_file))\n# ------------------------------------------------------------------------------\n\nrm(list = ls())\n\n\n\n\nCreate a New Project\nClose RStudio and reopen a new instance of RStudio (not from an RProject file).\nOnce you have the psyworkflow package installed you will be able to create a new RProject directory and file from my Research Study template. This will automatically create the directory structure outlined in the previous chapter. It will also add template R scripts in R / templates and a mainscript.qmd file.\nUsing this template will allow you to get right to working with your data in R, without having to spend too much time thinking about organization (I have already done that for you).\nTo create an RProject from this template:\nFile -&gt; New Project… -&gt; New Directory -&gt; Research Study (you might need to scroll down to see it)\nThis will bring up a window to customize the template:\n\nType in whatever you want for the Directory Name - this will end up being the name of the project folder and RProject file.\nClick on Browse… and create the project on your desktop, for now.\nKeep all the defaults and select Create Project.\nGive it some time, and it will reopen RStudio from the newly created RProject. Take a look at the file pane and you can see that the folders have been created, and R Script templates downloaded."
  }
]